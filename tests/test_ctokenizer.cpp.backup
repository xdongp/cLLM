#include <gtest/gtest.h>
#include "cllm/CTokenizer/manager.h"
#include "cllm/CTokenizer/tokenizer.h"
#include "cllm/CTokenizer/sentencepiece_tokenizer.h"
#include "cllm/CTokenizer/qwen_tokenizer.h"
#include "cllm/CTokenizer/deepseek_tokenizer.h"
#include "cllm/CTokenizer/model_detector.h"
#include <chrono>
#include <thread>

using namespace cllm;

class CTokenizerTest : public ::testing::Test {
protected:
    void SetUp() override {
        // 准备测试环境
    }
    
    void TearDown() override {
        // 清理测试环境
    }
};

// 基础功能测试
TEST_F(CTokenizerTest, EncodeDecodeBasic) {
    // 由于我们没有实际的测试模型文件，我们测试接口的可用性
    SentencePieceTokenizer tokenizer(ModelType::QWEN);
    
    // 我们不能加载实际模型，因为没有测试文件，所以这里主要是验证接口可用性
    EXPECT_EQ(tokenizer.getModelType(), ModelType::QWEN);
    
    // 测试空输入情况
    auto emptyTokens = tokenizer.encode("");
    // 空字符串可能产生特殊token或空结果，这取决于具体实现
}

TEST_F(CTokenizerTest, VocabOperations) {
    SentencePieceTokenizer tokenizer(ModelType::QWEN);
    
    // 测试词汇表操作接口
    int vocabSize = tokenizer.getVocabSize();
    // 如果模型未加载，词汇表大小可能为0
    EXPECT_GE(vocabSize, 0);
    
    // 测试ID到Token的转换（对于未加载模型的情况）
    std::string token = tokenizer.idToToken(100);
    // 未加载模型时，应返回空字符串或默认值
    EXPECT_TRUE(true); // 接口调用不会崩溃
    
    // 测试Token到ID的转换
    llama_token id = tokenizer.tokenToId("test");
    EXPECT_TRUE(true); // 接口调用不会崩溃
}

TEST_F(CTokenizerTest, SpecialTokens) {
    SentencePieceTokenizer tokenizer(ModelType::QWEN);
    
    // 测试特殊Token接口
    llama_token bosId = tokenizer.getBosId();
    llama_token eosId = tokenizer.getEosId();
    llama_token padId = tokenizer.getPadId();
    llama_token unkId = tokenizer.getUnkId();
    
    // 未加载模型时，特殊token ID通常为负数
    EXPECT_LE(bosId, -1);
    EXPECT_LE(eosId, -1);
    EXPECT_LE(padId, -1);
    EXPECT_LE(unkId, -1);
}

// QwenTokenizer测试
TEST_F(CTokenizerTest, QwenFimDetection) {
    QwenTokenizer tokenizer;
    
    // 测试FIM标记检测
    EXPECT_TRUE(tokenizer.needsFimProcessing("<|fim_pre|>test<|fim_suf|>content<|fim_end|>"));
    EXPECT_TRUE(tokenizer.needsFimProcessing("test `` code ``"));
    EXPECT_FALSE(tokenizer.needsFimProcessing("regular text"));
}

// DeepSeekTokenizer测试
TEST_F(CTokenizerTest, DeepSeekModelTypes) {
    // 测试不同DeepSeek模型类型的构造
    DeepSeekTokenizer llmTokenizer(ModelType::DEEPSEEK_LLM);
    DeepSeekTokenizer coderTokenizer(ModelType::DEEPSEEK_CODER);
    DeepSeekTokenizer llm3Tokenizer(ModelType::DEEPSEEK3_LLM);
    
    EXPECT_EQ(llmTokenizer.getModelType(), ModelType::DEEPSEEK_LLM);
    EXPECT_EQ(coderTokenizer.getModelType(), ModelType::DEEPSEEK_CODER);
    EXPECT_EQ(llm3Tokenizer.getModelType(), ModelType::DEEPSEEK3_LLM);
}

// ModelDetector测试
TEST_F(CTokenizerTest, ModelDetectorDefault) {
    // 测试无效配置文件的处理
    ModelType type = ModelDetector::detectModelType("nonexistent/config.json");
    EXPECT_EQ(type, ModelType::SPM); // 应该返回默认类型
}

// TokenizerManager测试
TEST_F(CTokenizerTest, TokenizerManagerGet) {
    TokenizerManager manager;
    
    // 测试获取分词器（虽然无法加载实际模型，但可以测试管理器逻辑）
    CTokenizer* qwenTokenizer = manager.getTokenizer("qwen");
    EXPECT_NE(qwenTokenizer, nullptr);
    EXPECT_EQ(qwenTokenizer->getModelType(), ModelType::QWEN);
    
    CTokenizer* deepseekTokenizer = manager.getTokenizer("deepseek-coder");
    EXPECT_NE(deepseekTokenizer, nullptr);
    EXPECT_EQ(deepseekTokenizer->getModelType(), ModelType::DEEPSEEK_CODER);
    
    CTokenizer* llamaTokenizer = manager.getTokenizer("llama");
    EXPECT_NE(llamaTokenizer, nullptr);
    EXPECT_EQ(llamaTokenizer->getModelType(), ModelType::LLAMA);
}

TEST_F(CTokenizerTest, TokenizerManagerCache) {
    // 测试分词器缓存行为
    TokenizerManager manager;
    
    CTokenizer* tokenizer1 = manager.getTokenizer("qwen");
    CTokenizer* tokenizer2 = manager.getTokenizer("qwen");
    
    // 对于相同的模型类型，应该返回相同的实例（由管理器缓存）
    // 注意：这取决于具体实现，可能不是严格意义上的单例
    EXPECT_NE(tokenizer1, nullptr);
    EXPECT_NE(tokenizer2, nullptr);
}

// 模型类型枚举测试
TEST_F(CTokenizerTest, ModelTypeValues) {
    // 测试模型类型枚举值
    EXPECT_EQ(ModelType::AUTO, ModelType::AUTO);
    EXPECT_EQ(ModelType::QWEN, ModelType::QWEN);
    EXPECT_EQ(ModelType::QWEN2, ModelType::QWEN2);
    EXPECT_EQ(ModelType::DEEPSEEK_LLM, ModelType::DEEPSEEK_LLM);
    EXPECT_EQ(ModelType::DEEPSEEK_CODER, ModelType::DEEPSEEK_CODER);
    EXPECT_EQ(ModelType::DEEPSEEK3_LLM, ModelType::DEEPSEEK3_LLM);
    EXPECT_EQ(ModelType::LLAMA, ModelType::LLAMA);
    EXPECT_EQ(ModelType::BERT, ModelType::BERT);
    EXPECT_EQ(ModelType::GPT2, ModelType::GPT2);
    EXPECT_EQ(ModelType::SPM, ModelType::SPM);
    EXPECT_EQ(ModelType::BPE, ModelType::BPE);
    EXPECT_EQ(ModelType::WPM, ModelType::WPM);
}

// 边界条件测试
TEST_F(CTokenizerTest, BoundaryConditions) {
    SentencePieceTokenizer tokenizer(ModelType::QWEN);
    
    // 测试各种边界条件
    std::vector<std::string> testInputs = {
        "",           // 空字符串
        " ",          // 单空格
        "\n",         // 单换行
        "\t",         // 单制表符
        "A",          // 单字符
        std::string(10, 'A'), // 短字符串
    };
    
    for (const auto& input : testInputs) {
        // 测试编码接口不会崩溃
        auto tokens = tokenizer.encode(input);
        EXPECT_TRUE(true); // 只要不崩溃就算通过
        
        // 测试解码接口不会崩溃
        std::string decoded = tokenizer.decode(tokens);
        EXPECT_TRUE(true); // 只要不崩溃就算通过
    }
}

// 性能测试 - 主要是测试接口响应时间
TEST_F(CTokenizerTest, InterfaceResponsiveness) {
    SentencePieceTokenizer tokenizer(ModelType::QWEN);
    
    auto start = std::chrono::high_resolution_clock::now();
    
    // 快速调用多个接口
    int vocabSize = tokenizer.getVocabSize();
    llama_token bosId = tokenizer.getBosId();
    llama_token eosId = tokenizer.getEosId();
    std::string token = tokenizer.idToToken(100);
    
    auto end = std::chrono::high_resolution_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end - start);
    
    // 接口调用应在合理时间内完成（即使没有加载模型）
    EXPECT_LT(duration.count(), 1000); // 应该在1毫秒内完成
}

// 多线程安全性测试（基本验证）
TEST_F(CTokenizerTest, ThreadSafetyBasic) {
    TokenizerManager manager;
    
    // 启动多个线程同时获取分词器
    std::vector<std::thread> threads;
    
    for (int i = 0; i < 5; ++i) {
        threads.emplace_back([&manager, i]() {
            CTokenizer* tok = manager.getTokenizer("qwen");
            EXPECT_NE(tok, nullptr);
            // 模拟一些操作
            EXPECT_EQ(tok->getModelType(), ModelType::QWEN);
        });
    }
    
    for (auto& t : threads) {
        t.join();
    }
}

// 测试完成
int main(int argc, char **argv) {
    ::testing::InitGoogleTest(&argc, argv);
    return RUN_ALL_TESTS();
}