#include <gtest/gtest.h>
#include "cllm/CTokenizer/qwen_tokenizer.h"
#include <string>
#include <vector>
#include <thread>
#include <chrono>

using namespace cllm;

// ============================================================================
// QwenTokenizer é¢„å¤„ç†å•å…ƒæµ‹è¯•
// ============================================================================

class QwenPreprocessingUnitTest : public ::testing::Test {
protected:
    void SetUp() override {
        // æ¯ä¸ªæµ‹è¯•å‰çš„è®¾ç½®
    }
    
    void TearDown() override {
        // æ¯ä¸ªæµ‹è¯•åçš„æ¸…ç†
    }
};

// ========== åŸºç¡€åŠŸèƒ½æµ‹è¯• ==========

TEST_F(QwenPreprocessingUnitTest, ConstructorAndModelType) {
    QwenTokenizer tokenizer;
    
    // éªŒè¯æ¨¡å‹ç±»å‹
    EXPECT_EQ(tokenizer.getModelType(), ModelType::QWEN);
}

TEST_F(QwenPreprocessingUnitTest, EmptyTextHandling) {
    QwenTokenizer tokenizer;
    
    // ç©ºæ–‡æœ¬åº”è¯¥è¿”å›ç©ºç»“æœ
    std::vector<llama_token> tokens = tokenizer.encode("", true);
    EXPECT_TRUE(tokens.empty());
    
    tokens = tokenizer.encode("", false);
    EXPECT_TRUE(tokens.empty());
}

// ========== FIM æ£€æµ‹æµ‹è¯• ==========

TEST_F(QwenPreprocessingUnitTest, FimDetectionWithStandardMarkers) {
    QwenTokenizer tokenizer;
    
    // æµ‹è¯•æ ‡å‡†FIMæ ‡è®°æ£€æµ‹
    EXPECT_TRUE(tokenizer.needsFimProcessing("<|fim_pre|>test<|fim_suf|>content<|fim_end|>"));
    EXPECT_TRUE(tokenizer.needsFimProcessing("<|fim_begin|>test"));
    EXPECT_TRUE(tokenizer.needsFimProcessing("test<|fim_end|>"));
    EXPECT_TRUE(tokenizer.needsFimProcessing("<|fim_pre|>test"));
    EXPECT_TRUE(tokenizer.needsFimProcessing("<|fim_suf|>test"));
}

TEST_F(QwenPreprocessingUnitTest, FimDetectionWithSimpleMarkers) {
    QwenTokenizer tokenizer;
    
    // æµ‹è¯•ç®€åŒ–çš„``æ ‡è®°æ£€æµ‹
    EXPECT_TRUE(tokenizer.needsFimProcessing("test `` code"));
    EXPECT_TRUE(tokenizer.needsFimProcessing("``"));
    EXPECT_TRUE(tokenizer.needsFimProcessing("prefix `` suffix"));
}

TEST_F(QwenPreprocessingUnitTest, FimDetectionWithoutMarkers) {
    QwenTokenizer tokenizer;
    
    // æ™®é€šæ–‡æœ¬ä¸åº”æ£€æµ‹ä¸ºFIM
    EXPECT_FALSE(tokenizer.needsFimProcessing("regular text without fim markers"));
    EXPECT_FALSE(tokenizer.needsFimProcessing("test with ` single backtick"));
    EXPECT_FALSE(tokenizer.needsFimProcessing(""));
    EXPECT_FALSE(tokenizer.needsFimProcessing("   "));
}

// ========== è‹±è¯­ç¼©å†™é¢„å¤„ç†æµ‹è¯• ==========

TEST_F(QwenPreprocessingUnitTest, EnglishContractions) {
    QwenTokenizer tokenizer;
    
    // æµ‹è¯•å¸¸è§è‹±è¯­ç¼©å†™
    // æ³¨æ„ï¼šè¿™é‡Œåªæµ‹è¯•é¢„å¤„ç†ä¸ä¼šç ´åæ–‡æœ¬ï¼Œå…·ä½“åˆ†è¯ç”±SentencePieceå†³å®š
    std::vector<std::string> test_cases = {
        "don't worry",
        "it's working",
        "they're here",
        "I've done it",
        "I'm happy",
        "we'll see",
        "he'd go"
    };
    
    for (const auto& text : test_cases) {
        // ç¼–ç åº”è¯¥æˆåŠŸï¼ˆä¸å´©æºƒï¼‰
        auto tokens = tokenizer.encode(text, false);
        // æ— æ¨¡å‹æ—¶è¿”å›ç©ºï¼Œè¿™æ˜¯æ­£å¸¸çš„
        EXPECT_TRUE(tokens.empty() || !tokens.empty()) 
            << "Processing failed for: " << text;
    }
}

// ========== æ··åˆå†…å®¹é¢„å¤„ç†æµ‹è¯• ==========

TEST_F(QwenPreprocessingUnitTest, MixedEnglishAndNumbers) {
    QwenTokenizer tokenizer;
    
    std::string text = "The year is 2024 and it's great!";
    auto tokens = tokenizer.encode(text, false);
    
    // æ— æ¨¡å‹æ—¶è¿”å›ç©ºï¼ŒéªŒè¯ä¸å´©æºƒå³å¯
    EXPECT_TRUE(tokens.empty());
}

TEST_F(QwenPreprocessingUnitTest, MixedChineseAndEnglish) {
    QwenTokenizer tokenizer;
    
    std::string text = "ä½ å¥½World! This is æµ‹è¯•123.";
    auto tokens = tokenizer.encode(text, false);
    
    // æ— æ¨¡å‹æ—¶è¿”å›ç©ºï¼ŒéªŒè¯ä¸å´©æºƒå³å¯
    EXPECT_TRUE(tokens.empty());
}

TEST_F(QwenPreprocessingUnitTest, PunctuationHandling) {
    QwenTokenizer tokenizer;
    
    std::string text = "Hello, World! How are you? I'm fine.";
    auto tokens = tokenizer.encode(text, false);
    
    // æ— æ¨¡å‹æ—¶è¿”å›ç©ºï¼ŒéªŒè¯ä¸å´©æºƒå³å¯
    EXPECT_TRUE(tokens.empty());
}

// ========== æ•°å­—å¤„ç†æµ‹è¯• ==========

TEST_F(QwenPreprocessingUnitTest, NumberHandling) {
    QwenTokenizer tokenizer;
    
    std::vector<std::string> test_cases = {
        "0",
        "123",
        "1 2 3",
        "number 42 is the answer",
        "3.14159"
    };
    
    for (const auto& text : test_cases) {
        auto tokens = tokenizer.encode(text, false);
        // éªŒè¯ä¸å´©æºƒ
        EXPECT_TRUE(tokens.empty()) << "Failed for: " << text;
    }
}

// ========== ç©ºç™½å­—ç¬¦å¤„ç†æµ‹è¯• ==========

TEST_F(QwenPreprocessingUnitTest, WhitespaceHandling) {
    QwenTokenizer tokenizer;
    
    std::vector<std::string> test_cases = {
        "test   multiple   spaces",
        "test\ttab\tcharacters",
        "test\nnewline\ncharacters",
        "test\r\nwindows\r\nnewlines",
        "   leading spaces",
        "trailing spaces   ",
        "\n\n\nmultiple newlines\n\n\n"
    };
    
    for (const auto& text : test_cases) {
        auto tokens = tokenizer.encode(text, false);
        // éªŒè¯ä¸å´©æºƒ
        EXPECT_TRUE(tokens.empty()) << "Failed for: " << text;
    }
}

// ========== è¾¹ç•Œæ¡ä»¶æµ‹è¯• ==========

TEST_F(QwenPreprocessingUnitTest, SingleCharacter) {
    QwenTokenizer tokenizer;
    
    std::vector<std::string> test_cases = {
        "a", "Z", "0", "9", "!", "?", " ", "\n"
    };
    
    for (const auto& text : test_cases) {
        auto tokens = tokenizer.encode(text, false);
        EXPECT_TRUE(tokens.empty());
    }
}

TEST_F(QwenPreprocessingUnitTest, VeryLongText) {
    QwenTokenizer tokenizer;
    
    // ç”Ÿæˆä¸€ä¸ªå¾ˆé•¿çš„æ–‡æœ¬ï¼ˆ10KBï¼‰
    std::string long_text;
    long_text.reserve(10000);
    for (int i = 0; i < 1000; i++) {
        long_text += "This is a test sentence. ";
    }
    
    auto start = std::chrono::high_resolution_clock::now();
    auto tokens = tokenizer.encode(long_text, false);
    auto end = std::chrono::high_resolution_clock::now();
    
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);
    
    // éªŒè¯å¤„ç†æ—¶é—´åˆç†ï¼ˆåº”è¯¥åœ¨100mså†…ï¼‰
    EXPECT_LT(duration.count(), 100) << "Processing took " << duration.count() << "ms";
    EXPECT_TRUE(tokens.empty());
}

// ========== ç‰¹æ®Šå­—ç¬¦æµ‹è¯• ==========

TEST_F(QwenPreprocessingUnitTest, UnicodeCharacters) {
    QwenTokenizer tokenizer;
    
    std::vector<std::string> test_cases = {
        "ä¸­æ–‡æµ‹è¯•",
        "æ—¥æœ¬èªãƒ†ã‚¹ãƒˆ",
        "í•œêµ­ì–´ í…ŒìŠ¤íŠ¸",
        "Ğ¢ĞµÑÑ‚ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼",
        "Test with Ã©mojis ğŸ˜€ğŸ‰",
        "Mixed: ä¸­æ–‡Englishæ—¥æœ¬èª123"
    };
    
    for (const auto& text : test_cases) {
        auto tokens = tokenizer.encode(text, false);
        // éªŒè¯ä¸å´©æºƒ
        EXPECT_TRUE(tokens.empty()) << "Failed for: " << text;
    }
}

TEST_F(QwenPreprocessingUnitTest, SpecialCharacters) {
    QwenTokenizer tokenizer;
    
    std::string text = "!@#$%^&*()_+-=[]{}|;:',.<>?/~`";
    auto tokens = tokenizer.encode(text, false);
    
    // éªŒè¯ä¸å´©æºƒ
    EXPECT_TRUE(tokens.empty());
}

// ========== è¯æ±‡è¡¨æ“ä½œæµ‹è¯• ==========

TEST_F(QwenPreprocessingUnitTest, VocabOperationsWithoutModel) {
    QwenTokenizer tokenizer;
    
    // æ²¡æœ‰æ¨¡å‹æ—¶ï¼Œè¯æ±‡è¡¨å¤§å°åº”è¯¥ä¸º0
    EXPECT_EQ(tokenizer.getVocabSize(), 0);
    
    // æ²¡æœ‰æ¨¡å‹æ—¶ï¼ŒIDåˆ°tokençš„è½¬æ¢åº”è¯¥è¿”å›ç©ºå­—ç¬¦ä¸²
    std::string token = tokenizer.idToToken(100);
    EXPECT_TRUE(token.empty());
    
    // æ²¡æœ‰æ¨¡å‹æ—¶ï¼Œtokenåˆ°IDçš„è½¬æ¢åº”è¯¥è¿”å›0æˆ–-1
    llama_token id = tokenizer.tokenToId("test");
    EXPECT_TRUE(id == 0 || id == -1) << "Expected 0 or -1, got " << id;
}

// ========== ç¼–ç é€‰é¡¹æµ‹è¯• ==========

TEST_F(QwenPreprocessingUnitTest, EncodeWithAndWithoutSpecialTokens) {
    QwenTokenizer tokenizer;
    
    std::string text = "test text";
    
    // æµ‹è¯•å¸¦ç‰¹æ®Štokensçš„ç¼–ç 
    auto tokens_with = tokenizer.encode(text, true);
    EXPECT_TRUE(tokens_with.empty());
    
    // æµ‹è¯•ä¸å¸¦ç‰¹æ®Štokensçš„ç¼–ç 
    auto tokens_without = tokenizer.encode(text, false);
    EXPECT_TRUE(tokens_without.empty());
}

// ========== å¤šçº¿ç¨‹å®‰å…¨æ€§æµ‹è¯• ==========

TEST_F(QwenPreprocessingUnitTest, ConcurrentEncode) {
    QwenTokenizer tokenizer;
    
    std::vector<std::thread> threads;
    std::atomic<int> success_count{0};
    
    // å¯åŠ¨10ä¸ªçº¿ç¨‹å¹¶å‘ç¼–ç 
    for (int i = 0; i < 10; i++) {
        threads.emplace_back([&tokenizer, &success_count, i]() {
            std::string text = "test text " + std::to_string(i);
            auto tokens = tokenizer.encode(text, false);
            // æ— æ¨¡å‹æ—¶è¿”å›ç©ºæ˜¯æ­£å¸¸çš„
            if (tokens.empty()) {
                success_count++;
            }
        });
    }
    
    // ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
    for (auto& t : threads) {
        t.join();
    }
    
    // æ‰€æœ‰çº¿ç¨‹éƒ½åº”è¯¥æˆåŠŸ
    EXPECT_EQ(success_count.load(), 10);
}

// ========== å¼‚å¸¸å¤„ç†æµ‹è¯• ==========

TEST_F(QwenPreprocessingUnitTest, NullCharacterHandling) {
    QwenTokenizer tokenizer;
    
    std::string text_with_null = "test\0text";
    text_with_null.resize(9); // ç¡®ä¿åŒ…å«nullå­—ç¬¦
    
    // åº”è¯¥èƒ½å¤Ÿå¤„ç†åŒ…å«nullå­—ç¬¦çš„æ–‡æœ¬ï¼ˆä¸å´©æºƒï¼‰
    auto tokens = tokenizer.encode(text_with_null, false);
    EXPECT_TRUE(tokens.empty());
}

// ========== æ¥å£å“åº”æ—¶é—´æµ‹è¯• ==========

TEST_F(QwenPreprocessingUnitTest, InterfaceResponseTime) {
    QwenTokenizer tokenizer;
    std::string text = "test text for performance";
    
    // é¢„çƒ­
    tokenizer.encode(text, false);
    
    // æµ‹é‡å“åº”æ—¶é—´
    auto start = std::chrono::high_resolution_clock::now();
    for (int i = 0; i < 1000; i++) {
        tokenizer.encode(text, false);
    }
    auto end = std::chrono::high_resolution_clock::now();
    
    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end - start);
    double avg_time = duration.count() / 1000.0;
    
    // å¹³å‡å“åº”æ—¶é—´åº”è¯¥å°äº10å¾®ç§’ï¼ˆæ— æ¨¡å‹æƒ…å†µä¸‹ï¼‰
    EXPECT_LT(avg_time, 10.0) << "Average response time: " << avg_time << "Î¼s";
}

// ========== ä»£ç è¡¥å…¨åœºæ™¯æµ‹è¯• ==========

TEST_F(QwenPreprocessingUnitTest, CodeCompletionScenario) {
    QwenTokenizer tokenizer;
    
    // æ¨¡æ‹Ÿä»£ç è¡¥å…¨åœºæ™¯
    std::string code = R"(def add(a, b):
    return a + b

def subtract(a, b):
    return a - b)";
    
    auto tokens = tokenizer.encode(code, false);
    
    // éªŒè¯ä¸å´©æºƒï¼Œæ— æ¨¡å‹æ—¶è¿”å›ç©º
    EXPECT_TRUE(tokens.empty());
}

// ============================================================================
// ä¸»å‡½æ•°
// ============================================================================

int main(int argc, char **argv) {
    ::testing::InitGoogleTest(&argc, argv);
    return RUN_ALL_TESTS();
}
