/**
 * @file kylin_backend.cpp
 * @brief Kylin (éº’éºŸ) è‡ªç ”æ¨ç†åç«¯å®ç°
 */

#include "cllm/inference/kylin_backend.h"
#include "cllm/model/loader_interface.h"
#include "cllm/common/logger.h"
#include "cllm/common/config.h"
#include "cllm/kylin/core/quantization.h"

#include <stdexcept>
#include <cmath>
#include <filesystem>

namespace cllm {
namespace inference {

namespace {

// ä¸ºæƒé‡å¼ é‡å¡«å……ç®€å•çš„å¯é‡å¤æ¨¡å¼ï¼Œé¿å…å…¨é›¶
inline void fill_tensor_with_pattern(kylin::Tensor &tensor, float scale) {
    const size_t n = tensor.size();
    for (size_t i = 0; i < n; ++i) {
        // ä½¿ç”¨æœ‰ç¬¦å·åç§»é¿å… size_t ä¸‹æº¢
        int v = static_cast<int>(i % 31) - 15;
        tensor[i] = static_cast<float>(v) * scale;
    }
}

// Xavier/Glorot åˆå§‹åŒ–ï¼šé€‚ç”¨äºçº¿æ€§å±‚æƒé‡
// å¯¹äºå½¢çŠ¶ä¸º [fan_in, fan_out] çš„æƒé‡ï¼Œä½¿ç”¨ scale = sqrt(2.0 / (fan_in + fan_out))
inline void xavier_init(kylin::Tensor &tensor, size_t fan_in, size_t fan_out) {
    const size_t n = tensor.size();
    if (n == 0) return;
    
    // ä½¿ç”¨ç®€åŒ–çš„Xavieråˆå§‹åŒ–ï¼šscale = sqrt(2.0 / (fan_in + fan_out))
    float scale = std::sqrt(2.0f / static_cast<float>(fan_in + fan_out));
    
    // ä½¿ç”¨æ­£æ€åˆ†å¸ƒçš„è¿‘ä¼¼ï¼šBox-Mullerå˜æ¢çš„ç®€åŒ–ç‰ˆæœ¬
    // ä¸ºäº†ç®€å•ï¼Œä½¿ç”¨å‡åŒ€åˆ†å¸ƒä¹˜ä»¥scaleï¼Œç„¶åæ·»åŠ å°çš„éšæœºåç§»
    for (size_t i = 0; i < n; ++i) {
        // ä½¿ç”¨æœ‰ç¬¦å·åç§»é¿å… size_t ä¸‹æº¢
        int u = static_cast<int>(i % 100) - 50;
        tensor[i] = static_cast<float>(u) / 50.0f * scale;
    }
}

// å°å€¼åˆå§‹åŒ–ï¼šé€‚ç”¨äºembeddingå’ŒæŸäº›ç‰¹æ®Šå±‚
inline void small_value_init(kylin::Tensor &tensor, float scale = 0.1f) {
    const size_t n = tensor.size();
    for (size_t i = 0; i < n; ++i) {
        // ä½¿ç”¨å°çš„å‡åŒ€åˆ†å¸ƒå€¼
        int v = static_cast<int>(i % 21) - 10;
        tensor[i] = static_cast<float>(v) / 100.0f * scale;
    }
}

} // namespace

KylinBackend::KylinBackend(
    const ModelConfig &config, 
    const std::string &modelPath,
    kylin::OperatorBackend operatorBackend
)
    : externalConfig_(config)
    , internalConfig_(config)
    , initialized_(false)
    , modelPath_(modelPath)
    , model_(config)
    , operatorBackendType_(operatorBackend)
    , deviceBackendType_(kylin::BackendType::CPU)
    , useGGMLDirect_(false)
    , ggmlModel_(nullptr)
    , useHFModel_(false)
    , hfModel_(nullptr) {
    
    CLLM_INFO("[KylinBackend] Initializing Kylin (éº’éºŸ) inference backend");
    
    // æ£€æµ‹æ¨¡å‹æ ¼å¼
    if (!modelPath_.empty()) {
        std::filesystem::path path(modelPath_);
        
        // æ£€æµ‹æ˜¯å¦ä¸º HuggingFace æ¨¡å‹ç›®å½•ï¼ˆåŒ…å« config.json å’Œ *.safetensorsï¼‰
        if (std::filesystem::is_directory(path)) {
            std::filesystem::path configJson = path / "config.json";
            std::filesystem::path safetensors = path / "model.safetensors";
            
            if (std::filesystem::exists(configJson) && std::filesystem::exists(safetensors)) {
                useHFModel_ = true;
                CLLM_INFO("[KylinBackend] Detected HuggingFace model directory, will use HFTransformerModel");
            } else {
                CLLM_INFO("[KylinBackend] Directory does not contain HuggingFace model files");
            }
        }
        // æ£€æµ‹æ˜¯å¦ä¸º GGUF æ ¼å¼
        else if (path.extension() == ".gguf") {
            useGGMLDirect_ = true;
            CLLM_INFO("[KylinBackend] Detected GGUF format, will use GGMLTransformerModel (direct GGML inference)");
        } else {
            CLLM_INFO("[KylinBackend] Will use TransformerModel with operator backend");
        }
    }
    
    // è¯»å–è®¾å¤‡åç«¯é…ç½®
    std::string deviceBackendStr = Config::instance().backendKylinDeviceBackend();
    deviceBackendType_ = kylin::BackendType::CPU;
    
    if (deviceBackendStr == "metal" || deviceBackendStr == "Metal") {
        deviceBackendType_ = kylin::BackendType::Metal;
        CLLM_INFO("[KylinBackend] Using Metal (Apple GPU) device backend");
    } else if (deviceBackendStr == "cuda" || deviceBackendStr == "CUDA") {
        deviceBackendType_ = kylin::BackendType::CUDA;
        CLLM_INFO("[KylinBackend] Using CUDA (NVIDIA GPU) device backend");
    } else if (deviceBackendStr == "auto" || deviceBackendStr == "Auto") {
        deviceBackendType_ = kylin::BackendType::Auto;
        CLLM_INFO("[KylinBackend] Auto-detecting best device backend");
    } else {
        CLLM_INFO("[KylinBackend] Using CPU device backend");
    }
    
    // å¦‚æœä½¿ç”¨ GGML ç›´æ¥æ¨ç†ï¼Œä¸éœ€è¦ç®—å­
    if (!useGGMLDirect_) {
        // åˆ›å»ºç®—å­å®ä¾‹ï¼ˆä¼ é€’è®¾å¤‡åç«¯ï¼‰
        op_ = kylin::OperatorFactory::create(operatorBackend, deviceBackendType_);
        CLLM_INFO("[KylinBackend] Using operator backend: %s", op_->getName().c_str());
    }
    
    if (!modelPath_.empty()) {
        if (useHFModel_) {
            // HuggingFace æ¨¡å‹ï¼šHFTransformerModel åœ¨ initialize() ä¸­åˆ›å»º
            CLLM_INFO("[KylinBackend] Will use HFTransformerModel for HuggingFace model: %s", modelPath_.c_str());
        } else if (useGGMLDirect_) {
            // GGUF æ–‡ä»¶ï¼šä½¿ç”¨ GGMLTransformerModelï¼ˆä¼ é€’è®¾å¤‡åç«¯ï¼‰
            CLLM_INFO("[KylinBackend] Will use GGMLTransformerModel for GGUF file: %s", modelPath_.c_str());
            CLLM_INFO("[KylinBackend] GGMLTransformerModel will use device backend: %s",
                     deviceBackendType_ == kylin::BackendType::Metal ? "Metal" :
                     deviceBackendType_ == kylin::BackendType::CUDA ? "CUDA" : "CPU");
            ggmlModel_ = std::make_unique<kylin::GGMLTransformerModel>(deviceBackendType_);
        } else {
            // å…¶ä»–æ ¼å¼ï¼šä½¿ç”¨ ModelLoader + TransformerModel
            CLLM_INFO("[KylinBackend] Will load real weights from: %s", modelPath_.c_str());
            try {
                loader_ = ModelLoaderFactory::createLoader(modelPath_, externalConfig_);
                CLLM_INFO("[KylinBackend] Created loader for format: %s", 
                         ModelLoaderFactory::formatToString(ModelLoaderFactory::detectFormat(modelPath_)).c_str());
            } catch (const std::exception& e) {
                CLLM_ERROR("[KylinBackend] Failed to create model loader: %s", e.what());
                throw;
            }
        }
    } else {
        // å ä½æƒé‡æ¨¡å¼
        CLLM_INFO("[KylinBackend] Will use placeholder weights (test mode)");
        prepareInternalConfig();
    }

    // é¢„åˆ†é…æƒé‡å®¹å™¨ï¼ˆä»…åœ¨é HuggingFace æ¨¡å¼ä¸‹éœ€è¦ï¼‰
    if (!useHFModel_) {
        const size_t numLayers = internalConfig_.numLayers;
        wq_.resize(numLayers);
        wk_.resize(numLayers);
        wv_.resize(numLayers);
        wo_.resize(numLayers);
        wGate_.resize(numLayers);
        wUp_.resize(numLayers);
        wDown_.resize(numLayers);
        norm1_.resize(numLayers);
        norm2_.resize(numLayers);
        attnQNorm_.resize(numLayers);
        attnKNorm_.resize(numLayers);
    }
}

void KylinBackend::prepareInternalConfig() {
    // ä¸ºé¿å…ä¸€æ¬¡æ€§åˆ†é…è¿‡å¤§çš„çŸ©é˜µï¼Œä½¿ç”¨ç²¾ç®€é…ç½®
    // ä½†ä¿æŒ vocabSize ä¸å¤–éƒ¨é…ç½®ä¸€è‡´ï¼Œç¡®ä¿ logits ç»´åº¦æ­£ç¡®
    internalConfig_.hiddenSize = 128;
    internalConfig_.intermediateSize = 256;
    internalConfig_.numLayers = 2;
    internalConfig_.numAttentionHeads = 4; // headDim = 32
    
    CLLM_INFO("[KylinBackend] Using simplified config:");
    CLLM_INFO("  hiddenSize: %u", internalConfig_.hiddenSize);
    CLLM_INFO("  intermediateSize: %u", internalConfig_.intermediateSize);
    CLLM_INFO("  numLayers: %u", internalConfig_.numLayers);
    CLLM_INFO("  vocabSize: %u (from external)", internalConfig_.vocabSize);
}

bool KylinBackend::initialize() {
    if (initialized_) {
        CLLM_INFO("[KylinBackend] Already initialized");
        return true;
    }

    CLLM_INFO("[KylinBackend] Starting initialization...");

    // ========== HuggingFace æ¨¡å‹ï¼ˆsafetensors ç›®å½•ï¼‰==========
    if (useHFModel_) {
        return initializeHFModel();
    }

    // ========== GGML ç›´æ¥æ¨ç†æ¨¡å¼ï¼ˆGGUF æ–‡ä»¶ï¼‰==========
    if (useGGMLDirect_) {
        return initializeGGMLDirect();
    }
    
    // ========== TransformerModel æ¨¡å¼ï¼ˆ.bin æ–‡ä»¶æˆ–å ä½æƒé‡ï¼‰==========

    // 1. éªŒè¯é…ç½®
    const size_t vocab = externalConfig_.vocabSize;
    const size_t hidden = internalConfig_.hiddenSize;
    const size_t inter = internalConfig_.intermediateSize;
    const size_t numLayers = internalConfig_.numLayers;

    if (vocab == 0 || hidden == 0 || inter == 0 || numLayers == 0) {
        throw std::runtime_error("KylinBackend::initialize: invalid model configuration");
    }

    // 2. åŠ è½½æƒé‡
    if (loader_) {
        if (!loadRealWeights()) {
            return false;
        }
    } else {
        // åˆ†é…å ä½æƒé‡
        CLLM_INFO("[KylinBackend] Allocating placeholder weights...");
        
        embedding_ = Tensor({vocab, hidden});
        lmHead_ = Tensor({hidden, vocab});
        finalNormWeight_ = Tensor({hidden});

        for (size_t layer = 0; layer < numLayers; ++layer) {
            wq_[layer] = Tensor({hidden, hidden});
            wk_[layer] = Tensor({hidden, hidden});
            wv_[layer] = Tensor({hidden, hidden});
            wo_[layer] = Tensor({hidden, hidden});

            wGate_[layer] = Tensor({hidden, inter});
            wUp_[layer] = Tensor({hidden, inter});
            wDown_[layer] = Tensor({inter, hidden});

            norm1_[layer] = Tensor({hidden});
            norm2_[layer] = Tensor({hidden});
        }

        initializePlaceholderWeights();
    }

    // 3. ç»‘å®šæƒé‡åˆ°æ¨¡å‹
    CLLM_INFO("[KylinBackend] About to call bindWeightsToModel()...");
    try {
    bindWeightsToModel();
    } catch (const std::exception& e) {
        CLLM_ERROR("[KylinBackend] Exception in bindWeightsToModel(): %s", e.what());
        throw;
    } catch (...) {
        CLLM_ERROR("[KylinBackend] Unknown exception in bindWeightsToModel()");
        throw;
    }
    CLLM_INFO("[KylinBackend] bindWeightsToModel() completed successfully");

    initialized_ = true;
    CLLM_INFO("[KylinBackend] Initialization completed successfully");
    return true;
}

bool KylinBackend::initializeHFModel() {
    CLLM_INFO("[KylinBackend] Initializing HuggingFace model (safetensors)...");
    
    try {
        // è½¬æ¢è®¾å¤‡ç±»å‹
        kylin::DeviceType deviceType = kylin::DeviceType::CPU;
        if (deviceBackendType_ == kylin::BackendType::Metal) {
            deviceType = kylin::DeviceType::Metal;
            CLLM_INFO("[KylinBackend] Requesting Metal GPU acceleration for HF model");
        } else if (deviceBackendType_ == kylin::BackendType::CUDA) {
            deviceType = kylin::DeviceType::CUDA;
            CLLM_INFO("[KylinBackend] Requesting CUDA GPU acceleration for HF model");
        }
        
        // ä»å…¨å±€é…ç½®è¯»å–é‡åŒ–ç±»å‹
        kylin::QuantType quantType = kylin::QuantType::FP32;  // é»˜è®¤ FP32
        std::string quantStr = Config::instance().serverQuantization();
        if (!quantStr.empty()) {
            quantType = kylin::parseQuantType(quantStr);
            CLLM_INFO("[KylinBackend] Using quantization: %s", kylin::quantTypeName(quantType));
        }
        
        // åˆ›å»ºå¹¶åŠ è½½ HuggingFace æ¨¡å‹
        hfModel_ = std::make_unique<kylin::HFTransformerModel>(modelPath_, deviceType, quantType);
        
        if (!hfModel_->isLoaded()) {
            CLLM_ERROR("[KylinBackend] Failed to load HuggingFace model: %s", modelPath_.c_str());
            return false;
        }
        
        // æ›´æ–°é…ç½®
        const auto& hfConfig = hfModel_->config();
        externalConfig_.vocabSize = hfConfig.vocabSize;
        externalConfig_.hiddenSize = hfConfig.hiddenSize;
        externalConfig_.numLayers = hfConfig.numHiddenLayers;
        externalConfig_.numAttentionHeads = hfConfig.numAttentionHeads;
        externalConfig_.numKeyValueHeads = hfConfig.getNumKVHeads();
        externalConfig_.intermediateSize = hfConfig.intermediateSize;
        
        CLLM_INFO("[KylinBackend] HuggingFace model loaded successfully:");
        CLLM_INFO("  Model: %s", hfConfig.modelType.c_str());
        CLLM_INFO("  Vocab: %u", externalConfig_.vocabSize);
        CLLM_INFO("  Hidden: %u", externalConfig_.hiddenSize);
        CLLM_INFO("  Layers: %u", externalConfig_.numLayers);
        CLLM_INFO("  Heads: %u (KV: %u)", externalConfig_.numAttentionHeads, externalConfig_.numKeyValueHeads);
        CLLM_INFO("  Dtype: %s", hfConfig.torchDtype.c_str());
        
        initialized_ = true;
        CLLM_INFO("[KylinBackend] HuggingFace model initialized successfully");
        return true;
        
    } catch (const std::exception& e) {
        CLLM_ERROR("[KylinBackend] Exception loading HuggingFace model: %s", e.what());
        return false;
    }
}

bool KylinBackend::initializeGGMLDirect() {
    CLLM_INFO("[KylinBackend] Initializing GGML direct inference mode...");
    
    if (!ggmlModel_) {
        CLLM_ERROR("[KylinBackend] GGMLTransformerModel not created");
        return false;
    }
    
    // åŠ è½½ GGUF æ¨¡å‹
    if (!ggmlModel_->loadFromGGUF(modelPath_)) {
        CLLM_ERROR("[KylinBackend] Failed to load GGUF model: %s", modelPath_.c_str());
        return false;
    }
    
    // æ›´æ–°é…ç½®
    const auto& ggmlConfig = ggmlModel_->getConfig();
    externalConfig_.vocabSize = ggmlConfig.vocabSize;
    externalConfig_.hiddenSize = ggmlConfig.embeddingLength;
    externalConfig_.numLayers = ggmlConfig.blockCount;
    externalConfig_.numAttentionHeads = ggmlConfig.headCount;
    externalConfig_.numKeyValueHeads = ggmlConfig.headCountKV;
    externalConfig_.intermediateSize = ggmlConfig.feedForwardLength;
    externalConfig_.maxSequenceLength = ggmlConfig.contextLength;
    
    CLLM_INFO("[KylinBackend] GGML model loaded successfully:");
    CLLM_INFO("  Vocab: %u", externalConfig_.vocabSize);
    CLLM_INFO("  Hidden: %u", externalConfig_.hiddenSize);
    CLLM_INFO("  Layers: %u", externalConfig_.numLayers);
    CLLM_INFO("  Heads: %u (KV: %u)", externalConfig_.numAttentionHeads, externalConfig_.numKeyValueHeads);
    
    initialized_ = true;
    CLLM_INFO("[KylinBackend] GGML direct inference initialized successfully");
    return true;
}

bool KylinBackend::loadRealWeights() {
    CLLM_INFO("[KylinBackend] Loading real weights...");

    // 1) ä½¿ç”¨ ModelLoader åŠ è½½ï¼ˆä¼šè¯»å– <model>.json å…ƒæ•°æ®ï¼‰
    if (!loader_->load()) {
        CLLM_ERROR("[KylinBackend] Failed to load model weights via ModelLoader");
        return false;
    }

    // 2) ç”¨å…ƒæ•°æ®ä¸­çš„çœŸå®ç»“æ„å‚æ•°è¦†ç›–å¤–éƒ¨é…ç½®ï¼ˆé¿å…é»˜è®¤ llama é…ç½®å¯¼è‡´ shape mismatchï¼‰
    externalConfig_ = loader_->getConfig();
    internalConfig_ = externalConfig_;

    const size_t numLayers = internalConfig_.numLayers;

    // ç¡®ä¿æƒé‡å®¹å™¨å¤§å°æ­£ç¡®
    wq_.resize(numLayers);
    wk_.resize(numLayers);
    wv_.resize(numLayers);
    wo_.resize(numLayers);
    wGate_.resize(numLayers);
    wUp_.resize(numLayers);
    wDown_.resize(numLayers);
    norm1_.resize(numLayers);
    norm2_.resize(numLayers);
    attnQNorm_.resize(numLayers);
    attnKNorm_.resize(numLayers);

    CLLM_INFO("[KylinBackend] Calling loadInto to map weights...");
    if (!loader_->loadInto(
            embedding_,
            wq_, wk_, wv_, wo_,
            wGate_, wUp_, wDown_,
            norm1_, norm2_,
            finalNormWeight_,
            lmHead_)) {
        CLLM_ERROR("[KylinBackend] Failed to map weights from ModelLoader");
        return false;
    }

    // å°è¯•åŠ è½½ Q/K å½’ä¸€åŒ–æƒé‡ï¼ˆå¦‚æœä½¿ç”¨ GGUF æ ¼å¼ä¸”å­˜åœ¨ï¼‰
    // æ³¨æ„ï¼šloadInto æ¥å£ä¸æ”¯æŒè¿™äº›æƒé‡ï¼Œéœ€è¦é€šè¿‡ ModelWeights ç»“æ„åŠ è½½
    // è¿™é‡Œå…ˆå°è¯•é€šè¿‡ IModelLoader æ¥å£åŠ è½½ï¼ˆå¦‚æœæ”¯æŒï¼‰
    if (loader_) {
        model::ModelWeights modelWeights;
        if (loader_->loadWeights(modelWeights, false)) {  // ä¸ç«‹å³åŠ è½½æ•°æ®ï¼Œåªåˆ›å»ºç»“æ„
            // å°è¯•åŠ è½½ Q/K å½’ä¸€åŒ–æƒé‡
            for (size_t layer = 0; layer < numLayers && layer < modelWeights.layers.size(); ++layer) {
                const auto& layerWeights = modelWeights.layers[layer];
                
                // å¦‚æœ Q/K å½’ä¸€åŒ–æƒé‡å­˜åœ¨ï¼ŒåŠ è½½å®ƒä»¬
                if (!layerWeights.attnQNorm.shape.empty() && layerWeights.attnQNorm.data.size() > 0) {
                    attnQNorm_[layer] = kylin::Tensor(layerWeights.attnQNorm.shape);
                    std::copy(layerWeights.attnQNorm.data.begin(), 
                             layerWeights.attnQNorm.data.end(), 
                             attnQNorm_[layer].data());
                    CLLM_DEBUG("[KylinBackend] Loaded attnQNorm for layer %zu (shape size: %zu)", 
                              layer, layerWeights.attnQNorm.shape.size());
                }
                
                if (!layerWeights.attnKNorm.shape.empty() && layerWeights.attnKNorm.data.size() > 0) {
                    attnKNorm_[layer] = kylin::Tensor(layerWeights.attnKNorm.shape);
                    std::copy(layerWeights.attnKNorm.data.begin(), 
                             layerWeights.attnKNorm.data.end(), 
                             attnKNorm_[layer].data());
                    CLLM_DEBUG("[KylinBackend] Loaded attnKNorm for layer %zu (shape size: %zu)", 
                              layer, layerWeights.attnKNorm.shape.size());
                }
            }
        }
    }

    CLLM_INFO("[KylinBackend] Real weights loaded successfully");
    CLLM_INFO("[KylinBackend] Weight containers: wq_.size()=%zu, embedding_.shape().size()=%zu",
             wq_.size(), embedding_.shape().size());
    return true;
}

void KylinBackend::initializePlaceholderWeights() {
    CLLM_INFO("[KylinBackend] Initializing placeholder weights...");

    const size_t numLayers = internalConfig_.numLayers;
    const size_t hidden = internalConfig_.hiddenSize;
    const size_t inter = internalConfig_.intermediateSize;
    const size_t vocab = internalConfig_.vocabSize;

    // Embedding: ä½¿ç”¨å°å€¼åˆå§‹åŒ–
    // embedding_: [vocab, hidden]
    small_value_init(embedding_, 0.1f);
    
    // LM Head: ä½¿ç”¨Xavieråˆå§‹åŒ–
    // lmHead_: [hidden, vocab]
    xavier_init(lmHead_, hidden, vocab);
    
    // Final norm: åˆå§‹åŒ–ä¸º1
    finalNormWeight_.fill(1.0f);

    // æ¯å±‚æƒé‡ï¼šä½¿ç”¨Xavieråˆå§‹åŒ–ä»¥è·å¾—æ›´å¥½çš„æ•°å€¼ç¨³å®šæ€§
    for (size_t layer = 0; layer < numLayers; ++layer) {
        // Attentionæƒé‡: [hidden, hidden] æˆ– [hidden, qDim/kvDim]
        const auto& wqShape = wq_[layer].shape();
        const auto& wkShape = wk_[layer].shape();
        const auto& wvShape = wv_[layer].shape();
        const auto& woShape = wo_[layer].shape();
        
        if (wqShape.size() == 2) {
            xavier_init(wq_[layer], wqShape[0], wqShape[1]);
        } else {
            fill_tensor_with_pattern(wq_[layer], 0.1f);
        }
        
        if (wkShape.size() == 2) {
            xavier_init(wk_[layer], wkShape[0], wkShape[1]);
        } else {
            fill_tensor_with_pattern(wk_[layer], 0.1f);
        }
        
        if (wvShape.size() == 2) {
            xavier_init(wv_[layer], wvShape[0], wvShape[1]);
        } else {
            fill_tensor_with_pattern(wv_[layer], 0.1f);
        }
        
        if (woShape.size() == 2) {
            xavier_init(wo_[layer], woShape[0], woShape[1]);
        } else {
            fill_tensor_with_pattern(wo_[layer], 0.1f);
        }

        // FFNæƒé‡: [hidden, inter] æˆ– [inter, hidden]
        const auto& wGateShape = wGate_[layer].shape();
        const auto& wUpShape = wUp_[layer].shape();
        const auto& wDownShape = wDown_[layer].shape();
        
        if (wGateShape.size() == 2) {
            xavier_init(wGate_[layer], wGateShape[0], wGateShape[1]);
        } else {
            fill_tensor_with_pattern(wGate_[layer], 0.1f);
        }
        
        if (wUpShape.size() == 2) {
            xavier_init(wUp_[layer], wUpShape[0], wUpShape[1]);
        } else {
            fill_tensor_with_pattern(wUp_[layer], 0.1f);
        }
        
        if (wDownShape.size() == 2) {
            xavier_init(wDown_[layer], wDownShape[0], wDownShape[1]);
        } else {
            fill_tensor_with_pattern(wDown_[layer], 0.1f);
        }

        // RMSNorm æƒé‡åˆå§‹åŒ–ä¸º 1
        norm1_[layer].fill(1.0f);
        norm2_[layer].fill(1.0f);
    }

    CLLM_INFO("[KylinBackend] Placeholder weights initialized");
}

void KylinBackend::bindWeightsToModel() {
    CLLM_INFO("[KylinBackend] ===== bindWeightsToModel() START =====");
    CLLM_INFO("[KylinBackend] Binding weights to TransformerModel...");

    // éªŒè¯æƒé‡å½¢çŠ¶
    CLLM_INFO("[KylinBackend] Getting config values...");
    const size_t hidden = internalConfig_.hiddenSize;
    const size_t vocab = internalConfig_.vocabSize;
    const size_t numLayers = internalConfig_.numLayers;
    size_t numHeads = internalConfig_.numAttentionHeads;  // å¯èƒ½è¢«ä¿®æ­£
    
    if (numHeads == 0) {
        CLLM_ERROR("[KylinBackend] numHeads is 0!");
        throw std::runtime_error("numHeads is 0");
    }
    
    // ä»å®é™…æƒé‡å½¢çŠ¶æ¨æ–­ qDimã€kvDim å’Œ interï¼ˆæ”¯æŒ GQA å’Œä¸åŒçš„ FFN é…ç½®ï¼‰
    // é»˜è®¤å€¼ï¼šå‡è®¾ Q å’Œ KV ç»´åº¦ç›¸åŒ
    size_t qDim = hidden;
    size_t kvDim = hidden;
    size_t inter = internalConfig_.intermediateSize;
    
    // ä»ç¬¬ä¸€å±‚çš„æƒé‡å½¢çŠ¶æ¨æ–­
    if (numLayers > 0 && wq_[0].shape().size() == 2) {
        qDim = wq_[0].shape()[1];  // wq: [hidden, qDim]
        CLLM_INFO("[KylinBackend] ä»wqå½¢çŠ¶æ¨æ–­qDim: %zu", qDim);
    }
    if (numLayers > 0 && wk_[0].shape().size() == 2) {
        kvDim = wk_[0].shape()[1];  // wk: [hidden, kvDim]
        CLLM_INFO("[KylinBackend] ä»wkå½¢çŠ¶æ¨æ–­kvDim: %zu", kvDim);
    }
    // ä»ç¬¬ä¸€å±‚çš„ FFN æƒé‡å½¢çŠ¶æ¨æ–­ intermediateSize
    if (numLayers > 0 && wGate_[0].shape().size() == 2) {
        inter = wGate_[0].shape()[1];  // wGate: [hidden, inter]
        CLLM_INFO("[KylinBackend] ä»wGateå½¢çŠ¶æ¨æ–­intermediateSize: %zu", inter);
        // æ›´æ–°é…ç½®ï¼Œä»¥ä¾¿åç»­ä½¿ç”¨
        internalConfig_.intermediateSize = inter;
    }
    
    // P1ä¿®å¤ï¼šç¦ç”¨"æ ‡å‡†å…¬å¼æ¨æ–­ heads"è¦†ç›–æ¨¡å‹é…ç½®
    // ä½†æ˜¯ï¼Œå¦‚æœé…ç½®ä¸­çš„ numQHeads æ˜æ˜¾é”™è¯¯ï¼ˆå¯¼è‡´ Q/K head_dim ä¸ä¸€è‡´ï¼‰ï¼Œéœ€è¦ä¿®æ­£
    // æ ¹æ®å¯¹æ¯”æ–‡æ¡£ï¼Œllama.cpp çš„ Qwen3 å®ç°è¦æ±‚ Q/K head_dim ä¸€è‡´
    //
    // ç­–ç•¥ï¼š
    // 1. å…ˆè®¡ç®— qHeadDim = qDim / numHeads
    // 2. éªŒè¯ kvDim æ˜¯å¦èƒ½è¢« qHeadDim æ•´é™¤ï¼ˆQwen3 è¦æ±‚ Q/K head_dim ä¸€è‡´ï¼‰
    // 3. å¦‚æœä¸èƒ½æ•´é™¤ï¼Œè¯´æ˜é…ç½®çš„ numQHeads å¯èƒ½é”™è¯¯ï¼Œå°è¯•ä»æƒé‡æ¨æ–­æ­£ç¡®çš„å€¼
    
    size_t standardHeadDim = hidden / numHeads;  // æ ‡å‡† head_dimï¼ˆä»…ç”¨äºå¯¹æ¯”å’ŒéªŒè¯ï¼‰
    
    // éªŒè¯ qDim æ˜¯å¦èƒ½è¢« numHeads æ•´é™¤
    if (numHeads > 0 && qDim > 0) {
        if (qDim % numHeads != 0) {
            CLLM_ERROR("[KylinBackend] âŒ qDim (%zu) ä¸èƒ½è¢« numQHeads (%zu) æ•´é™¤ï¼Œé…ç½®æˆ–æƒé‡å¯èƒ½æœ‰é—®é¢˜",
                      qDim, numHeads);
            throw std::runtime_error("qDim must be divisible by numQHeads");
        }
        
        // è®¡ç®—å®é™…çš„ qHeadDimï¼ˆä»æƒé‡å½¢çŠ¶æ¨æ–­ï¼Œæ”¯æŒæ‰©å±• head_dimï¼‰
        size_t actualQHeadDim = qDim / numHeads;
        
        // P1ä¿®å¤å¢å¼ºï¼šéªŒè¯ Q/K head_dim ä¸€è‡´æ€§
        // llama.cpp è¦æ±‚ Q/K head_dim å¿…é¡»ä¸€è‡´ï¼ˆn_embd_head_v == n_embd_head_kï¼‰
        // å¦‚æœé…ç½®çš„ numQHeads å¯¼è‡´ Q/K head_dim ä¸ä¸€è‡´ï¼Œéœ€è¦æ¨æ–­æ­£ç¡®çš„å€¼
        if (kvDim > 0 && kvDim % actualQHeadDim != 0) {
            // é…ç½®çš„ numQHeads å¯¼è‡´ Q/K head_dim ä¸ä¸€è‡´ï¼Œå°è¯•æ¨æ–­æ­£ç¡®çš„å€¼
            // llama.cpp è¦æ±‚ Q/K head_dim å¿…é¡»ä¸€è‡´ï¼Œæ‰€ä»¥éœ€è¦æ‰¾åˆ°ä½¿å¾—ä¸¤è€…ä¸€è‡´çš„ numQHeads
            // ç­–ç•¥ï¼šæ‰¾åˆ°åŒæ—¶èƒ½è¢« qDim å’Œ kvDim æ•´é™¤çš„ head_dimï¼Œç„¶ååæ¨ numQHeads
            
            CLLM_WARN("[KylinBackend] âš ï¸ é…ç½®çš„ numQHeads (%zu) å¯¼è‡´ Q/K head_dim ä¸ä¸€è‡´ï¼šqHeadDim=%zu, kvDim=%zuï¼Œå°è¯•æ¨æ–­æ­£ç¡®çš„å€¼",
                     numHeads, actualQHeadDim, kvDim);
            
            // å°è¯•æ¨æ–­ï¼šæ‰¾åˆ°ä½¿å¾— Q å’Œ K çš„ head_dim ä¸€è‡´çš„ head_dim
            // å¸¸è§çš„ head_dim å€¼ï¼š64, 128, 256
            size_t inferredHeadDim = 0;
            size_t inferredNumQHeads = 0;
            
            for (size_t candidateHeadDim = 64; candidateHeadDim <= 256; candidateHeadDim *= 2) {
                if (qDim % candidateHeadDim == 0 && kvDim % candidateHeadDim == 0) {
                    size_t candidateNumQHeads = qDim / candidateHeadDim;
                    size_t candidateNumKVHeads = kvDim / candidateHeadDim;
                    // éªŒè¯ GQA çº¦æŸï¼šnumQHeads å¿…é¡»èƒ½è¢« numKVHeads æ•´é™¤
                    if (candidateNumQHeads > 0 && candidateNumKVHeads > 0 && 
                        candidateNumQHeads % candidateNumKVHeads == 0 &&
                        candidateNumQHeads <= 128) {  // åˆç†çš„ head æ•°é‡èŒƒå›´
                        inferredHeadDim = candidateHeadDim;
                        inferredNumQHeads = candidateNumQHeads;
                        break;
                    }
                }
            }
            
            if (inferredHeadDim > 0 && inferredNumQHeads != numHeads) {
                CLLM_WARN("[KylinBackend] âš ï¸ æ¨æ–­æ­£ç¡®çš„ numQHeads=%zu (qDim=%zu / headDim=%zu)ï¼ŒåŸé…ç½®ä¸º %zuï¼Œå°†æ›´æ–°é…ç½®",
                         inferredNumQHeads, qDim, inferredHeadDim, numHeads);
                internalConfig_.numAttentionHeads = inferredNumQHeads;
                numHeads = inferredNumQHeads;  // æ›´æ–°å±€éƒ¨å˜é‡
                actualQHeadDim = inferredHeadDim;  // æ›´æ–° actualQHeadDim
                standardHeadDim = hidden / numHeads;  // é‡æ–°è®¡ç®— standardHeadDim
            } else if (inferredHeadDim == 0) {
                CLLM_ERROR("[KylinBackend] âŒ æ— æ³•æ¨æ–­æ­£ç¡®çš„ numQHeadsï¼ŒQ/K head_dim ä¸ä¸€è‡´ï¼šqHeadDim=%zu (qDim=%zu / numQHeads=%zu), kvDim=%zu",
                          actualQHeadDim, qDim, numHeads, kvDim);
                throw std::runtime_error("Cannot infer correct numQHeads: Q/K head_dim inconsistent");
            }
        }
        
        // å¦‚æœ actualQHeadDim != standardHeadDimï¼Œè¯´æ˜ä½¿ç”¨äº†æ‰©å±• head_dimï¼ˆå¦‚ Qwen3ï¼‰
        if (actualQHeadDim != standardHeadDim) {
            size_t expansionFactor = actualQHeadDim / standardHeadDim;
            CLLM_INFO("[KylinBackend] âœ“ æ£€æµ‹åˆ°æ‰©å±• head_dimï¼šqHeadDim=%zu (æ ‡å‡†=%zu, æ‰©å±•å› å­=%zu)ï¼Œä½¿ç”¨é…ç½®çš„ numQHeads=%zu",
                     actualQHeadDim, standardHeadDim, expansionFactor, numHeads);
        } else {
            CLLM_INFO("[KylinBackend] âœ“ ä½¿ç”¨æ ‡å‡† head_dimï¼šqHeadDim=%zuï¼ŒnumQHeads=%zu",
                     actualQHeadDim, numHeads);
        }
    }
    
    // ä» kvDim æ¨æ–­ KV headsï¼ˆGQA æ”¯æŒï¼‰
    // å…³é”®ç‚¹ï¼šQwen3ï¼ˆllama.cpp å®ç°ï¼‰è¦æ±‚ Q/K çš„ head_dim ä¸€è‡´ï¼ˆn_embd_head_v == n_embd_head_kï¼‰ã€‚
    // åœ¨è¿™ç±»æ¨¡å‹ä¸­ï¼Œhead_dim ä¸èƒ½ç”¨ hidden/num_heads çš„â€œæ ‡å‡†å…¬å¼â€æ¨æ–­ï¼Œè€Œåº”ä»¥æŠ•å½±æƒé‡çš„å®é™…å½¢çŠ¶ä¸ºå‡†ã€‚
    // å› æ­¤ KV heads åº”è¯¥ä½¿ç”¨ qHeadDimFromWeights åæ¨ï¼šnumKVHeads = kvDim / qHeadDimFromWeightsã€‚
    size_t qHeadDimFromWeights = 0;
    if (internalConfig_.numAttentionHeads > 0 && qDim % internalConfig_.numAttentionHeads == 0) {
        qHeadDimFromWeights = qDim / internalConfig_.numAttentionHeads;
    }

    // P1ä¿®å¤ï¼šéªŒè¯ kvDim æ˜¯å¦èƒ½è¢« qHeadDim æ•´é™¤ï¼ˆQwen3 è¦æ±‚ Q/K head_dim ä¸€è‡´ï¼‰
    // ä¼˜å…ˆç›¸ä¿¡é…ç½®ä¸­çš„ numKeyValueHeadsï¼Œåªåœ¨é…ç½®ä¸åˆç†æ—¶æ‰æ¨æ–­
    bool kvHeadsInferred = false;
    if (qHeadDimFromWeights > 0 && kvDim > 0) {
        if (kvDim % qHeadDimFromWeights != 0) {
            CLLM_ERROR("[KylinBackend] âŒ kvDim (%zu) ä¸èƒ½è¢« qHeadDim (%zu) æ•´é™¤ï¼ŒQ/K head_dim ä¸ä¸€è‡´ï¼",
                      kvDim, qHeadDimFromWeights);
            throw std::runtime_error("kvDim must be divisible by qHeadDim (Qwen3 requires Q/K head_dim to be consistent)");
        }
        
        size_t inferredNumKVHeads = kvDim / qHeadDimFromWeights;
        if (inferredNumKVHeads > 0 &&
            inferredNumKVHeads <= internalConfig_.numAttentionHeads &&
            (internalConfig_.numAttentionHeads % inferredNumKVHeads == 0)) {
            size_t configKVHeadDim = 0;
            if (internalConfig_.numKeyValueHeads > 0 && kvDim % internalConfig_.numKeyValueHeads == 0) {
                configKVHeadDim = kvDim / internalConfig_.numKeyValueHeads;
            }
            // å¦‚æœé…ç½®ä¸åˆç†æˆ–å¯¼è‡´ Q/K head_dim ä¸ä¸€è‡´ï¼Œä½¿ç”¨æ¨æ–­å€¼
            if (internalConfig_.numKeyValueHeads == 0 ||
                internalConfig_.numKeyValueHeads > internalConfig_.numAttentionHeads ||
                configKVHeadDim != qHeadDimFromWeights) {
                CLLM_WARN("[KylinBackend] âš ï¸ é…ç½®çš„ numKVHeads=%zu å¯¼è‡´ kvHeadDim=%zuï¼Œä¸ qHeadDim=%zu ä¸ä¸€è‡´ï¼Œæ”¹ä¸º %zu",
                         internalConfig_.numKeyValueHeads, configKVHeadDim, qHeadDimFromWeights, inferredNumKVHeads);
                internalConfig_.numKeyValueHeads = inferredNumKVHeads;
                kvHeadsInferred = true;
            } else {
                CLLM_INFO("[KylinBackend] âœ“ KV heads é…ç½®ä¸æƒé‡ä¸€è‡´ï¼šnumKVHeads=%zu, kvHeadDim=%zu",
                         internalConfig_.numKeyValueHeads, qHeadDimFromWeights);
                kvHeadsInferred = true;
            }
        } else {
            CLLM_ERROR("[KylinBackend] âŒ æ¨æ–­å‡ºçš„ numKVHeads=%zu ä¸åˆæ³•ï¼ˆnumQHeads=%zuï¼‰",
                      inferredNumKVHeads, internalConfig_.numAttentionHeads);
            throw std::runtime_error("Invalid inferred numKVHeads");
        }
    }

    if (!kvHeadsInferred && (internalConfig_.numKeyValueHeads == 0 ||
                             internalConfig_.numKeyValueHeads > internalConfig_.numAttentionHeads)) {
        // å¦‚æœæ¨æ–­å¤±è´¥æˆ–é…ç½®ä¸åˆç†ï¼Œé»˜è®¤ç­‰äº Q headsï¼ˆMHAï¼‰
        internalConfig_.numKeyValueHeads = internalConfig_.numAttentionHeads;
        CLLM_INFO("[KylinBackend] è®¾ç½® numKeyValueHeads = numAttentionHeads = %zu (MHA)",
                 internalConfig_.numAttentionHeads);
    }
    
    // ä½¿ç”¨æ›´æ–°åçš„é…ç½®
    const size_t actualNumHeads = internalConfig_.numAttentionHeads;
    const size_t actualNumKVHeads = internalConfig_.numKeyValueHeads;
    
    // W1ä¿®å¤ï¼šä½¿ç”¨å®é™…çš„ qHeadDim å’Œ kvHeadDimï¼Œè€Œä¸æ˜¯æ ‡å‡†å…¬å¼è®¡ç®—çš„ headDim
    // å®é™…çš„ head_dim åº”è¯¥ä»æƒé‡å½¢çŠ¶æ¨æ–­ï¼Œè€Œä¸æ˜¯å‡è®¾ headDim = hidden / numHeads
    const size_t actualQHeadDim = (actualNumHeads > 0) ? (qDim / actualNumHeads) : (hidden / actualNumHeads);
    const size_t actualKVHeadDim = (actualNumKVHeads > 0) ? (kvDim / actualNumKVHeads) : (hidden / actualNumKVHeads);
    // é‡æ–°è®¡ç®— standardHeadDimï¼ˆåŸºäºæ›´æ–°åçš„ actualNumHeadsï¼‰
    standardHeadDim = hidden / actualNumHeads;  // æ ‡å‡†å…¬å¼ï¼ˆä»…ç”¨äºå¯¹æ¯”ï¼‰
    
    CLLM_INFO("[KylinBackend] éªŒè¯æƒé‡å½¢çŠ¶: hidden=%zu, vocab=%zu, numLayers=%zu, numQHeads=%zu, numKVHeads=%zu, actualQHeadDim=%zu, actualKVHeadDim=%zu, standardHeadDim=%zu, qDim=%zu, kvDim=%zu, inter=%zu",
             hidden, vocab, numLayers, actualNumHeads, actualNumKVHeads, actualQHeadDim, actualKVHeadDim, standardHeadDim, qDim, kvDim, inter);
    
    // éªŒè¯ head æ•°é‡çš„ä¸€è‡´æ€§ï¼ˆä½¿ç”¨å®é™…çš„ head_dimï¼‰
    // ä¿®å¤ï¼šåº”è¯¥ä½¿ç”¨å®é™…çš„ head_dim è¿›è¡ŒéªŒè¯ï¼Œä¸åº”è¯¥å†å‡ºç°ç»´åº¦ä¸åŒ¹é…çš„è­¦å‘Šï¼ˆé™¤éçœŸçš„æœ‰é—®é¢˜ï¼‰
    if (qDim != actualNumHeads * actualQHeadDim) {
        CLLM_WARN("[KylinBackend] âš ï¸ qDim (%zu) != numQHeads * actualQHeadDim (%zu * %zu = %zu)ï¼Œç»´åº¦ä¸åŒ¹é…ï¼",
                 qDim, actualNumHeads, actualQHeadDim, actualNumHeads * actualQHeadDim);
    } else if (actualQHeadDim != standardHeadDim) {
        // å¦‚æœ qDim ä¸æ ‡å‡†å…¬å¼ä¸åŒï¼Œè¯´æ˜ä½¿ç”¨äº†æ‰©å±• head_dimï¼ˆè¿™æ˜¯æ­£å¸¸çš„ï¼Œæ¯”å¦‚ Qwen3ï¼‰
        size_t expansionFactor = actualQHeadDim / standardHeadDim;
        CLLM_INFO("[KylinBackend] âœ“ æ£€æµ‹åˆ°æ‰©å±• head_dimï¼šQ head_dim=%zu (æ ‡å‡†=%zu, æ‰©å±•å› å­=%zu)ï¼Œç»´åº¦åŒ¹é…",
                 actualQHeadDim, standardHeadDim, expansionFactor);
    } else {
        CLLM_INFO("[KylinBackend] âœ“ Q ç»´åº¦åŒ¹é…ï¼šqDim=%zu = numQHeads * headDim (%zu * %zu)",
                 qDim, actualNumHeads, actualQHeadDim);
    }
    if (kvDim != actualNumKVHeads * actualKVHeadDim) {
        CLLM_WARN("[KylinBackend] âš ï¸ kvDim (%zu) != numKVHeads * actualKVHeadDim (%zu * %zu = %zu)ï¼Œç»´åº¦ä¸åŒ¹é…ï¼",
                 kvDim, actualNumKVHeads, actualKVHeadDim, actualNumKVHeads * actualKVHeadDim);
    } else if (actualKVHeadDim != standardHeadDim) {
        // å¦‚æœ kvDim ä¸æ ‡å‡†å…¬å¼ä¸åŒï¼Œè¯´æ˜ä½¿ç”¨äº†ä¸åŒçš„ head_dimï¼ˆè¿™æ˜¯æ­£å¸¸çš„ï¼‰
        CLLM_INFO("[KylinBackend] âœ“ KV head_dim=%zu (æ ‡å‡†=%zu)ï¼Œç»´åº¦åŒ¹é…",
                 actualKVHeadDim, standardHeadDim);
    } else {
        CLLM_INFO("[KylinBackend] âœ“ KV ç»´åº¦åŒ¹é…ï¼škvDim=%zu = numKVHeads * headDim (%zu * %zu)",
                 kvDim, actualNumKVHeads, actualKVHeadDim);
    }
    
    if (hidden == 0 || vocab == 0 || numLayers == 0 || inter == 0) {
        CLLM_ERROR("[KylinBackend] Invalid config values!");
        throw std::runtime_error("Invalid config values");
    }
    
    // éªŒè¯embeddingå½¢çŠ¶
    if (embedding_.shape().size() != 2) {
        CLLM_ERROR("[KylinBackend] Embedding shape invalid: expected 2D, got %zuD", embedding_.shape().size());
        throw std::runtime_error("Embedding shape mismatch");
    }
    if (embedding_.shape()[0] != vocab || embedding_.shape()[1] != hidden) {
        CLLM_ERROR("[KylinBackend] Embedding shape mismatch: expected [%zu, %zu], got [%zu, %zu]",
                  vocab, hidden, embedding_.shape()[0], embedding_.shape()[1]);
        throw std::runtime_error("Embedding shape mismatch");
    }
    CLLM_INFO("[KylinBackend] Embedding shape: [%zu, %zu] âœ“", embedding_.shape()[0], embedding_.shape()[1]);
    
    // éªŒè¯lmHeadå½¢çŠ¶
    if (lmHead_.shape().size() != 2) {
        CLLM_ERROR("[KylinBackend] LMHead shape invalid: expected 2D, got %zuD", lmHead_.shape().size());
        throw std::runtime_error("LMHead shape mismatch");
    }
    if (lmHead_.shape()[0] != hidden || lmHead_.shape()[1] != vocab) {
        CLLM_ERROR("[KylinBackend] LMHead shape mismatch: expected [%zu, %zu], got [%zu, %zu]",
                  hidden, vocab, lmHead_.shape()[0], lmHead_.shape()[1]);
        throw std::runtime_error("LMHead shape mismatch");
    }
    CLLM_INFO("[KylinBackend] LMHead shape: [%zu, %zu] âœ“", lmHead_.shape()[0], lmHead_.shape()[1]);
    
    // éªŒè¯å±‚æƒé‡å½¢çŠ¶
    for (size_t layer = 0; layer < numLayers; ++layer) {
        if (wq_[layer].shape().size() != 2) {
            CLLM_ERROR("[KylinBackend] Layer %zu wq shape invalid: expected 2D", layer);
            throw std::runtime_error("Layer weight shape mismatch");
        }
        
        // éªŒè¯wqå½¢çŠ¶: æœŸæœ› [hidden, qDim]
        if (wq_[layer].shape()[0] != hidden || wq_[layer].shape()[1] != qDim) {
            CLLM_ERROR("[KylinBackend] Layer %zu wq shape mismatch: expected [%zu, %zu], got [%zu, %zu]",
                      layer, hidden, qDim, wq_[layer].shape()[0], wq_[layer].shape()[1]);
            throw std::runtime_error("Layer wq shape mismatch");
        }
        
        // éªŒè¯wk/wvå½¢çŠ¶: æœŸæœ› [hidden, kvDim] (æ”¯æŒGQAï¼ŒKVç»´åº¦å¯èƒ½ä¸åŒäºQ)
        if (wk_[layer].shape()[0] != hidden || wk_[layer].shape()[1] != kvDim) {
            CLLM_ERROR("[KylinBackend] Layer %zu wk shape mismatch: expected [%zu, %zu], got [%zu, %zu]",
                      layer, hidden, kvDim, wk_[layer].shape()[0], wk_[layer].shape()[1]);
            throw std::runtime_error("Layer wk shape mismatch");
        }
        if (wv_[layer].shape()[0] != hidden || wv_[layer].shape()[1] != kvDim) {
            CLLM_ERROR("[KylinBackend] Layer %zu wv shape mismatch: expected [%zu, %zu], got [%zu, %zu]",
                      layer, hidden, kvDim, wv_[layer].shape()[0], wv_[layer].shape()[1]);
            throw std::runtime_error("Layer wv shape mismatch");
        }
        
        // éªŒè¯woå½¢çŠ¶: æœŸæœ› [qDim, hidden]
        if (wo_[layer].shape()[0] != qDim || wo_[layer].shape()[1] != hidden) {
            CLLM_ERROR("[KylinBackend] Layer %zu wo shape mismatch: expected [%zu, %zu], got [%zu, %zu]",
                      layer, qDim, hidden, wo_[layer].shape()[0], wo_[layer].shape()[1]);
            throw std::runtime_error("Layer wo shape mismatch");
        }
        
        // éªŒè¯FFNæƒé‡å½¢çŠ¶
        if (wGate_[layer].shape()[0] != hidden || wGate_[layer].shape()[1] != inter) {
            CLLM_ERROR("[KylinBackend] Layer %zu wGate shape mismatch: expected [%zu, %zu], got [%zu, %zu]",
                      layer, hidden, inter, wGate_[layer].shape()[0], wGate_[layer].shape()[1]);
            throw std::runtime_error("Layer wGate shape mismatch");
        }
        if (wUp_[layer].shape()[0] != hidden || wUp_[layer].shape()[1] != inter) {
            CLLM_ERROR("[KylinBackend] Layer %zu wUp shape mismatch: expected [%zu, %zu], got [%zu, %zu]",
                      layer, hidden, inter, wUp_[layer].shape()[0], wUp_[layer].shape()[1]);
            throw std::runtime_error("Layer wUp shape mismatch");
        }
        if (wDown_[layer].shape()[0] != inter || wDown_[layer].shape()[1] != hidden) {
            CLLM_ERROR("[KylinBackend] Layer %zu wDown shape mismatch: expected [%zu, %zu], got [%zu, %zu]",
                      layer, inter, hidden, wDown_[layer].shape()[0], wDown_[layer].shape()[1]);
            throw std::runtime_error("Layer wDown shape mismatch");
        }
        
        CLLM_DEBUG("[KylinBackend] Layer %zu: wq[%zu, %zu], wk[%zu, %zu], wv[%zu, %zu], wo[%zu, %zu] âœ“",
                   layer,
                   wq_[layer].shape()[0], wq_[layer].shape()[1],
                   wk_[layer].shape()[0], wk_[layer].shape()[1],
                   wv_[layer].shape()[0], wv_[layer].shape()[1],
                   wo_[layer].shape()[0], wo_[layer].shape()[1]);
    }

    // é‡å»ºæ¨¡å‹ï¼ˆä½¿ç”¨å½“å‰é…ç½®ï¼‰
    model_ = kylin::TransformerModel(internalConfig_);

    // ç»‘å®š Embedding å’Œ LM Head
    model_.setEmbeddingWeight(embedding_);
    CLLM_INFO("[KylinBackend] Binding LM head...");
    model_.setLmHeadWeight(lmHead_);
    CLLM_INFO("[KylinBackend] LM head bound");

    // ç»‘å®šæ¯å±‚æƒé‡
    for (size_t layer = 0; layer < numLayers; ++layer) {
        CLLM_INFO("[KylinBackend] Binding layer %zu weights...", layer);
        // æ£€æŸ¥æ˜¯å¦æœ‰ Q/K å½’ä¸€åŒ–æƒé‡
        kylin::Tensor attnQNorm = attnQNorm_[layer].shape().empty() ? kylin::Tensor() : attnQNorm_[layer];
        kylin::Tensor attnKNorm = attnKNorm_[layer].shape().empty() ? kylin::Tensor() : attnKNorm_[layer];
        
        model_.setBlockWeights(
            layer,
            wq_[layer],
            wk_[layer],
            wv_[layer],
            wo_[layer],
            wGate_[layer],
            wUp_[layer],
            wDown_[layer],
            norm1_[layer],
            norm2_[layer],
            attnQNorm,  // Q å½’ä¸€åŒ–æƒé‡ï¼ˆå¯é€‰ï¼‰
            attnKNorm   // K å½’ä¸€åŒ–æƒé‡ï¼ˆå¯é€‰ï¼‰
        );
        CLLM_INFO("[KylinBackend] Layer %zu weights bound", layer);
    }

    // ç»‘å®š Final Norm
    model_.setFinalNormWeight(finalNormWeight_);

    CLLM_INFO("[KylinBackend] Weights bound to model successfully");
}

kylin::Tensor KylinBackend::forward(const std::vector<int> &inputIds) {
    if (!initialized_) {
        throw std::runtime_error("KylinBackend::forward: backend not initialized");
    }
    if (inputIds.empty()) {
        throw std::invalid_argument("KylinBackend::forward: empty inputIds");
    }
    const size_t vocabSize = externalConfig_.vocabSize;
    if (vocabSize == 0) {
        throw std::runtime_error("KylinBackend::forward: vocabSize is 0");
    }
    for (int id : inputIds) {
        if (id < 0 || static_cast<size_t>(id) >= vocabSize) {
            throw std::out_of_range("KylinBackend::forward: token id out of range");
        }
    }

    // ========== HuggingFace æ¨¡å‹ ==========
    if (useHFModel_ && hfModel_) {
        const size_t seqLen = inputIds.size();
        
        CLLM_DEBUG("[KylinBackend::forward] HF mode: seqLen=%zu, vocabSize=%zu", seqLen, vocabSize);
        
        // HFTransformerModel åªè¿”å›æœ€åä¸€ä¸ª token çš„ logits (vocab_size ä¸ªå…ƒç´ )
        // å¯¹äºè‡ªå›å½’ç”Ÿæˆï¼Œè¿™æ˜¯æ­£ç¡®çš„è¡Œä¸º
        // å¯¹äº prefillï¼ˆseq_len > 1ï¼‰ï¼Œéœ€è¦é€ token å¤„ç†ä»¥æ­£ç¡®æ„å»º KV cache
        
        if (seqLen == 1) {
            // å• token æ¨ç†ï¼ˆå¢é‡ç”Ÿæˆï¼‰ï¼šç›´æ¥è°ƒç”¨ forwardï¼ŒKV cache ä¼šè‡ªåŠ¨ç´¯ç§¯
            std::vector<int32_t> inputIds32(inputIds.begin(), inputIds.end());
            std::vector<float> logitsFlat = hfModel_->forward(inputIds32);
            
            kylin::Tensor result({1, vocabSize});
            std::copy(logitsFlat.begin(), logitsFlat.end(), result.data());
            return result;
        } else {
            // å¤š token æ¨ç†ï¼ˆprefillï¼‰ï¼šæ¸…é™¤ KV cache å¹¶é€ token å¤„ç†
            // ä½¿ç”¨ requestId = 0 ä½œä¸ºé»˜è®¤è¯·æ±‚
            hfModel_->releaseKVCache(0);
            CLLM_DEBUG("[KylinBackend::forward] Prefill: seqLen=%zu, reset KV cache", seqLen);
            
            // é€ token å¤„ç†ä»¥æ­£ç¡®æ„å»º KV cache
            kylin::Tensor result({seqLen, vocabSize});
            std::fill(result.data(), result.data() + seqLen * vocabSize, 0.0f);
            
            for (size_t i = 0; i < seqLen; ++i) {
                std::vector<int32_t> singleToken = {static_cast<int32_t>(inputIds[i])};
                std::vector<float> logits = hfModel_->forward(singleToken);
                
                // å¤åˆ¶å½“å‰ token çš„ logits åˆ°ç»“æœä¸­
                std::copy(logits.begin(), logits.end(), 
                         result.data() + i * vocabSize);
            }
            
            return result;
        }
    }

    // ========== GGML ç›´æ¥æ¨ç†æ¨¡å¼ ==========
    if (useGGMLDirect_ && ggmlModel_) {
        // æ³¨æ„ï¼šç‹¬ç«‹çš„ forward() è°ƒç”¨ï¼ˆéé€šè¿‡ forwardBatchï¼‰
        // æ ¹æ®è¾“å…¥é•¿åº¦åˆ¤æ–­æ˜¯å¦éœ€è¦æ¸…é™¤ KV cacheï¼š
        // - å¦‚æœ inputIds.size() > 1ï¼Œè¯´æ˜æ˜¯æ–°è¯·æ±‚çš„ promptï¼Œæ¸…é™¤ KV cache
        // - å¦‚æœ inputIds.size() == 1ï¼Œå¯èƒ½æ˜¯å¢é‡ç”Ÿæˆï¼Œä¿ç•™ KV cache
        // è¿™ä¸ªå¯å‘å¼æ–¹æ³•ä¸å®Œç¾ï¼Œä½†åœ¨æ²¡æœ‰ sequenceId ä¿¡æ¯æ—¶æ˜¯åˆç†çš„é»˜è®¤è¡Œä¸º
        if (inputIds.size() > 1) {
            ggmlModel_->clearKVCache();
            currentSequenceId_ = SIZE_MAX;  // é‡ç½®åºåˆ— ID
            CLLM_DEBUG("[KylinBackend] Cleared KV cache for new prompt (len=%zu)", inputIds.size());
        }
        
        // è½¬æ¢ int åˆ° int32_t
        std::vector<int32_t> inputIds32(inputIds.begin(), inputIds.end());
        
        // ä½¿ç”¨ GGMLTransformerModel æ¨ç†
        std::vector<float> logitsFlat = ggmlModel_->forward(inputIds32);
        
        // è½¬æ¢ä¸º kylin::Tensor
        const size_t seqLen = inputIds.size();
        const size_t vocabSize = externalConfig_.vocabSize;
        kylin::Tensor result({seqLen, vocabSize});
        std::copy(logitsFlat.begin(), logitsFlat.end(), result.data());
        
        return result;
    }
    
    // ========== TransformerModel æ¨¡å¼ ==========
    return model_.forward(inputIds);
}

kylin::Tensor KylinBackend::forwardBatch(
    const std::vector<int> &flatInputIds,
    const std::vector<std::pair<size_t, size_t>> &requestPositions,
    size_t batchSize,
    const std::vector<size_t> &sequenceIds
) {
    // sequenceIds å‚æ•°æœªä½¿ç”¨ï¼ˆKylinBackend ä¸éœ€è¦åºåˆ—IDç®¡ç†ï¼‰
    (void)sequenceIds;
    if (!initialized_) {
        throw std::runtime_error("KylinBackend::forwardBatch: backend not initialized");
    }

    if (batchSize == 0) {
        throw std::invalid_argument("KylinBackend::forwardBatch: batchSize == 0");
    }
    if (requestPositions.size() != batchSize) {
        throw std::invalid_argument("KylinBackend::forwardBatch: requestPositions size mismatch");
    }

    const size_t totalTokens = flatInputIds.size();
    const size_t vocab = externalConfig_.vocabSize;

    if (totalTokens == 0) {
        throw std::invalid_argument("KylinBackend::forwardBatch: empty flatInputIds");
    }

    // åˆ†é…è¾“å‡ºå¼ é‡
    kylin::Tensor logits({totalTokens, vocab});
    
    // ========== HuggingFace æ¨¡å‹ ==========
    if (useHFModel_ && hfModel_) {
        // ä½¿ç”¨ per-request KV Cache å®ç°çœŸæ­£çš„å¹¶å‘
        CLLM_DEBUG("[KylinBackend] HuggingFace mode: processing %zu requests with per-request KV cache", batchSize);
        
        // ä¼˜åŒ–ï¼šå¦‚æœæ‰€æœ‰è¯·æ±‚éƒ½æ˜¯å• token æ¨ç†ï¼Œä½¿ç”¨ GPU æ‰¹å¤„ç†åŠ é€Ÿ
        bool allSingleToken = true;
        std::vector<int> singleTokenIds;
        std::vector<int> positions;
        std::vector<size_t> requestIds;
        
        // æ£€æŸ¥æ˜¯å¦æ‰€æœ‰è¯·æ±‚éƒ½æ˜¯å• token
        for (size_t i = 0; i < batchSize; ++i) {
            const auto &pos = requestPositions[i];
            const size_t start = pos.first;
            const size_t end = pos.second;
            
            if (start > end || end > totalTokens) {
                CLLM_ERROR("[KylinBackend] Invalid requestPositions range for request %zu", i);
                continue;
            }
            
            const size_t reqLen = end - start;
            size_t requestId = (i < sequenceIds.size()) ? sequenceIds[i] : i;
            
            if (reqLen == 1) {
                singleTokenIds.push_back(flatInputIds[start]);
                positions.push_back(hfModel_->getKVCacheCurrentLength(requestId)); // è·å–å½“å‰ä½ç½®
                requestIds.push_back(requestId);
            } else {
                // æœ‰å¤š token è¯·æ±‚ï¼Œä¸èƒ½ä½¿ç”¨ GPU æ‰¹å¤„ç†
                allSingleToken = false;
                break;
            }
        }
        
        // ä½¿ç”¨ forwardWithRequestId ä»¥ç¡®ä¿æ­£ç¡®çš„ per-request KV Cache ç®¡ç†
        // æ³¨ï¼šGPU æ‰¹å¤„ç†å·²ç¦ç”¨ï¼Œå› ä¸º GGMLGPUBackend::forwardGraphMinimal æ²¡æœ‰ per-request KV Cache æ”¯æŒ
        {
             // æ··åˆè¯·æ±‚æˆ–æœ‰å¤šä¸ª token çš„è¯·æ±‚ï¼Œä½¿ç”¨åŸæ¥çš„å¤„ç†æ–¹å¼
             #pragma omp parallel for schedule(dynamic) if(batchSize > 1)
             for (size_t i = 0; i < batchSize; ++i) {
                 const auto &pos = requestPositions[i];
                 const size_t start = pos.first;
                 const size_t end = pos.second;

                 if (start > end || end > totalTokens) {
                     CLLM_ERROR("[KylinBackend] Invalid requestPositions range for request %zu", i);
                     continue;
                 }
                 
                 // è·å–è¯·æ±‚ IDï¼ˆç”¨äº per-request KV Cacheï¼‰
                 size_t requestId = (i < sequenceIds.size()) ? sequenceIds[i] : i;
                 
                 const size_t reqLen = end - start;
                 
                 // ğŸ”¥ å…³é”®ä¼˜åŒ–ï¼šä½¿ç”¨æ‰¹é‡ prefillï¼Œä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰ tokens
                 // CPUBackend::forward ç°åœ¨æ”¯æŒå¤š token è¾“å…¥
                 if (reqLen > 1) {
                     // æ–°è¯·æ±‚ï¼ˆå¤š tokenï¼‰ï¼šå…ˆé‡Šæ”¾æ—§çš„ KV Cache
                     hfModel_->releaseKVCache(requestId);
                 }
                 
                 // ä¸€æ¬¡æ€§ä¼ å…¥æ‰€æœ‰ tokensï¼ˆå• token æˆ–å¤š tokenï¼‰
                 std::vector<int32_t> allTokens(flatInputIds.begin() + start, flatInputIds.begin() + end);
                 std::vector<float> requestLogits = hfModel_->forwardWithRequestId(allTokens, requestId);
                 
                 // å¤åˆ¶æœ€åä¸€ä¸ª token çš„ logits åˆ°è¾“å‡º
                 // å¯¹äºå¤š token è¾“å…¥ï¼Œåªè¿”å›æœ€åä¸€ä¸ª token çš„ logits
                 std::copy(requestLogits.begin(), requestLogits.end(), 
                          logits.data() + (end - 1) * vocab);
             }
        }
        
        return logits;
    }
    
    // ========== GGML ç›´æ¥æ¨ç†æ¨¡å¼ ==========
    if (useGGMLDirect_ && ggmlModel_) {
        // GGML æ¨¡å¼ï¼šé€è¯·æ±‚æ¨ç†ï¼ˆæš‚ä¸æ”¯æŒçœŸæ­£çš„æ‰¹å¤„ç†ï¼‰
        // ç”±äº GGMLTransformerModel åªæœ‰ä¸€ä¸ªå…¨å±€ KV cacheï¼Œä¸æ”¯æŒå¤šåºåˆ—å¹¶å‘
        // æˆ‘ä»¬ä½¿ç”¨ sequenceId æ¥ç®¡ç† KV cacheï¼š
        // - å¦‚æœ sequenceId ä¸å½“å‰åºåˆ—ä¸åŒï¼Œè¯´æ˜æ˜¯æ–°è¯·æ±‚ï¼Œæ¸…é™¤ KV cache
        // - å¦‚æœ sequenceId ç›¸åŒï¼Œè¯´æ˜æ˜¯åŒä¸€åºåˆ—çš„å¢é‡ç”Ÿæˆï¼Œä¿ç•™ KV cache
        CLLM_DEBUG("[KylinBackend] GGML direct mode: processing %zu requests sequentially", batchSize);
        
        for (size_t i = 0; i < batchSize; ++i) {
            const auto &pos = requestPositions[i];
            const size_t start = pos.first;
            const size_t end = pos.second;

            if (start > end || end > totalTokens) {
                throw std::out_of_range("KylinBackend::forwardBatch: invalid requestPositions range");
            }
            
            // è·å–å½“å‰è¯·æ±‚çš„åºåˆ—ID
            size_t seqId = (i < sequenceIds.size()) ? sequenceIds[i] : SIZE_MAX;
            const size_t reqLen = end - start;
            
            // KV cache ç®¡ç†ï¼š
            // 1. å¦‚æœåºåˆ—IDå˜åŒ–ï¼Œæ¸…é™¤ KV cacheï¼ˆæ–°è¯·æ±‚ï¼‰
            // 2. å¦‚æœè¾“å…¥é•¿åº¦ > 1ï¼Œä¹Ÿæ¸…é™¤ KV cacheï¼ˆæ–° promptï¼‰
            bool needClearCache = (seqId != currentSequenceId_) || (reqLen > 1);
            
            if (needClearCache) {
                ggmlModel_->clearKVCache();
                currentSequenceId_ = seqId;
                CLLM_DEBUG("[KylinBackend] Cleared KV cache for sequence %zu (prev=%zu, reqLen=%zu)", 
                          seqId, currentSequenceId_, reqLen);
            } else {
                CLLM_DEBUG("[KylinBackend] Reusing KV cache for sequence %zu (reqLen=%zu)", 
                          seqId, reqLen);
            }
            
            // æå–å½“å‰è¯·æ±‚çš„ token IDs
            std::vector<int32_t> requestIds32(flatInputIds.begin() + start, flatInputIds.begin() + end);
            
            // æ¨ç†
            std::vector<float> requestLogits = ggmlModel_->forward(requestIds32);
            
            // å¤åˆ¶åˆ°è¾“å‡º
            std::copy(requestLogits.begin(), requestLogits.end(), 
                     logits.data() + start * vocab);
        }
        
        return logits;
    }

    // ========== TransformerModel æ¨¡å¼ ==========
    // é€è¯·æ±‚è°ƒç”¨ forwardï¼Œå¹¶æ‹¼æ¥ç»“æœ
    for (size_t i = 0; i < batchSize; ++i) {
        const auto &pos = requestPositions[i];
        const size_t start = pos.first;
        const size_t end = pos.second;

        if (start > end || end > totalTokens) {
            throw std::out_of_range("KylinBackend::forwardBatch: invalid requestPositions range");
        }

        if (start == end) {
            continue; // ç©ºè¯·æ±‚ï¼Œè·³è¿‡
        }

        // æå–å½“å‰è¯·æ±‚çš„è¾“å…¥
        std::vector<int> inputIds(
            flatInputIds.begin() + static_cast<std::ptrdiff_t>(start),
            flatInputIds.begin() + static_cast<std::ptrdiff_t>(end)
        );

        // æ¨ç†
        kylin::Tensor requestLogits = forward(inputIds); // [len, vocab]

        const size_t len = end - start;
        if (requestLogits.shape().size() != 2 ||
            requestLogits.shape()[0] != len ||
            requestLogits.shape()[1] != vocab) {
            throw std::runtime_error("KylinBackend::forwardBatch: request logits shape mismatch");
        }

        // æ‹·è´åˆ°è¾“å‡ºå¼ é‡
        const float *src = requestLogits.data();
        float *dst = logits.data();

        for (size_t t = 0; t < len; ++t) {
            size_t globalRow = start + t;
            size_t srcOffset = t * vocab;
            size_t dstOffset = globalRow * vocab;
            for (size_t v = 0; v < vocab; ++v) {
                dst[dstOffset + v] = src[srcOffset + v];
            }
        }
    }

    return logits;
}

bool KylinBackend::loadFromModelWeights(const model::ModelWeights &weights) {
    CLLM_INFO("[KylinBackend] Loading weights from ModelWeights");
    
    try {
        const size_t numLayers = weights.layers.size();
        if (numLayers == 0) {
            CLLM_ERROR("[KylinBackend] No layers found in ModelWeights");
            return false;
        }
        
        // æ›´æ–°å†…éƒ¨é…ç½®
        internalConfig_.numLayers = numLayers;
        internalConfig_.vocabSize = weights.embedding.shape[0];
        internalConfig_.hiddenSize = weights.embedding.shape[1];
        
        // ç¡®ä¿æƒé‡å®¹å™¨å¤§å°æ­£ç¡®
        wq_.resize(numLayers);
        wk_.resize(numLayers);
        wv_.resize(numLayers);
        wo_.resize(numLayers);
        wGate_.resize(numLayers);
        wUp_.resize(numLayers);
        wDown_.resize(numLayers);
        norm1_.resize(numLayers);
        norm2_.resize(numLayers);
        attnQNorm_.resize(numLayers);
        attnKNorm_.resize(numLayers);
        
        // åŠ è½½embeddingæƒé‡
        embedding_ = Tensor(weights.embedding.shape);
        std::copy(weights.embedding.data.begin(), weights.embedding.data.end(), embedding_.data());
        
        // åŠ è½½lmHeadæƒé‡
        lmHead_ = Tensor(weights.lmHead.shape);
        std::copy(weights.lmHead.data.begin(), weights.lmHead.data.end(), lmHead_.data());
        
        // åŠ è½½finalNormæƒé‡
        finalNormWeight_ = Tensor(weights.finalNorm.shape);
        std::copy(weights.finalNorm.data.begin(), weights.finalNorm.data.end(), finalNormWeight_.data());
        
        // åŠ è½½æ¯å±‚çš„æƒé‡
        for (size_t layer = 0; layer < numLayers; ++layer) {
            const model::LayerWeights &layerWeights = weights.layers[layer];
            
            // Attentionæƒé‡
            wq_[layer] = Tensor(layerWeights.wq.shape);
            std::copy(layerWeights.wq.data.begin(), layerWeights.wq.data.end(), wq_[layer].data());
            
            wk_[layer] = Tensor(layerWeights.wk.shape);
            std::copy(layerWeights.wk.data.begin(), layerWeights.wk.data.end(), wk_[layer].data());
            
            wv_[layer] = Tensor(layerWeights.wv.shape);
            std::copy(layerWeights.wv.data.begin(), layerWeights.wv.data.end(), wv_[layer].data());
            
            wo_[layer] = Tensor(layerWeights.wo.shape);
            std::copy(layerWeights.wo.data.begin(), layerWeights.wo.data.end(), wo_[layer].data());
            
            // FFNæƒé‡
            wGate_[layer] = Tensor(layerWeights.wGate.shape);
            std::copy(layerWeights.wGate.data.begin(), layerWeights.wGate.data.end(), wGate_[layer].data());
            
            wUp_[layer] = Tensor(layerWeights.wUp.shape);
            std::copy(layerWeights.wUp.data.begin(), layerWeights.wUp.data.end(), wUp_[layer].data());
            
            wDown_[layer] = Tensor(layerWeights.wDown.shape);
            std::copy(layerWeights.wDown.data.begin(), layerWeights.wDown.data.end(), wDown_[layer].data());
            
            // Normæƒé‡
            norm1_[layer] = Tensor(layerWeights.norm1.shape);
            std::copy(layerWeights.norm1.data.begin(), layerWeights.norm1.data.end(), norm1_[layer].data());
            
            norm2_[layer] = Tensor(layerWeights.norm2.shape);
            std::copy(layerWeights.norm2.data.begin(), layerWeights.norm2.data.end(), norm2_[layer].data());
            
            // Q/K ç‹¬ç«‹å½’ä¸€åŒ–æƒé‡ï¼ˆå¯é€‰ï¼‰
            if (!layerWeights.attnQNorm.shape.empty() && layerWeights.attnQNorm.data.size() > 0) {
                attnQNorm_[layer] = Tensor(layerWeights.attnQNorm.shape);
                std::copy(layerWeights.attnQNorm.data.begin(), 
                         layerWeights.attnQNorm.data.end(), 
                         attnQNorm_[layer].data());
                CLLM_DEBUG("[KylinBackend] Loaded attnQNorm for layer %zu from ModelWeights", layer);
            }
            
            if (!layerWeights.attnKNorm.shape.empty() && layerWeights.attnKNorm.data.size() > 0) {
                attnKNorm_[layer] = Tensor(layerWeights.attnKNorm.shape);
                std::copy(layerWeights.attnKNorm.data.begin(), 
                         layerWeights.attnKNorm.data.end(), 
                         attnKNorm_[layer].data());
                CLLM_DEBUG("[KylinBackend] Loaded attnKNorm for layer %zu from ModelWeights", layer);
            }
        }
        
        // ç»‘å®šæƒé‡åˆ°æ¨¡å‹
        bindWeightsToModel();
        
        CLLM_INFO("[KylinBackend] Successfully loaded weights from ModelWeights");
        return true;
    } catch (const std::exception &e) {
        CLLM_ERROR("[KylinBackend] Failed to load weights from ModelWeights: %s", e.what());
        return false;
    }
}

kylin::OperatorBackend KylinBackend::getOperatorBackend() const {
    if (op_) {
        return op_->getBackend();
    }
    return kylin::OperatorBackend::Native;
}

std::string KylinBackend::getOperatorBackendName() const {
    if (op_) {
        return op_->getName();
    }
    return "None";
}

bool KylinBackend::cleanupKVCache(size_t requestId) {
    if (useHFModel_ && hfModel_) {
        hfModel_->releaseKVCache(requestId);
        CLLM_DEBUG("[KylinBackend] Released KV cache for request %zu", requestId);
        return true;
    }
    // å…¶ä»–æ¨¡å¼æš‚ä¸æ”¯æŒ per-request KV cache
    return false;
}

} // namespace inference
} // namespace cllm
