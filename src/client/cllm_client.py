#!/usr/bin/env python3
"""
cLLM äº¤äº’å¼å®¢æˆ·ç«¯
æ”¯æŒæµå¼å’Œéæµå¼æ–‡æœ¬ç”Ÿæˆ
"""

import os
import requests
import json
import time
import argparse
from typing import Dict, Any, Optional


# é»˜è®¤æœåŠ¡å™¨åœ°å€
DEFAULT_SERVER_URL = "http://localhost:8080"


class CLLMClient:
    """cLLM å®¢æˆ·ç«¯ç±»"""
    
    def __init__(self, server_url: str = None):
        if server_url is None:
            server_url = os.environ.get("CLLM_SERVER_URL", DEFAULT_SERVER_URL)
        self.server_url = server_url
        self.session = requests.Session()
        self.default_params = {
            "max_tokens": 100,
            "temperature": 0.7,
            "top_p": 0.9,
            "top_k": 50
        }
        self.interrupt_requested = False
        self._token_count = 0
        
    def check_server_health(self) -> bool:
        """æ£€æŸ¥æœåŠ¡å™¨å¥åº·çŠ¶æ€"""
        try:
            timeout = float(os.environ.get("CLLM_CLIENT_HEALTH_TIMEOUT", "5"))
            response = self.session.get(f"{self.server_url}/health", timeout=timeout)
            return response.status_code == 200
        except Exception:
            return False
    
    def request_interrupt(self):
        """è¯·æ±‚ä¸­æ–­å½“å‰ç”Ÿæˆ"""
        self.interrupt_requested = True
    
    def reset_interrupt(self):
        """é‡ç½®ä¸­æ–­æ ‡å¿—"""
        self.interrupt_requested = False
    
    def generate_text(self, prompt: str, stream: bool = False, **kwargs) -> Optional[Dict[str, Any]]:
        """
        ç”Ÿæˆæ–‡æœ¬
        
        Args:
            prompt: è¾“å…¥æç¤ºè¯
            stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
            **kwargs: å…¶ä»–å‚æ•° (max_tokens, temperature, top_p, top_k)
        
        Returns:
            åŒ…å«ç”Ÿæˆç»“æœçš„å­—å…¸ï¼Œå¤±è´¥è¿”å› None
        """
        self.reset_interrupt()
        
        # åˆå¹¶å‚æ•°
        params = self.default_params.copy()
        params.update(kwargs)
        params["prompt"] = prompt
        
        if stream:
            return self._generate_streaming(params)
        else:
            return self._generate_non_streaming(params)
    
    def _generate_non_streaming(self, params: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """éæµå¼ç”Ÿæˆ"""
        try:
            timeout = float(os.environ.get("CLLM_CLIENT_GENERATE_TIMEOUT", "120"))
            response = self.session.post(
                f"{self.server_url}/generate",
                headers={"Content-Type": "application/json; charset=utf-8"},
                data=json.dumps(params, ensure_ascii=False).encode('utf-8'),
                timeout=timeout
            )
            
            if response.status_code == 200:
                response.encoding = 'utf-8'
                result = response.json()
                # ç»Ÿä¸€æå–ç”Ÿæˆçš„æ–‡æœ¬
                if 'data' in result and isinstance(result['data'], dict):
                    data = result['data']
                    if 'text' in data:
                        result['generated_text'] = data['text']
                    if 'generated_tokens' in data:
                        result['token_count'] = data['generated_tokens']
                elif 'text' in result:
                    result['generated_text'] = result['text']
                return result
            else:
                print(f"âŒ æœåŠ¡å™¨è¿”å›é”™è¯¯: {response.status_code}")
                print(f"   é”™è¯¯ä¿¡æ¯: {response.text}")
                return None
                
        except requests.exceptions.Timeout:
            print("âŒ è¯·æ±‚è¶…æ—¶")
            return None
        except requests.exceptions.ConnectionError:
            print("âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨")
            return None
        except Exception as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
            return None

    def _generate_streaming(self, params: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """æµå¼ç”Ÿæˆ"""
        params["stream"] = True
        self._token_count = 0
        
        try:
            response = self.session.post(
                f"{self.server_url}/generate_stream",
                headers={"Content-Type": "application/json; charset=utf-8"},
                data=json.dumps(params, ensure_ascii=False).encode('utf-8'),
                stream=True,
                timeout=300
            )
            
            if response.status_code == 200:
                print("ğŸ¤– æœåŠ¡å™¨: ", end='', flush=True)
                
                full_text = ""
                buffer = ""
                
                for chunk in response.iter_content(chunk_size=None, decode_unicode=False):
                    if self.interrupt_requested:
                        print("\nâœ… ç”Ÿæˆå·²ä¸­æ–­")
                        return {"generated_text": full_text, "finish_reason": "interrupted", "token_count": self._token_count}
                    
                    if not chunk:
                        continue
                    
                    try:
                        buffer += chunk.decode('utf-8')
                    except UnicodeDecodeError:
                        continue
                    
                    # å¤„ç†ç¼“å†²åŒºä¸­çš„å®Œæ•´è¡Œ
                    while '\n' in buffer:
                        line, buffer = buffer.split('\n', 1)
                        line = line.strip()
                        
                        if not line:
                            continue
                        
                        if line.startswith('data: '):
                            data_str = line[6:]
                            if data_str.strip() == '[DONE]':
                                break
                            try:
                                data = json.loads(data_str)
                                if "token" in data:
                                    token_text = data["token"]
                                    full_text += token_text
                                    self._token_count += 1
                                    print(token_text, end='', flush=True)
                                if data.get("done", False):
                                    print()
                                    return {"generated_text": full_text, "token_count": self._token_count}
                            except json.JSONDecodeError:
                                continue
                
                print()
                return {"generated_text": full_text, "token_count": self._token_count}
            else:
                print(f"âŒ æœåŠ¡å™¨è¿”å›é”™è¯¯: {response.status_code}")
                print(f"   é”™è¯¯ä¿¡æ¯: {response.text}")
                return None
                
        except requests.exceptions.Timeout:
            print("âŒ è¯·æ±‚è¶…æ—¶")
            return None
        except requests.exceptions.ConnectionError:
            print("âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨")
            return None
        except Exception as e:
            print(f"âŒ æµå¼è¯·æ±‚å¤±è´¥: {e}")
            return None
    
    def show_help(self):
        """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
        print()
        print("=" * 50)
        print("ğŸ“– cLLM å®¢æˆ·ç«¯å¸®åŠ©")
        print("=" * 50)
        print()
        print("åŸºæœ¬ç”¨æ³•:")
        print("  ç›´æ¥è¾“å…¥é—®é¢˜ï¼ŒæŒ‰å›è½¦å‘é€")
        print()
        print("å‘½ä»¤åˆ—è¡¨:")
        print("  help          - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯")
        print("  config        - æŸ¥çœ‹å½“å‰é…ç½®")
        print("  set <k> <v>   - è®¾ç½®å‚æ•° (å¦‚: set max_tokens 200)")
        print("  stream on     - å¼€å¯æµå¼è¾“å‡º (é€å­—æ˜¾ç¤º)")
        print("  stream off    - å…³é—­æµå¼è¾“å‡º (ä¸€æ¬¡æ˜¾ç¤º)")
        print("  clear         - æ¸…å±")
        print("  quit/exit/q   - é€€å‡ºç¨‹åº")
        print()
        print("å¯è®¾ç½®çš„å‚æ•°:")
        print("  max_tokens    - æœ€å¤§ç”Ÿæˆtokenæ•° (æ•´æ•°)")
        print("  temperature   - æ¸©åº¦ï¼Œæ§åˆ¶éšæœºæ€§ (0.0-2.0)")
        print("  top_p         - Top-p é‡‡æ ·å‚æ•° (0.0-1.0)")
        print("  top_k         - Top-k é‡‡æ ·å‚æ•° (æ•´æ•°)")
        print()
        print("å¿«æ·é”®:")
        print("  Ctrl+C        - ä¸­æ–­å½“å‰ç”Ÿæˆ")
        print("=" * 50)
        print()
    
    def show_config(self):
        """æ˜¾ç¤ºå½“å‰é…ç½®"""
        print()
        print("âš™ï¸  å½“å‰é…ç½®:")
        print(f"  æœåŠ¡å™¨åœ°å€: {self.server_url}")
        for key, value in self.default_params.items():
            print(f"  {key}: {value}")
        print()
    
    def set_config(self, config_str: str) -> bool:
        """è®¾ç½®é…ç½®å‚æ•°"""
        parts = config_str.strip().split()
        if len(parts) < 2:
            print("âŒ ç”¨æ³•: set <å‚æ•°å> <å‚æ•°å€¼>")
            print("   ä¾‹å¦‚: set max_tokens 200")
            return False
        
        param_name = parts[0]
        param_value_str = parts[1]
        
        # ç±»å‹è½¬æ¢
        try:
            if param_name in ['max_tokens', 'top_k']:
                param_value = int(param_value_str)
            elif param_name in ['temperature', 'top_p']:
                param_value = float(param_value_str)
            else:
                param_value = param_value_str
        except ValueError:
            print(f"âŒ æ— æ•ˆçš„å‚æ•°å€¼: {param_value_str}")
            return False
        
        self.default_params[param_name] = param_value
        print(f"âœ… å·²è®¾ç½® {param_name} = {param_value}")
        return True

    def chat_loop(self):
        """äº¤äº’å¼èŠå¤©å¾ªç¯"""
        print()
        print("ğŸš€ cLLM äº¤äº’å¼å®¢æˆ·ç«¯")
        print("=" * 50)
        print(f"æœåŠ¡å™¨: {self.server_url}")
        print("è¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©ï¼Œ'quit' é€€å‡º")
        print("=" * 50)
        
        # æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€
        if not self.check_server_health():
            print()
            print("âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œè¯·ç¡®ä¿ cLLM æœåŠ¡å™¨æ­£åœ¨è¿è¡Œ")
            print(f"   æœåŠ¡å™¨åœ°å€: {self.server_url}")
            return
        
        print("âœ… å·²è¿æ¥åˆ°æœåŠ¡å™¨")
        print()
        
        # é»˜è®¤å¯ç”¨æµå¼è¾“å‡º
        streaming_enabled = True
        
        while True:
            try:
                user_input = input("ğŸ’¬ æ‚¨: ").strip()
                
                if not user_input:
                    continue
                
                # å¤„ç†å‘½ä»¤
                cmd = user_input.lower()
                
                if cmd in ['quit', 'exit', 'q']:
                    self.request_interrupt()
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                    
                elif cmd == 'clear':
                    os.system('clear' if os.name != 'nt' else 'cls')
                    continue
                    
                elif cmd == 'help':
                    self.show_help()
                    continue
                    
                elif cmd == 'config':
                    self.show_config()
                    continue
                    
                elif cmd.startswith('set '):
                    self.set_config(user_input[4:])
                    continue
                    
                elif cmd == 'stream on':
                    streaming_enabled = True
                    print("âœ… å·²å¯ç”¨æµå¼è¾“å‡º")
                    continue
                    
                elif cmd == 'stream off':
                    streaming_enabled = False
                    print("âœ… å·²ç¦ç”¨æµå¼è¾“å‡º")
                    continue
                
                # å‘é€ç”Ÿæˆè¯·æ±‚
                if not streaming_enabled:
                    print("â³ æ­£åœ¨ç”Ÿæˆ...", end='', flush=True)
                
                start_time = time.time()
                result = self.generate_text(user_input, stream=streaming_enabled)
                end_time = time.time()
                
                if result:
                    # æå–ç”Ÿæˆçš„æ–‡æœ¬
                    generated_text = result.get("generated_text", "")
                    
                    # éæµå¼æ¨¡å¼æ˜¾ç¤ºç»“æœ
                    if not streaming_enabled:
                        print()
                        print(f"ğŸ¤– æœåŠ¡å™¨: {generated_text}")
                    
                    # ç»Ÿè®¡ä¿¡æ¯
                    response_time = end_time - start_time
                    token_count = result.get("token_count", self._token_count)
                    if token_count == 0 and generated_text:
                        token_count = len(generated_text) // 2 + 1  # ä¼°ç®—
                    
                    speed = token_count / response_time if response_time > 0 else 0
                    print(f"ğŸ“ˆ ç»Ÿè®¡: {token_count} tokens, {response_time:.2f}s, {speed:.1f} t/s")
                else:
                    if not streaming_enabled:
                        print()
                    print("âŒ ç”Ÿæˆå¤±è´¥ï¼Œè¯·é‡è¯•")
                
                print()
                
            except KeyboardInterrupt:
                print("\nâœ… å·²ä¸­æ–­")
                self.reset_interrupt()
                continue
            except EOFError:
                print("\nğŸ‘‹ å†è§ï¼")
                break


def main():
    parser = argparse.ArgumentParser(
        description="cLLM äº¤äº’å¼å®¢æˆ·ç«¯",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python cllm_client.py --server-url http://localhost:8085
  python cllm_client.py --max-tokens 200 --temperature 0.8
        """
    )
    parser.add_argument(
        "--server-url", 
        default=DEFAULT_SERVER_URL,
        help=f"cLLM æœåŠ¡å™¨åœ°å€ (é»˜è®¤: {DEFAULT_SERVER_URL})"
    )
    parser.add_argument(
        "--max-tokens", 
        type=int, 
        default=100,
        help="æœ€å¤§ç”Ÿæˆtokenæ•° (é»˜è®¤: 100)"
    )
    parser.add_argument(
        "--temperature", 
        type=float, 
        default=0.7,
        help="æ¸©åº¦å‚æ•° (é»˜è®¤: 0.7)"
    )
    parser.add_argument(
        "--top-p", 
        type=float, 
        default=0.9,
        help="Top-p é‡‡æ ·å‚æ•° (é»˜è®¤: 0.9)"
    )
    parser.add_argument(
        "--top-k", 
        type=int, 
        default=50,
        help="Top-k é‡‡æ ·å‚æ•° (é»˜è®¤: 50)"
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºå®¢æˆ·ç«¯
    client = CLLMClient(args.server_url)
    
    # è®¾ç½®å‚æ•°
    client.default_params.update({
        "max_tokens": args.max_tokens,
        "temperature": args.temperature,
        "top_p": args.top_p,
        "top_k": args.top_k
    })
    
    # å¼€å§‹èŠå¤©
    client.chat_loop()


if __name__ == "__main__":
    main()
