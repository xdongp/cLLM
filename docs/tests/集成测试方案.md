# cLLM 集成测试方案

**遵循 C++编程规范.md**

## 1. 集成测试概述

### 1.1 测试目标

集成测试旨在验证 cLLM 各组件间的交互是否正确，确保系统作为一个整体能够正常工作。主要目标包括：

- **组件协作验证**：验证各组件按照设计文档正确交互
- **数据流验证**：确保数据在组件间正确传递和转换
- **错误传播验证**：验证错误能正确从底层传播到上层
- **并发安全验证**：确保多线程环境下组件交互的安全性
- **性能基线建立**：建立系统性能基线，为优化提供依据
- **端到端流程验证**：验证从 HTTP 请求到响应的完整流程

### 1.2 测试范围

| 测试类型 | 覆盖范围 | 测试重点 |
|---------|---------|---------|
| **组件接口测试** | 相邻组件间的接口调用 | 参数传递、返回值验证、异常处理 |
| **数据流测试** | 跨多个组件的数据流转 | 数据完整性、转换正确性 |
| **并发集成测试** | 多线程下的组件交互 | 线程安全、死锁检测、资源竞争 |
| **端到端测试** | 完整请求处理流程 | 功能正确性、性能指标 |
| **错误场景测试** | 异常情况下的组件协作 | 错误处理、系统恢复 |

### 1.3 测试策略

采用**自底向上**的集成测试策略：

```
第一阶段：基础组件集成
├─> MemoryMonitor + KVCache
├─> MemoryMonitor + BatchManager
└─> ThreadPool + ModelExecutor

第二阶段：调度层集成
├─> RequestQueue + RequestTracker
├─> Scheduler + BatchManager
└─> Scheduler + KVCache

第三阶段：服务层集成
├─> HttpServer + RequestValidator
├─> HttpServer + Scheduler
└─> TokenizerManager + ModelExecutor

第四阶段：端到端集成
└─> 完整请求处理流程
```

### 1.4 测试工具

- **测试框架**：Google Test (GTest) + Google Mock (GMock)
- **HTTP 测试**：顶层 tests/ 目录下的 test_api.py 和 test_client.py
- **性能测试**：tools/unified_benchmark.py
- **并发测试**：ThreadSanitizer (TSan)
- **内存检测**：Valgrind + AddressSanitizer (ASan)
- **覆盖率**：gcov + lcov

## 2. 系统初始化集成测试

### 2.1 初始化顺序验证测试

**测试目标**：验证系统按照设计的8步初始化顺序正确启动

#### 测试用例 IT-INIT-001：完整初始化流程测试

```cpp
TEST(SystemInitializationTest, FullInitializationSequence) {
    // 准备：配置参数
    ServerConfig config;
    config.modelPath = "/path/to/model";
    config.port = 8080;
    config.maxBatchSize = 8;
    config.maxContextLength = 2048;
    config.kvCacheMaxSize = 100;
    config.kvCacheMaxMemoryMB = 4096;
    config.memoryLimitMB = 16384;
    config.numThreads = 8;
    
    // 执行：按顺序初始化各组件
    
    // 1. 内存监控器初始化
    auto& memMonitor = MemoryMonitor::instance();
    memMonitor.setLimit(config.memoryLimitMB * 1024 * 1024);
    EXPECT_GT(memMonitor.getLimit(), 0);
    
    // 2. 线程池初始化
    auto threadPool = std::make_unique<ThreadPool>(config.numThreads);
    EXPECT_TRUE(threadPool != nullptr);
    
    // 3. Tokenizer 初始化
    auto tokenizer = std::make_unique<TokenizerManager>(config.modelPath);
    EXPECT_TRUE(tokenizer->isLoaded());
    
    // 4. ModelExecutor 初始化
    auto modelExecutor = std::make_unique<ModelExecutor>(
        config.modelPath, 
        config.quantization
    );
    EXPECT_TRUE(modelExecutor != nullptr);
    modelExecutor->loadModel();
    
    // 5. KVCache 初始化
    auto kvCache = std::make_unique<KVCache>(
        config.kvCacheMaxSize,
        config.kvCacheMaxMemoryMB
    );
    EXPECT_EQ(kvCache->size(), 0);
    
    // 6. BatchManager 初始化
    auto batchManager = std::make_unique<BatchManager>(
        modelExecutor.get(),
        kvCache.get(),
        config.maxBatchSize,
        config.maxContextLength
    );
    EXPECT_TRUE(batchManager != nullptr);
    
    // 7. Scheduler 初始化
    auto scheduler = std::make_unique<Scheduler>(
        config.modelPath,
        config.quantization,
        config.maxBatchSize,
        config.maxContextLength
    );
    scheduler->start();
    EXPECT_TRUE(scheduler->isRunning());
    
    // 8. HttpServer 初始化
    auto httpServer = std::make_unique<HttpServer>("0.0.0.0", config.port);
    httpServer->start();
    EXPECT_TRUE(httpServer->isRunning());
    
    // 清理：按相反顺序关闭
    httpServer->stop();
    scheduler->stop();
    batchManager.reset();
    kvCache.reset();
    modelExecutor->unloadModel();
    modelExecutor.reset();
    tokenizer.reset();
    threadPool->shutdown();
    threadPool.reset();
}
```

#### 测试用例 IT-INIT-002：依赖顺序错误测试

```cpp
TEST(SystemInitializationTest, WrongOrderInitializationFails) {
    // 测试：尝试在 MemoryMonitor 之前初始化 KVCache（错误顺序）
    // 预期：应该失败或产生警告
    
    // 不设置内存限制
    auto kvCache = std::make_unique<KVCache>(100, 4096);
    
    // 尝试分配内存，应该由于没有监控器而产生问题
    // （实际行为取决于实现）
}
```

### 2.2 配置参数传递测试

#### 测试用例 IT-INIT-003：配置参数正确传递

```cpp
TEST(SystemInitializationTest, ConfigurationPropagation) {
    ServerConfig config;
    config.maxBatchSize = 16;
    config.maxContextLength = 4096;
    
    auto scheduler = std::make_unique<Scheduler>(
        config.modelPath,
        config.quantization,
        config.maxBatchSize,
        config.maxContextLength
    );
    
    // 验证配置正确传递
    auto& schedulerConfig = scheduler->getConfig();
    EXPECT_EQ(schedulerConfig.maxBatchSize, 16);
    EXPECT_EQ(schedulerConfig.maxContextLength, 4096);
}
```

## 3. 基础组件集成测试

### 3.1 MemoryMonitor + KVCache 集成测试

**测试目标**：验证 KVCache 正确使用 MemoryMonitor 进行内存监控

#### 测试用例 IT-MEM-001：内存监控与限制

```cpp
TEST(MemoryKVCacheIntegrationTest, MemoryMonitoringAndLimit) {
    // 准备：设置内存限制为 100MB
    auto& monitor = MemoryMonitor::instance();
    monitor.setLimit(100 * 1024 * 1024);
    
    // 创建 KVCache，限制内存为 50MB
    KVCache kvCache(100, 50);
    
    // 添加大量缓存条目直到接近限制
    for (size_t i = 0; i < 100; ++i) {
        FloatArray keyCache(10000);   // ~40KB
        FloatArray valueCache(10000); // ~40KB
        kvCache.put(i, keyCache, valueCache);
    }
    
    // 验证：内存使用量应该被限制
    float memUsageMB = kvCache.getMemoryUsageMB();
    EXPECT_LE(memUsageMB, 50.0f);
    
    // 验证：LRU 淘汰应该已经发生
    auto stats = kvCache.getStats();
    EXPECT_GT(stats.evictionCount, 0);
}
```

#### 测试用例 IT-MEM-002：内存超限回调

```cpp
TEST(MemoryKVCacheIntegrationTest, MemoryLimitCallback) {
    bool callbackTriggered = false;
    
    auto& monitor = MemoryMonitor::instance();
    monitor.setLimit(50 * 1024 * 1024);
    monitor.registerCallback([&](size_t used, size_t limit) {
        callbackTriggered = true;
    });
    
    KVCache kvCache(1000, 100);  // 尝试使用 100MB
    
    // 添加大量数据触发内存限制
    try {
        for (size_t i = 0; i < 1000; ++i) {
            FloatArray keyCache(50000);
            FloatArray valueCache(50000);
            kvCache.put(i, keyCache, valueCache);
        }
    } catch (const std::runtime_error& e) {
        // 预期会抛出内存超限异常
    }
    
    // 验证回调被触发
    EXPECT_TRUE(callbackTriggered);
}
```

### 3.2 ThreadPool + ModelExecutor 集成测试

**测试目标**：验证 ModelExecutor 正确使用 ThreadPool 进行并行推理

#### 测试用例 IT-THREAD-001：并行推理任务

```cpp
TEST(ThreadPoolModelExecutorTest, ParallelInferenceTasks) {
    ThreadPool threadPool(4);
    ModelExecutor executor("/path/to/model", "fp16");
    executor.loadModel();
    
    // 提交多个推理任务到线程池
    std::vector<std::future<BatchOutput>> futures;
    for (int i = 0; i < 10; ++i) {
        auto future = threadPool.submit([&executor, i]() {
            BatchInput input;
            input.batchSize = 1;
            input.requests.push_back(createTestRequest(i));
            return executor.forward(input);
        });
        futures.push_back(std::move(future));
    }
    
    // 等待所有任务完成
    for (auto& future : futures) {
        auto output = future.get();
        EXPECT_FALSE(output.generatedTokens.empty());
    }
    
    // 验证线程池统计
    auto stats = threadPool.getStats();
    EXPECT_EQ(stats.completedTasks, 10);
}
```

### 3.3 BatchManager + ModelExecutor + KVCache 集成测试

**测试目标**：验证批处理管理、模型执行和 KV 缓存的协同工作

#### 测试用例 IT-BATCH-001：批处理与缓存协作

```cpp
TEST(BatchManagerIntegrationTest, BatchProcessingWithCache) {
    // 初始化组件
    auto modelExecutor = std::make_unique<ModelExecutor>("/path/to/model");
    modelExecutor->loadModel();
    
    auto kvCache = std::make_unique<KVCache>(100, 1024);
    
    BatchManager batchManager(
        modelExecutor.get(),
        kvCache.get(),
        8,    // maxBatchSize
        2048  // maxContextLength
    );
    
    // 创建测试请求
    std::vector<RequestState> requests;
    for (int i = 0; i < 5; ++i) {
        RequestState req;
        req.requestId = i;
        req.tokenizedPrompt = {1, 2, 3, 4, 5};
        req.maxTokens = 10;
        requests.push_back(req);
    }
    
    // 形成批处理
    auto batch = batchManager.formBatch(requests);
    EXPECT_EQ(batch.requests.size(), 5);
    
    // 执行批处理（会使用 KVCache）
    auto output = batchManager.processBatch(batch);
    
    // 验证输出
    EXPECT_EQ(output.generatedTokens.size(), 5);
    
    // 验证缓存命中
    auto cacheStats = kvCache->getStats();
    EXPECT_GT(cacheStats.totalAccesses, 0);
}
```

## 4. 调度层集成测试

### 4.1 Scheduler + RequestQueue + RequestTracker 集成测试

**测试目标**：验证调度器正确管理请求队列和跟踪请求状态

#### 测试用例 IT-SCH-001：请求生命周期管理

```cpp
TEST(SchedulerIntegrationTest, RequestLifecycleManagement) {
    Scheduler scheduler("/path/to/model", "fp16", 8, 2048);
    scheduler.start();
    
    // 添加多个请求
    std::vector<size_t> requestIds;
    for (int i = 0; i < 10; ++i) {
        RequestState req;
        req.tokenizedPrompt = {1, 2, 3, 4, 5};
        req.maxTokens = 20;
        auto requestId = scheduler.addRequest(req);
        requestIds.push_back(requestId);
    }
    
    // 等待所有请求完成
    for (auto requestId : requestIds) {
        auto result = scheduler.getRequestResult(requestId);
        while (!result.isCompleted) {
            std::this_thread::sleep_for(std::chrono::milliseconds(100));
            result = scheduler.getRequestResult(requestId);
        }
        
        // 验证请求完成
        EXPECT_TRUE(result.isCompleted);
        EXPECT_FALSE(result.generatedTokens.empty());
    }
    
    // 验证调度器统计
    auto stats = scheduler.getStats();
    EXPECT_EQ(stats.completedRequests, 10);
    
    scheduler.stop();
}
```

#### 测试用例 IT-SCH-002：请求优先级调度

```cpp
TEST(SchedulerIntegrationTest, PriorityScheduling) {
    Scheduler scheduler("/path/to/model", "fp16", 8, 2048);
    scheduler.start();
    
    // 添加不同优先级的请求
    std::vector<size_t> lowPriorityIds;
    std::vector<size_t> highPriorityIds;
    
    // 先添加低优先级请求
    for (int i = 0; i < 5; ++i) {
        RequestState req;
        req.tokenizedPrompt = {1, 2, 3};
        req.maxTokens = 100;  // 长时间任务
        req.priority = 1;     // 低优先级
        lowPriorityIds.push_back(scheduler.addRequest(req));
    }
    
    // 短暂延迟后添加高优先级请求
    std::this_thread::sleep_for(std::chrono::milliseconds(100));
    
    for (int i = 0; i < 3; ++i) {
        RequestState req;
        req.tokenizedPrompt = {1, 2, 3};
        req.maxTokens = 10;   // 短时间任务
        req.priority = 10;    // 高优先级
        highPriorityIds.push_back(scheduler.addRequest(req));
    }
    
    // 记录完成时间
    std::map<size_t, std::chrono::steady_clock::time_point> completionTimes;
    
    auto checkCompletion = [&](const std::vector<size_t>& ids) {
        for (auto id : ids) {
            auto result = scheduler.getRequestResult(id);
            if (result.isCompleted && completionTimes.find(id) == completionTimes.end()) {
                completionTimes[id] = std::chrono::steady_clock::now();
            }
        }
    };
    
    // 轮询检查完成状态
    while (completionTimes.size() < lowPriorityIds.size() + highPriorityIds.size()) {
        checkCompletion(lowPriorityIds);
        checkCompletion(highPriorityIds);
        std::this_thread::sleep_for(std::chrono::milliseconds(50));
    }
    
    // 验证：高优先级请求应该更早完成
    auto firstHighPriorityTime = completionTimes[highPriorityIds[0]];
    auto lastLowPriorityTime = completionTimes[lowPriorityIds.back()];
    EXPECT_LT(firstHighPriorityTime, lastLowPriorityTime);
    
    scheduler.stop();
}
```

### 4.2 Scheduler + BatchManager 集成测试

**测试目标**：验证调度器正确使用批处理管理器

#### 测试用例 IT-SCH-003：动态批处理

```cpp
TEST(SchedulerBatchManagerTest, DynamicBatching) {
    Scheduler scheduler("/path/to/model", "fp16", 8, 2048);
    scheduler.start();
    
    // 模拟突发请求
    std::vector<size_t> requestIds;
    for (int i = 0; i < 20; ++i) {
        RequestState req;
        req.tokenizedPrompt = {1, 2, 3, 4, 5};
        req.maxTokens = 10;
        requestIds.push_back(scheduler.addRequest(req));
    }
    
    // 短暂等待让调度器形成批处理
    std::this_thread::sleep_for(std::chrono::milliseconds(500));
    
    // 获取统计信息
    auto stats = scheduler.getStats();
    
    // 验证：应该形成了多个批处理
    EXPECT_GT(stats.batchCount, 1);
    
    // 验证：批处理大小应该接近最大值
    EXPECT_GT(stats.averageBatchSize, 4.0);
    
    scheduler.stop();
}
```

## 5. 服务层集成测试

### 5.1 HttpServer + RequestValidator 集成测试

**测试目标**：验证 HTTP 服务器正确验证请求参数

#### 测试用例 IT-HTTP-001：请求参数验证

```cpp
TEST(HttpServerValidationTest, RequestParameterValidation) {
    HttpServer server("127.0.0.1", 8080);
    RequestValidator validator;
    server.setValidator(&validator);
    server.start();
    
    // 测试1：有效请求
    {
        HttpRequest validReq;
        validReq.method = "POST";
        validReq.path = "/generate";
        validReq.body = R"({
            "prompt": "Hello",
            "max_tokens": 50,
            "temperature": 0.7
        })";
        
        EXPECT_NO_THROW(validator.validateGenerateRequest(validReq));
    }
    
    // 测试2：缺少必需参数
    {
        HttpRequest invalidReq;
        invalidReq.method = "POST";
        invalidReq.path = "/generate";
        invalidReq.body = R"({
            "temperature": 0.7
        })";
        
        EXPECT_THROW(validator.validateGenerateRequest(invalidReq), 
                     std::invalid_argument);
    }
    
    // 测试3：参数超出范围
    {
        HttpRequest invalidReq;
        invalidReq.method = "POST";
        invalidReq.path = "/generate";
        invalidReq.body = R"({
            "prompt": "Hello",
            "max_tokens": 10000,
            "temperature": 5.0
        })";
        
        EXPECT_THROW(validator.validateGenerateRequest(invalidReq), 
                     std::invalid_argument);
    }
    
    server.stop();
}
```

### 5.2 HttpServer + Scheduler 集成测试

**测试目标**：验证 HTTP 服务器正确路由请求到调度器

#### 测试用例 IT-HTTP-002：HTTP 到调度器的请求路由

```cpp
TEST(HttpServerSchedulerTest, RequestRouting) {
    // 初始化调度器
    auto scheduler = std::make_unique<Scheduler>("/path/to/model", "fp16", 8, 2048);
    scheduler->start();
    
    // 初始化 HTTP 服务器
    HttpServer server("127.0.0.1", 8081);
    server.setScheduler(scheduler.get());
    server.start();
    
    // 使用 HTTP 客户端发送请求
    HttpClient client("http://127.0.0.1:8081");
    
    auto response = client.post("/generate", R"({
        "prompt": "Hello, world!",
        "max_tokens": 20,
        "temperature": 0.7
    })");
    
    // 验证响应
    EXPECT_EQ(response.statusCode, 200);
    EXPECT_FALSE(response.body.empty());
    
    // 解析响应 JSON
    auto json = nlohmann::json::parse(response.body);
    EXPECT_TRUE(json.contains("generated_text"));
    
    server.stop();
    scheduler->stop();
}
```

### 5.3 TokenizerManager + Scheduler 集成测试

**测试目标**：验证文本编解码与调度器的协作

#### 测试用例 IT-TOK-001：端到端文本处理

```cpp
TEST(TokenizerSchedulerTest, EndToEndTextProcessing) {
    // 初始化组件
    auto tokenizer = std::make_unique<TokenizerManager>("/path/to/model");
    auto scheduler = std::make_unique<Scheduler>("/path/to/model", "fp16", 8, 2048);
    scheduler->start();
    
    // 输入文本
    std::string inputText = "What is artificial intelligence?";
    
    // 编码
    auto tokenIds = tokenizer->encode(inputText, true);
    EXPECT_FALSE(tokenIds.empty());
    
    // 创建请求
    RequestState req;
    req.tokenizedPrompt = tokenIds;
    req.maxTokens = 50;
    req.temperature = 0.7f;
    
    // 提交到调度器
    auto requestId = scheduler->addRequest(req);
    
    // 等待完成
    auto result = scheduler->getRequestResult(requestId);
    while (!result.isCompleted) {
        std::this_thread::sleep_for(std::chrono::milliseconds(100));
        result = scheduler->getRequestResult(requestId);
    }
    
    // 解码
    std::string outputText = tokenizer->decode(result.generatedTokens, true);
    EXPECT_FALSE(outputText.empty());
    
    // 验证输出
    std::cout << "Input: " << inputText << std::endl;
    std::cout << "Output: " << outputText << std::endl;
    
    scheduler->stop();
}
```

## 6. 端到端集成测试

### 6.1 完整请求处理流程测试

**测试目标**：验证从 HTTP 请求到响应的完整流程

#### 测试用例 IT-E2E-001：文本生成完整流程

```cpp
TEST(EndToEndTest, CompleteGenerationFlow) {
    // 1. 初始化所有组件（按照设计的8步顺序）
    auto& memMonitor = MemoryMonitor::instance();
    memMonitor.setLimit(16 * 1024 * 1024 * 1024ULL);
    
    auto threadPool = std::make_unique<ThreadPool>(8);
    
    auto tokenizer = std::make_unique<TokenizerManager>("/path/to/model");
    
    auto modelExecutor = std::make_unique<ModelExecutor>("/path/to/model", "fp16");
    modelExecutor->loadModel();
    
    auto kvCache = std::make_unique<KVCache>(100, 4096);
    
    auto batchManager = std::make_unique<BatchManager>(
        modelExecutor.get(),
        kvCache.get(),
        8,
        2048
    );
    
    auto scheduler = std::make_unique<Scheduler>("/path/to/model", "fp16", 8, 2048);
    scheduler->start();
    
    auto httpServer = std::make_unique<HttpServer>("127.0.0.1", 8082);
    httpServer->setScheduler(scheduler.get());
    httpServer->setTokenizer(tokenizer.get());
    httpServer->start();
    
    // 2. 发送 HTTP 请求
    HttpClient client("http://127.0.0.1:8082");
    
    auto response = client.post("/generate", R"({
        "prompt": "Explain the concept of recursion",
        "max_tokens": 100,
        "temperature": 0.7,
        "top_p": 0.9
    })");
    
    // 3. 验证响应
    EXPECT_EQ(response.statusCode, 200);
    
    auto json = nlohmann::json::parse(response.body);
    EXPECT_TRUE(json.contains("generated_text"));
    EXPECT_TRUE(json.contains("tokens_generated"));
    EXPECT_TRUE(json.contains("processing_time_ms"));
    
    std::string generatedText = json["generated_text"];
    EXPECT_FALSE(generatedText.empty());
    EXPECT_GT(generatedText.length(), 10);
    
    // 4. 验证统计信息
    auto schedulerStats = scheduler->getStats();
    EXPECT_EQ(schedulerStats.completedRequests, 1);
    
    auto cacheStats = kvCache->getStats();
    EXPECT_GT(cacheStats.totalAccesses, 0);
    
    // 5. 清理（按相反顺序）
    httpServer->stop();
    scheduler->stop();
    batchManager.reset();
    kvCache.reset();
    modelExecutor->unloadModel();
    modelExecutor.reset();
    tokenizer.reset();
    threadPool->shutdown();
    threadPool.reset();
}
```

#### 测试用例 IT-E2E-002：流式生成完整流程

```cpp
TEST(EndToEndTest, StreamingGenerationFlow) {
    // 初始化系统（简化）
    auto system = initializeSystem();
    
    // 发送流式请求
    HttpClient client("http://127.0.0.1:8082");
    
    std::vector<std::string> streamChunks;
    
    client.postStream("/generate", R"({
        "prompt": "Write a short story",
        "max_tokens": 200,
        "stream": true
    })", [&streamChunks](const std::string& chunk) {
        streamChunks.push_back(chunk);
        return true;  // 继续接收
    });
    
    // 验证：应该收到多个数据块
    EXPECT_GT(streamChunks.size(), 5);
    
    // 验证：最后一个块应该是 [DONE]
    EXPECT_EQ(streamChunks.back(), "data: [DONE]\n\n");
    
    // 清理
    cleanupSystem(system);
}
```

### 6.2 并发请求测试

**测试目标**：验证系统处理并发请求的能力

#### 测试用例 IT-E2E-003：高并发请求处理

```cpp
TEST(EndToEndTest, ConcurrentRequests) {
    auto system = initializeSystem();
    
    HttpClient client("http://127.0.0.1:8082");
    
    const int NUM_REQUESTS = 50;
    std::vector<std::future<HttpResponse>> futures;
    
    // 并发发送多个请求
    for (int i = 0; i < NUM_REQUESTS; ++i) {
        auto future = std::async(std::launch::async, [&client, i]() {
            return client.post("/generate", R"({
                "prompt": "Request )" + std::to_string(i) + R"(",
                "max_tokens": 20,
                "temperature": 0.7
            })");
        });
        futures.push_back(std::move(future));
    }
    
    // 等待所有请求完成
    int successCount = 0;
    for (auto& future : futures) {
        auto response = future.get();
        if (response.statusCode == 200) {
            successCount++;
        }
    }
    
    // 验证：所有请求都应该成功
    EXPECT_EQ(successCount, NUM_REQUESTS);
    
    // 验证：系统统计
    auto stats = system.scheduler->getStats();
    EXPECT_EQ(stats.completedRequests, NUM_REQUESTS);
    EXPECT_GT(stats.averageBatchSize, 1.0);  // 应该有批处理
    
    cleanupSystem(system);
}
```

## 7. 错误场景集成测试

### 7.1 组件故障测试

**测试目标**：验证单个组件故障时的系统行为

#### 测试用例 IT-ERR-001：模型加载失败

```cpp
TEST(ErrorScenarioTest, ModelLoadFailure) {
    // 使用无效的模型路径
    EXPECT_THROW({
        ModelExecutor executor("/invalid/path/to/model", "fp16");
        executor.loadModel();
    }, ModelException);
}
```

#### 测试用例 IT-ERR-002：内存超限处理

```cpp
TEST(ErrorScenarioTest, MemoryLimitExceeded) {
    // 设置很小的内存限制
    auto& monitor = MemoryMonitor::instance();
    monitor.setLimit(10 * 1024 * 1024);  // 10MB
    
    KVCache kvCache(1000, 100);  // 尝试使用 100MB
    
    // 添加大量数据应该触发内存限制
    bool memoryLimitHit = false;
    try {
        for (size_t i = 0; i < 1000; ++i) {
            FloatArray keyCache(50000);
            FloatArray valueCache(50000);
            kvCache.put(i, keyCache, valueCache);
        }
    } catch (const MemoryException& e) {
        memoryLimitHit = true;
        EXPECT_EQ(e.getErrorCode(), MemoryException::MEMORY_LIMIT_EXCEEDED);
    }
    
    EXPECT_TRUE(memoryLimitHit);
}
```

### 7.2 错误传播测试

**测试目标**：验证错误从底层正确传播到上层

#### 测试用例 IT-ERR-003：推理错误传播到HTTP响应

```cpp
TEST(ErrorPropagationTest, InferenceErrorToHttpResponse) {
    auto system = initializeSystem();
    
    HttpClient client("http://127.0.0.1:8082");
    
    // 发送会导致推理失败的请求（例如超长输入）
    auto response = client.post("/generate", R"({
        "prompt": ")" + std::string(100000, 'a') + R"(",
        "max_tokens": 10
    })");
    
    // 验证：应该返回错误响应
    EXPECT_EQ(response.statusCode, 400);  // Bad Request
    
    auto json = nlohmann::json::parse(response.body);
    EXPECT_TRUE(json.contains("error"));
    EXPECT_TRUE(json.contains("details"));
    
    cleanupSystem(system);
}
```

## 8. 性能集成测试

### 8.1 吞吐量测试

**测试目标**：测量系统在稳定负载下的吞吐量

#### 测试用例 IT-PERF-001：吞吐量基准测试

```cpp
TEST(PerformanceTest, ThroughputBenchmark) {
    auto system = initializeSystem();
    
    HttpClient client("http://127.0.0.1:8082");
    
    const int TEST_DURATION_SEC = 60;
    const int NUM_THREADS = 10;
    
    std::atomic<int> requestCount(0);
    std::atomic<bool> stopFlag(false);
    
    // 启动多个线程持续发送请求
    std::vector<std::thread> threads;
    for (int i = 0; i < NUM_THREADS; ++i) {
        threads.emplace_back([&]() {
            while (!stopFlag) {
                auto response = client.post("/generate", R"({
                    "prompt": "Test prompt",
                    "max_tokens": 20
                })");
                if (response.statusCode == 200) {
                    requestCount++;
                }
            }
        });
    }
    
    // 运行指定时间
    std::this_thread::sleep_for(std::chrono::seconds(TEST_DURATION_SEC));
    stopFlag = true;
    
    // 等待所有线程结束
    for (auto& thread : threads) {
        thread.join();
    }
    
    // 计算吞吐量
    double throughput = static_cast<double>(requestCount) / TEST_DURATION_SEC;
    
    std::cout << "Throughput: " << throughput << " requests/sec" << std::endl;
    
    // 验证：吞吐量应该达到预期值（根据硬件调整）
    EXPECT_GT(throughput, 10.0);  // 至少 10 req/sec
    
    cleanupSystem(system);
}
```

### 8.2 延迟测试

**测试目标**：测量端到端请求延迟

#### 测试用例 IT-PERF-002：延迟分布测试

```cpp
TEST(PerformanceTest, LatencyDistribution) {
    auto system = initializeSystem();
    
    HttpClient client("http://127.0.0.1:8082");
    
    const int NUM_REQUESTS = 100;
    std::vector<double> latencies;
    
    for (int i = 0; i < NUM_REQUESTS; ++i) {
        auto start = std::chrono::high_resolution_clock::now();
        
        auto response = client.post("/generate", R"({
            "prompt": "Test prompt",
            "max_tokens": 50
        })");
        
        auto end = std::chrono::high_resolution_clock::now();
        
        if (response.statusCode == 200) {
            double latencyMs = std::chrono::duration<double, std::milli>(end - start).count();
            latencies.push_back(latencyMs);
        }
    }
    
    // 计算统计信息
    std::sort(latencies.begin(), latencies.end());
    
    double p50 = latencies[latencies.size() * 0.50];
    double p95 = latencies[latencies.size() * 0.95];
    double p99 = latencies[latencies.size() * 0.99];
    
    std::cout << "P50 latency: " << p50 << " ms" << std::endl;
    std::cout << "P95 latency: " << p95 << " ms" << std::endl;
    std::cout << "P99 latency: " << p99 << " ms" << std::endl;
    
    // 验证延迟在合理范围内
    EXPECT_LT(p50, 1000.0);  // P50 < 1秒
    EXPECT_LT(p99, 5000.0);  // P99 < 5秒
    
    cleanupSystem(system);
}
```

## 9. 使用 Python 测试脚本进行集成测试

### 9.1 test_api.py 集成测试

**测试目标**：使用顶层 tests/test_api.py 验证 API 功能

#### 测试步骤

```bash
# 1. 启动 cLLM 服务器
cd cpp/cLLM
make start

# 2. 运行 API 测试
cd ../../tests
python3 test_api.py --host 127.0.0.1 --port 8080

# 3. 验证测试结果
# 预期：所有测试用例通过
```

#### 测试覆盖

- `/health` 端点健康检查
- `/generate` 端点文本生成
- `/encode` 端点文本编码
- 参数验证
- 错误处理

### 9.2 test_client.py 集成测试

**测试目标**：使用客户端库验证交互功能

```bash
cd tests
python3 test_client.py --host 127.0.0.1 --port 8080
```

### 9.3 unified_benchmark.py 性能测试

**测试目标**：进行全面的性能基准测试

```bash
cd tools
python3 unified_benchmark.py \
    --host 127.0.0.1 \
    --port 8080 \
    --num-requests 1000 \
    --concurrency 10 \
    --output benchmark_results.json
```

#### 测试指标

- 吞吐量（requests/sec, tokens/sec）
- 延迟分布（P50, P95, P99）
- 错误率
- 资源使用（CPU, 内存）
- 批处理效率

## 10. 并发安全集成测试

### 10.1 线程安全测试

**测试目标**：验证多线程环境下的线程安全性

#### 测试用例 IT-CONC-001：死锁检测

```cpp
TEST(ConcurrencySafetyTest, DeadlockDetection) {
    // 使用 ThreadSanitizer 运行
    auto system = initializeSystem();
    
    const int NUM_THREADS = 20;
    std::vector<std::thread> threads;
    
    // 多线程同时操作不同组件
    for (int i = 0; i < NUM_THREADS; ++i) {
        threads.emplace_back([&system, i]() {
            if (i % 3 == 0) {
                // 访问 Scheduler
                RequestState req;
                req.tokenizedPrompt = {1, 2, 3};
                system.scheduler->addRequest(req);
            } else if (i % 3 == 1) {
                // 访问 KVCache
                FloatArray key(100), value(100);
                system.kvCache->put(i, key, value);
            } else {
                // 访问 MemoryMonitor
                auto& monitor = MemoryMonitor::instance();
                monitor.getUsed();
            }
        });
    }
    
    // 等待所有线程完成
    for (auto& thread : threads) {
        thread.join();
    }
    
    // 如果没有死锁，测试通过
    SUCCEED();
    
    cleanupSystem(system);
}
```

### 10.2 竞争条件测试

**测试目标**：检测数据竞争

```bash
# 使用 ThreadSanitizer 编译和运行
make clean
make build BUILD_TYPE=Debug SANITIZER=thread
make test
```

## 11. 内存安全集成测试

### 11.1 内存泄漏检测

**测试目标**：验证长时间运行无内存泄漏

#### 测试用例 IT-MEM-003：长时间运行内存稳定性

```cpp
TEST(MemorySafetyTest, LongRunningStability) {
    auto system = initializeSystem();
    
    auto& monitor = MemoryMonitor::instance();
    size_t initialMemory = monitor.getUsed();
    
    // 运行大量请求
    HttpClient client("http://127.0.0.1:8082");
    
    for (int i = 0; i < 1000; ++i) {
        auto response = client.post("/generate", R"({
            "prompt": "Test",
            "max_tokens": 20
        })");
        EXPECT_EQ(response.statusCode, 200);
        
        // 每100个请求检查一次内存
        if (i % 100 == 0) {
            size_t currentMemory = monitor.getUsed();
            double memoryGrowthMB = (currentMemory - initialMemory) / (1024.0 * 1024.0);
            std::cout << "Requests: " << i << ", Memory growth: " 
                      << memoryGrowthMB << " MB" << std::endl;
            
            // 内存增长应该在合理范围内
            EXPECT_LT(memoryGrowthMB, 100.0);  // 不超过 100MB
        }
    }
    
    cleanupSystem(system);
}
```

### 11.2 Valgrind 检测

```bash
# 使用 Valgrind 检测内存问题
make clean
make build BUILD_TYPE=Debug
valgrind --leak-check=full --show-leak-kinds=all \
    ./build/bin/cllm_server \
    --model-path /path/to/model \
    --port 8080
```

## 12. 测试执行计划

### 12.1 测试执行顺序

```
阶段1：基础组件集成测试（1天）
├─> MemoryMonitor + KVCache
├─> ThreadPool + ModelExecutor
└─> BatchManager + ModelExecutor + KVCache

阶段2：调度层集成测试（2天）
├─> Scheduler + RequestQueue + RequestTracker
├─> Scheduler + BatchManager
└─> Scheduler + KVCache

阶段3：服务层集成测试（2天）
├─> HttpServer + RequestValidator
├─> HttpServer + Scheduler
└─> TokenizerManager + Scheduler

阶段4：端到端集成测试（2天）
├─> 完整请求处理流程
├─> 流式生成流程
└─> 并发请求处理

阶段5：错误场景测试（1天）
├─> 组件故障测试
└─> 错误传播测试

阶段6：性能集成测试（2天）
├─> 吞吐量测试
├─> 延迟测试
└─> 资源使用测试

阶段7：安全性测试（2天）
├─> 并发安全测试
└─> 内存安全测试
```

### 12.2 测试环境要求

| 项目 | 要求 |
|------|------|
| **操作系统** | macOS 15.5+ / Linux (Ubuntu 20.04+) |
| **CPU** | 8核以上 |
| **内存** | 16GB 以上 |
| **磁盘** | 50GB 可用空间 |
| **编译器** | GCC 10+ / Clang 12+ |
| **测试框架** | Google Test 1.12+ |
| **Python** | Python 3.9+ |

### 12.3 测试执行命令

```bash
# 1. 构建测试版本
cd cpp/cLLM
make clean
make build BUILD_TYPE=Debug BUILD_TESTS=ON

# 2. 运行单元测试
make test

# 3. 运行集成测试
./build/bin/integration_tests

# 4. 启动服务器进行端到端测试
make start &
sleep 5  # 等待服务器启动

# 5. 运行 Python 测试脚本
cd ../../tests
python3 test_api.py
python3 test_client.py

# 6. 运行性能测试
cd ../tools
python3 unified_benchmark.py

# 7. 停止服务器
cd ../cpp/cLLM
make stop
```

## 13. 测试覆盖率目标

### 13.1 覆盖率要求

| 覆盖率类型 | 目标 | 最低要求 |
|-----------|------|---------|
| **行覆盖率** | 85% | 75% |
| **函数覆盖率** | 90% | 80% |
| **分支覆盖率** | 75% | 65% |
| **集成场景覆盖** | 100% | 90% |

### 13.2 覆盖率测量

```bash
# 使用 gcov + lcov 生成覆盖率报告
make clean
make build BUILD_TYPE=Debug COVERAGE=ON
make test
make coverage

# 查看覆盖率报告
open build/coverage/index.html
```

## 14. 测试报告

### 14.1 报告内容

集成测试报告应包含以下内容：

1. **测试执行摘要**
   - 测试用例总数
   - 通过/失败/跳过数量
   - 测试覆盖率
   - 执行时间

2. **组件集成状态**
   - 各组件集成测试结果
   - 发现的问题列表
   - 修复建议

3. **性能指标**
   - 吞吐量（requests/sec, tokens/sec）
   - 延迟分布（P50, P95, P99）
   - 资源使用（CPU, 内存）
   - 与基线对比

4. **错误场景处理**
   - 错误处理测试结果
   - 错误传播验证
   - 系统恢复能力

5. **安全性检查**
   - 内存泄漏检测结果
   - 线程安全检查结果
   - 死锁检测结果

### 14.2 报告生成

```bash
# 生成 HTML 测试报告
./build/bin/integration_tests --gtest_output=xml:test_results.xml
python3 scripts/generate_test_report.py test_results.xml
```

## 15. 持续集成

### 15.1 CI 流程

```yaml
# .github/workflows/integration-test.yml
name: Integration Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  integration-test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential cmake
    
    - name: Build
      run: |
        cd cpp/cLLM
        make build BUILD_TYPE=Debug BUILD_TESTS=ON
    
    - name: Run Integration Tests
      run: |
        cd cpp/cLLM
        ./build/bin/integration_tests
    
    - name: Start Server
      run: |
        cd cpp/cLLM
        make start &
        sleep 10
    
    - name: Run Python Tests
      run: |
        cd tests
        python3 test_api.py
        python3 test_client.py
    
    - name: Generate Report
      run: |
        cd cpp/cLLM
        make coverage
    
    - name: Upload Coverage
      uses: codecov/codecov-action@v3
```

### 15.2 质量门禁

集成测试必须满足以下条件才能合并代码：

- ✅ 所有集成测试通过
- ✅ 代码覆盖率 ≥ 75%
- ✅ 无内存泄漏
- ✅ 无线程安全问题
- ✅ 性能指标不低于基线

## 16. 故障排查指南

### 16.1 常见集成问题

| 问题 | 可能原因 | 解决方案 |
|------|---------|---------|
| **组件初始化失败** | 依赖顺序错误 | 检查初始化顺序是否符合设计 |
| **请求处理超时** | 线程池资源不足 | 增加线程池大小 |
| **内存持续增长** | 内存泄漏 | 使用 Valgrind 检测 |
| **并发测试失败** | 线程安全问题 | 使用 ThreadSanitizer 检测 |
| **性能下降** | 批处理效率低 | 调整批处理大小参数 |

### 16.2 调试技巧

```bash
# 1. 启用详细日志
export CLLM_LOG_LEVEL=DEBUG
./build/bin/integration_tests

# 2. 使用 gdb 调试
gdb ./build/bin/integration_tests
(gdb) run
(gdb) bt  # 查看调用栈

# 3. 检查组件状态
curl http://localhost:8080/health
curl http://localhost:8080/stats
```

## 17. 附录

### 17.1 测试数据准备

```cpp
// 辅助函数：创建测试请求
RequestState createTestRequest(int id) {
    RequestState req;
    req.requestId = id;
    req.tokenizedPrompt = {1, 2, 3, 4, 5};
    req.maxTokens = 20;
    req.temperature = 0.7f;
    req.topK = 50;
    req.topP = 0.9f;
    return req;
}

// 辅助函数：初始化系统
SystemComponents initializeSystem() {
    SystemComponents sys;
    
    auto& monitor = MemoryMonitor::instance();
    monitor.setLimit(16 * 1024 * 1024 * 1024ULL);
    
    sys.threadPool = std::make_unique<ThreadPool>(8);
    sys.tokenizer = std::make_unique<TokenizerManager>("/path/to/model");
    sys.modelExecutor = std::make_unique<ModelExecutor>("/path/to/model", "fp16");
    sys.modelExecutor->loadModel();
    sys.kvCache = std::make_unique<KVCache>(100, 4096);
    sys.batchManager = std::make_unique<BatchManager>(
        sys.modelExecutor.get(),
        sys.kvCache.get(),
        8, 2048
    );
    sys.scheduler = std::make_unique<Scheduler>("/path/to/model", "fp16", 8, 2048);
    sys.scheduler->start();
    sys.httpServer = std::make_unique<HttpServer>("127.0.0.1", 8082);
    sys.httpServer->setScheduler(sys.scheduler.get());
    sys.httpServer->setTokenizer(sys.tokenizer.get());
    sys.httpServer->start();
    
    return sys;
}

// 辅助函数：清理系统
void cleanupSystem(SystemComponents& sys) {
    sys.httpServer->stop();
    sys.scheduler->stop();
    sys.batchManager.reset();
    sys.kvCache.reset();
    sys.modelExecutor->unloadModel();
    sys.modelExecutor.reset();
    sys.tokenizer.reset();
    sys.threadPool->shutdown();
    sys.threadPool.reset();
}
```

## 18. 补充测试场景

### 18.1 流式响应集成测试

**测试目标**：验证 HTTP 服务器正确处理流式响应，数据能够实时传递给客户端

#### 测试用例 IT-STREAM-001：流式文本生成

```cpp
TEST(StreamingResponseTest, StreamingTextGeneration) {
    // 初始化系统
    auto sys = initializeSystem();
    
    // 创建支持流式的 HTTP 客户端
    StreamingHttpClient client("http://127.0.0.1:8082");
    
    std::vector<std::string> receivedChunks;
    auto onChunk = [&](const std::string& chunk) {
        receivedChunks.push_back(chunk);
        std::cout << "Received chunk: " << chunk << std::endl;
    };
    
    // 发送流式生成请求
    GenerateRequest req;
    req.prompt = "Write a short story about a robot";
    req.maxTokens = 50;
    req.temperature = 0.8f;
    req.stream = true;
    
    client.postStream("/generate", req.toJson(), onChunk);
    
    // 验证：应该收到多个数据块
    EXPECT_GT(receivedChunks.size(), 1);
    
    // 验证：所有块组合后是完整的文本
    std::string fullText;
    for (const auto& chunk : receivedChunks) {
        fullText += chunk;
    }
    EXPECT_FALSE(fullText.empty());
    
    // 验证：每个块应该是有效的 JSON 或纯文本片段
    for (const auto& chunk : receivedChunks) {
        EXPECT_FALSE(chunk.empty());
    }
    
    cleanupSystem(sys);
}
```

#### 测试用例 IT-STREAM-002：流式响应中断处理

```cpp
TEST(StreamingResponseTest, StreamingInterruption) {
    auto sys = initializeSystem();
    
    StreamingHttpClient client("http://127.0.0.1:8082");
    
    std::vector<std::string> receivedChunks;
    int chunkCount = 0;
    auto onChunk = [&](const std::string& chunk) {
        receivedChunks.push_back(chunk);
        chunkCount++;
        
        // 在收到第3个块后中断连接
        if (chunkCount >= 3) {
            client.cancel();
        }
    };
    
    GenerateRequest req;
    req.prompt = "This is a long text that should be interrupted";
    req.maxTokens = 100;
    req.stream = true;
    
    client.postStream("/generate", req.toJson(), onChunk);
    
    // 验证：只收到了部分数据块
    EXPECT_EQ(receivedChunks.size(), 3);
    
    // 验证：服务器应该正确处理中断，不会崩溃
    auto stats = sys.scheduler->getStats();
    EXPECT_GE(stats.totalRequests, 1);
    
    cleanupSystem(sys);
}
```

### 18.2 错误处理集成测试

**测试目标**：验证各组件在错误场景下的正确处理和错误传播

#### 测试用例 IT-ERROR-001：模型加载失败处理

```cpp
TEST(ErrorHandlingTest, ModelLoadFailure) {
    // 尝试加载不存在的模型
    EXPECT_THROW({
        ModelExecutor executor("/nonexistent/model/path", "fp16");
        executor.loadModel();
    }, std::runtime_error);
    
    // 验证：系统应该能够优雅地处理错误
    // 验证：不会导致内存泄漏
    // 验证：错误信息应该清晰明确
}
```

#### 测试用例 IT-ERROR-002：内存不足处理

```cpp
TEST(ErrorHandlingTest, OutOfMemoryHandling) {
    auto& monitor = MemoryMonitor::instance();
    monitor.setLimit(10 * 1024 * 1024);  // 设置极低的内存限制
    
    auto sys = initializeSystem();
    
    // 尝试创建大量请求以触发内存不足
    std::vector<size_t> requestIds;
    try {
        for (int i = 0; i < 1000; ++i) {
            RequestState req;
            req.tokenizedPrompt = std::vector<int>(10000, 1);  // 大量 token
            req.maxTokens = 1000;
            auto requestId = sys.scheduler->addRequest(req);
            requestIds.push_back(requestId);
        }
    } catch (const std::runtime_error& e) {
        // 预期会抛出内存不足异常
        std::cout << "Expected OOM error: " << e.what() << std::endl;
    }
    
    // 验证：系统应该拒绝新请求而不是崩溃
    // 验证：已有请求应该能够继续处理
    auto stats = sys.scheduler->getStats();
    EXPECT_GE(stats.rejectedRequests, 0);
    
    cleanupSystem(sys);
}
```

#### 测试用例 IT-ERROR-003：请求超时处理

```cpp
TEST(ErrorHandlingTest, RequestTimeoutHandling) {
    auto sys = initializeSystem();
    
    // 创建一个会超时的请求
    RequestState req;
    req.tokenizedPrompt = {1, 2, 3};
    req.maxTokens = 10000;  // 设置极长的生成长度
    req.timeoutMs = 100;    // 设置极短的超时时间
    
    auto requestId = sys.scheduler->addRequest(req);
    
    // 等待超时
    std::this_thread::sleep_for(std::chrono::milliseconds(200));
    
    // 验证：请求应该被标记为超时
    auto result = sys.scheduler->getRequestResult(requestId);
    EXPECT_TRUE(result.isTimedOut);
    
    // 验证：系统应该释放相关资源
    auto stats = sys.scheduler->getStats();
    EXPECT_GT(stats.timedOutRequests, 0);
    
    cleanupSystem(sys);
}
```

#### 测试用例 IT-ERROR-004：无效参数处理

```cpp
TEST(ErrorHandlingTest, InvalidParameterHandling) {
    auto sys = initializeSystem();
    
    HttpClient client("http://127.0.0.1:8082");
    
    // 测试1：负数的 max_tokens
    {
        auto response = client.post("/generate", R"({
            "prompt": "Hello",
            "max_tokens": -10,
            "temperature": 0.7
        })");
        
        EXPECT_EQ(response.statusCode, 400);
        auto json = nlohmann::json::parse(response.body);
        EXPECT_TRUE(json.contains("error"));
    }
    
    // 测试2：超出范围的 temperature
    {
        auto response = client.post("/generate", R"({
            "prompt": "Hello",
            "max_tokens": 50,
            "temperature": 10.0
        })");
        
        EXPECT_EQ(response.statusCode, 400);
    }
    
    // 测试3：空 prompt
    {
        auto response = client.post("/generate", R"({
            "prompt": "",
            "max_tokens": 50,
            "temperature": 0.7
        })");
        
        EXPECT_EQ(response.statusCode, 400);
    }
    
    cleanupSystem(sys);
}
```

### 18.3 并发压力集成测试

**测试目标**：验证系统在高并发场景下的稳定性和性能

#### 测试用例 IT-CONC-001：高并发请求处理

```cpp
TEST(ConcurrencyTest, HighConcurrencyRequests) {
    auto sys = initializeSystem();
    
    const int numThreads = 50;
    const int requestsPerThread = 10;
    std::atomic<int> successCount(0);
    std::atomic<int> failureCount(0);
    
    std::vector<std::thread> threads;
    
    for (int t = 0; t < numThreads; ++t) {
        threads.emplace_back([&]() {
            HttpClient client("http://127.0.0.1:8082");
            
            for (int i = 0; i < requestsPerThread; ++i) {
                try {
                    auto response = client.post("/generate", R"({
                        "prompt": "Concurrent test",
                        "max_tokens": 20,
                        "temperature": 0.7
                    })");
                    
                    if (response.statusCode == 200) {
                        successCount++;
                    } else {
                        failureCount++;
                    }
                } catch (const std::exception& e) {
                    failureCount++;
                }
            }
        });
    }
    
    // 等待所有线程完成
    for (auto& thread : threads) {
        thread.join();
    }
    
    // 验证：大部分请求应该成功
    int totalRequests = numThreads * requestsPerThread;
    float successRate = static_cast<float>(successCount) / totalRequests;
    EXPECT_GT(successRate, 0.95f);
    
    // 验证：系统应该保持稳定
    auto stats = sys.scheduler->getStats();
    EXPECT_GT(stats.completedRequests, totalRequests * 0.9);
    
    cleanupSystem(sys);
}
```

#### 测试用例 IT-CONC-002：并发资源竞争

```cpp
TEST(ConcurrencyTest, ConcurrentResourceContention) {
    auto sys = initializeSystem();
    
    const int numThreads = 20;
    std::atomic<int> cacheHits(0);
    std::atomic<int> cacheMisses(0);
    
    std::vector<std::thread> threads;
    
    // 所有线程使用相同的 prompt，测试 KV 缓存竞争
    std::string sharedPrompt = "This is a shared prompt for cache testing";
    
    for (int t = 0; t < numThreads; ++t) {
        threads.emplace_back([&]() {
            HttpClient client("http://127.0.0.1:8082");
            
            auto response = client.post("/generate", R"({
                "prompt": ")" + sharedPrompt + R"(",
                "max_tokens": 30,
                "temperature": 0.7
            })");
            
            if (response.statusCode == 200) {
                // 检查是否命中缓存（通过响应时间判断）
                auto json = nlohmann::json::parse(response.body);
                if (json.contains("cache_hit")) {
                    if (json["cache_hit"]) {
                        cacheHits++;
                    } else {
                        cacheMisses++;
                    }
                }
            }
        });
    }
    
    for (auto& thread : threads) {
        thread.join();
    }
    
    // 验证：缓存命中率应该较高
    int totalAccesses = cacheHits + cacheMisses;
    if (totalAccesses > 0) {
        float hitRate = static_cast<float>(cacheHits) / totalAccesses;
        EXPECT_GT(hitRate, 0.5f);
    }
    
    cleanupSystem(sys);
}
```

### 18.4 资源清理集成测试

**测试目标**：验证组件销毁时正确释放所有资源

#### 测试用例 IT-RESOURCE-001：组件销毁资源释放

```cpp
TEST(ResourceCleanupTest, ComponentDestruction) {
    // 记录初始内存使用
    size_t initialMemory = getCurrentMemoryUsage();
    
    {
        // 创建并使用组件
        auto sys = initializeSystem();
        
        // 执行一些操作
        HttpClient client("http://127.0.0.1:8082");
        for (int i = 0; i < 10; ++i) {
            auto response = client.post("/generate", R"({
                "prompt": "Test",
                "max_tokens": 20,
                "temperature": 0.7
            })");
        }
        
        // 离开作用域，触发自动清理
    }
    
    // 等待资源完全释放
    std::this_thread::sleep_for(std::chrono::seconds(2));
    
    // 验证：内存应该被释放
    size_t finalMemory = getCurrentMemoryUsage();
    size_t memoryDiff = finalMemory - initialMemory;
    
    // 允许一定的内存增长，但不应该太大
    EXPECT_LT(memoryDiff, 100 * 1024 * 1024);  // 小于 100MB
}
```

#### 测试用例 IT-RESOURCE-002：异常情况下的资源清理

```cpp
TEST(ResourceCleanupTest, ExceptionalResourceCleanup) {
    size_t initialMemory = getCurrentMemoryUsage();
    
    try {
        auto sys = initializeSystem();
        
        // 触发异常
        throw std::runtime_error("Simulated exception");
        
        // 这行代码不会执行
        cleanupSystem(sys);
        
    } catch (const std::exception& e) {
        // 异常被捕获
        std::cout << "Caught exception: " << e.what() << std::endl;
    }
    
    // 验证：即使发生异常，资源也应该被正确释放
    std::this_thread::sleep_for(std::chrono::seconds(2));
    
    size_t finalMemory = getCurrentMemoryUsage();
    size_t memoryDiff = finalMemory - initialMemory;
    
    EXPECT_LT(memoryDiff, 100 * 1024 * 1024);
}
```

### 18.5 配置变更集成测试

**测试目标**：验证运行时配置变更的正确性和影响

#### 测试用例 IT-CONFIG-001：动态调整批处理大小

```cpp
TEST(ConfigurationTest, DynamicBatchSizeAdjustment) {
    auto sys = initializeSystem();
    
    // 获取初始配置
    auto initialConfig = sys.scheduler->getConfig();
    size_t initialBatchSize = initialConfig.maxBatchSize;
    
    // 调整批处理大小
    size_t newBatchSize = 16;
    sys.scheduler->setConfig({
        .maxBatchSize = newBatchSize,
        .maxContextLength = initialConfig.maxContextLength
    });
    
    // 验证：配置应该被更新
    auto updatedConfig = sys.scheduler->getConfig();
    EXPECT_EQ(updatedConfig.maxBatchSize, newBatchSize);
    
    // 提交请求验证新配置生效
    std::vector<size_t> requestIds;
    for (int i = 0; i < 20; ++i) {
        RequestState req;
        req.tokenizedPrompt = {1, 2, 3};
        req.maxTokens = 10;
        requestIds.push_back(sys.scheduler->addRequest(req));
    }
    
    // 等待处理
    std::this_thread::sleep_for(std::chrono::milliseconds(500));
    
    // 验证：批处理应该使用新的大小
    auto stats = sys.scheduler->getStats();
    // 批处理大小应该接近新的配置值
    EXPECT_LE(stats.averageBatchSize, newBatchSize);
    
    cleanupSystem(sys);
}
```

#### 测试用例 IT-CONFIG-002：动态调整内存限制

```cpp
TEST(ConfigurationTest, DynamicMemoryLimitAdjustment) {
    auto& monitor = MemoryMonitor::instance();
    
    // 设置初始内存限制
    size_t initialLimit = 1024 * 1024 * 1024;  // 1GB
    monitor.setLimit(initialLimit);
    
    auto sys = initializeSystem();
    
    // 动态降低内存限制
    size_t newLimit = 512 * 1024 * 1024;  // 512MB
    monitor.setLimit(newLimit);
    
    // 验证：新的限制应该生效
    EXPECT_EQ(monitor.getLimit(), newLimit);
    
    // 尝试添加大量请求
    std::vector<size_t> requestIds;
    for (int i = 0; i < 100; ++i) {
        RequestState req;
        req.tokenizedPrompt = std::vector<int>(1000, 1);
        req.maxTokens = 100;
        
        try {
            auto requestId = sys.scheduler->addRequest(req);
            requestIds.push_back(requestId);
        } catch (const std::runtime_error& e) {
            // 预期在内存不足时会拒绝请求
            break;
        }
    }
    
    // 验证：应该有请求被拒绝
    auto stats = sys.scheduler->getStats();
    EXPECT_GT(stats.rejectedRequests, 0);
    
    cleanupSystem(sys);
}
```

### 18.6 监控和统计集成测试

**测试目标**：验证各组件统计信息的准确性和一致性

#### 测试用例 IT-MONITOR-001：统计信息准确性

```cpp
TEST(MonitoringTest, StatisticsAccuracy) {
    auto sys = initializeSystem();
    
    // 记录初始统计
    auto initialStats = sys.scheduler->getStats();
    
    // 执行已知数量的请求
    const int numRequests = 50;
    std::vector<size_t> requestIds;
    
    for (int i = 0; i < numRequests; ++i) {
        RequestState req;
        req.tokenizedPrompt = {1, 2, 3, 4, 5};
        req.maxTokens = 10;
        requestIds.push_back(sys.scheduler->addRequest(req));
    }
    
    // 等待所有请求完成
    for (auto requestId : requestIds) {
        auto result = sys.scheduler->getRequestResult(requestId);
        while (!result.isCompleted) {
            std::this_thread::sleep_for(std::chrono::milliseconds(50));
            result = sys.scheduler->getRequestResult(requestId);
        }
    }
    
    // 获取最终统计
    auto finalStats = sys.scheduler->getStats();
    
    // 验证：统计信息应该准确
    EXPECT_EQ(finalStats.completedRequests - initialStats.completedRequests, numRequests);
    EXPECT_EQ(finalStats.totalRequests - initialStats.totalRequests, numRequests);
    
    // 验证：其他统计指标应该合理
    EXPECT_GT(finalStats.averageProcessingTime, 0);
    EXPECT_GT(finalStats.throughput, 0);
    
    cleanupSystem(sys);
}
```

#### 测试用例 IT-MONITOR-002：跨组件统计一致性

```cpp
TEST(MonitoringTest, CrossComponentStatisticsConsistency) {
    auto sys = initializeSystem();
    
    // 执行一些请求
    const int numRequests = 20;
    std::vector<size_t> requestIds;
    
    for (int i = 0; i < numRequests; ++i) {
        RequestState req;
        req.tokenizedPrompt = {1, 2, 3};
        req.maxTokens = 15;
        requestIds.push_back(sys.scheduler->addRequest(req));
    }
    
    // 等待完成
    for (auto requestId : requestIds) {
        auto result = sys.scheduler->getRequestResult(requestId);
        while (!result.isCompleted) {
            std::this_thread::sleep_for(std::chrono::milliseconds(50));
            result = sys.scheduler->getRequestResult(requestId);
        }
    }
    
    // 获取各组件的统计信息
    auto schedulerStats = sys.scheduler->getStats();
    auto cacheStats = sys.kvCache->getStats();
    auto batchStats = sys.batchManager->getStats();
    
    // 验证：各组件的统计应该一致
    EXPECT_EQ(schedulerStats.completedRequests, numRequests);
    EXPECT_GE(cacheStats.totalAccesses, numRequests);
    EXPECT_GE(batchStats.totalBatches, 1);
    
    // 验证：处理的总 token 数应该一致
    size_t totalTokens = 0;
    for (auto requestId : requestIds) {
        auto result = sys.scheduler->getRequestResult(requestId);
        totalTokens += result.generatedTokens.size();
    }
    
    EXPECT_GT(totalTokens, 0);
    
    cleanupSystem(sys);
}
```

### 18.7 跨组件数据一致性测试

**测试目标**：验证数据在多个组件间传递时的一致性和完整性

#### 测试用例 IT-DATA-001：请求状态一致性

```cpp
TEST(DataConsistencyTest, RequestStateConsistency) {
    auto sys = initializeSystem();
    
    // 创建请求
    RequestState originalReq;
    originalReq.tokenizedPrompt = {1, 2, 3, 4, 5};
    originalReq.maxTokens = 20;
    originalReq.temperature = 0.7f;
    originalReq.topK = 50;
    originalReq.topP = 0.9f;
    
    auto requestId = sys.scheduler->addRequest(originalReq);
    
    // 从不同组件获取请求状态
    auto schedulerState = sys.scheduler->getRequestState(requestId);
    auto trackerState = sys.scheduler->getTracker().getRequestState(requestId);
    
    // 验证：状态应该一致
    EXPECT_EQ(schedulerState.status, trackerState.status);
    EXPECT_EQ(schedulerState.tokenizedPrompt, originalReq.tokenizedPrompt);
    EXPECT_FLOAT_EQ(schedulerState.temperature, originalReq.temperature);
    
    // 等待完成
    auto result = sys.scheduler->getRequestResult(requestId);
    while (!result.isCompleted) {
        std::this_thread::sleep_for(std::chrono::milliseconds(50));
        result = sys.scheduler->getRequestResult(requestId);
    }
    
    // 验证：最终状态应该一致
    auto finalSchedulerState = sys.scheduler->getRequestState(requestId);
    auto finalTrackerState = sys.scheduler->getTracker().getRequestState(requestId);
    
    EXPECT_EQ(finalSchedulerState.status, RequestStatus::Completed);
    EXPECT_EQ(finalTrackerState.status, RequestStatus::Completed);
    
    cleanupSystem(sys);
}
```

#### 测试用例 IT-DATA-002：KV 缓存数据一致性

```cpp
TEST(DataConsistencyTest, KVCacheDataConsistency) {
    auto sys = initializeSystem();
    
    // 创建两个使用相同 prompt 的请求
    std::string prompt = "This is a test prompt for cache consistency";
    auto tokens = sys.tokenizer->encode(prompt);
    
    RequestState req1, req2;
    req1.tokenizedPrompt = tokens;
    req1.maxTokens = 10;
    req2.tokenizedPrompt = tokens;
    req2.maxTokens = 10;
    
    auto id1 = sys.scheduler->addRequest(req1);
    auto id2 = sys.scheduler->addRequest(req2);
    
    // 等待第一个请求完成
    auto result1 = sys.scheduler->getRequestResult(id1);
    while (!result1.isCompleted) {
        std::this_thread::sleep_for(std::chrono::milliseconds(50));
        result1 = sys.scheduler->getRequestResult(id1);
    }
    
    // 等待第二个请求完成
    auto result2 = sys.scheduler->getRequestResult(id2);
    while (!result2.isCompleted) {
        std::this_thread::sleep_for(std::chrono::milliseconds(50));
        result2 = sys.scheduler->getRequestResult(id2);
    }
    
    // 验证：两个请求的输出应该相同（因为使用了相同的 prompt）
    EXPECT_EQ(result1.generatedTokens, result2.generatedTokens);
    
    // 验证：第二个请求应该命中缓存
    auto cacheStats = sys.kvCache->getStats();
    EXPECT_GT(cacheStats.hitCount, 0);
    
    cleanupSystem(sys);
}
```

### 18.8 性能回归集成测试

**测试目标**：验证系统性能不低于基线，检测性能退化

#### 测试用例 IT-PERF-001：吞吐量基线测试

```cpp
TEST(PerformanceRegressionTest, ThroughputBaseline) {
    auto sys = initializeSystem();
    
    const int numRequests = 100;
    const int maxTokensPerRequest = 20;
    
    auto startTime = std::chrono::high_resolution_clock::now();
    
    // 提交所有请求
    std::vector<size_t> requestIds;
    for (int i = 0; i < numRequests; ++i) {
        RequestState req;
        req.tokenizedPrompt = {1, 2, 3, 4, 5};
        req.maxTokens = maxTokensPerRequest;
        requestIds.push_back(sys.scheduler->addRequest(req));
    }
    
    // 等待所有请求完成
    for (auto requestId : requestIds) {
        auto result = sys.scheduler->getRequestResult(requestId);
        while (!result.isCompleted) {
            std::this_thread::sleep_for(std::chrono::milliseconds(10));
            result = sys.scheduler->getRequestResult(requestId);
        }
    }
    
    auto endTime = std::chrono::high_resolution_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(endTime - startTime);
    
    // 计算吞吐量
    float throughput = static_cast<float>(numRequests) / (duration.count() / 1000.0f);
    
    std::cout << "Throughput: " << throughput << " requests/second" << std::endl;
    
    // 验证：吞吐量应该不低于基线（假设基线为 10 req/s）
    const float baselineThroughput = 10.0f;
    EXPECT_GE(throughput, baselineThroughput);
    
    cleanupSystem(sys);
}
```

#### 测试用例 IT-PERF-002：延迟基线测试

```cpp
TEST(PerformanceRegressionTest, LatencyBaseline) {
    auto sys = initializeSystem();
    
    const int numRequests = 50;
    std::vector<float> latencies;
    
    for (int i = 0; i < numRequests; ++i) {
        RequestState req;
        req.tokenizedPrompt = {1, 2, 3};
        req.maxTokens = 10;
        
        auto startTime = std::chrono::high_resolution_clock::now();
        auto requestId = sys.scheduler->addRequest(req);
        
        auto result = sys.scheduler->getRequestResult(requestId);
        while (!result.isCompleted) {
            std::this_thread::sleep_for(std::chrono::milliseconds(10));
            result = sys.scheduler->getRequestResult(requestId);
        }
        
        auto endTime = std::chrono::high_resolution_clock::now();
        auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(endTime - startTime);
        latencies.push_back(static_cast<float>(duration.count()));
    }
    
    // 计算平均延迟和 P95 延迟
    std::sort(latencies.begin(), latencies.end());
    float avgLatency = std::accumulate(latencies.begin(), latencies.end(), 0.0f) / numRequests;
    float p95Latency = latencies[static_cast<size_t>(numRequests * 0.95)];
    
    std::cout << "Average latency: " << avgLatency << " ms" << std::endl;
    std::cout << "P95 latency: " << p95Latency << " ms" << std::endl;
    
    // 验证：延迟应该不超过基线（假设基线为 500ms）
    const float baselineLatency = 500.0f;
    EXPECT_LE(avgLatency, baselineLatency);
    EXPECT_LE(p95Latency, baselineLatency * 2.0f);
    
    cleanupSystem(sys);
}
```

### 18.9 安全性集成测试

**测试目标**：验证系统在安全方面的防护措施

#### 测试用例 IT-SEC-001：输入验证和注入防护

```cpp
TEST(SecurityTest, InputValidationAndInjectionProtection) {
    auto sys = initializeSystem();
    
    HttpClient client("http://127.0.0.1:8082");
    
    // 测试1：SQL 注入尝试
    {
        auto response = client.post("/generate", R"({
            "prompt": "'; DROP TABLE users; --",
            "max_tokens": 20,
            "temperature": 0.7
        })");
        
        // 应该被拒绝或安全处理
        EXPECT_TRUE(response.statusCode == 400 || response.statusCode == 200);
    }
    
    // 测试2：XSS 尝试
    {
        auto response = client.post("/generate", R"({
            "prompt": "<script>alert('xss')</script>",
            "max_tokens": 20,
            "temperature": 0.7
        })");
        
        EXPECT_TRUE(response.statusCode == 400 || response.statusCode == 200);
    }
    
    // 测试3：超长输入
    {
        std::string longPrompt(100000, 'a');  // 100KB 的文本
        auto response = client.post("/generate", R"({
            "prompt": ")" + longPrompt + R"(",
            "max_tokens": 20,
            "temperature": 0.7
        })");
        
        // 应该被拒绝
        EXPECT_EQ(response.statusCode, 400);
    }
    
    cleanupSystem(sys);
}
```

#### 测试用例 IT-SEC-002：资源耗尽防护

```cpp
TEST(SecurityTest, ResourceExhaustionProtection) {
    auto sys = initializeSystem();
    
    HttpClient client("http://127.0.0.1:8082");
    
    // 尝试发送大量请求以耗尽资源
    const int numRequests = 10000;
    int successCount = 0;
    
    for (int i = 0; i < numRequests; ++i) {
        auto response = client.post("/generate", R"({
            "prompt": "Test",
            "max_tokens": 1000,
            "temperature": 0.7
        })");
        
        if (response.statusCode == 200) {
            successCount++;
        } else if (response.statusCode == 429) {
            // Too Many Requests - 限流生效
            break;
        }
    }
    
    // 验证：应该有请求被拒绝（限流）
    EXPECT_LT(successCount, numRequests);
    
    cleanupSystem(sys);
}
```

### 17.2 参考文档

- [组件交互设计.md](./组件交互设计.md)
- [cLLM详细设计.md](./cLLM详细设计.md)
- [测试设计文档.md](./测试设计文档.md)
- [C++编程规范.md](../docs/C++编程规范.md)

---

**文档版本**: 1.0  
**最后更新**: 2026-01-09  
**维护者**: cLLM 开发团队
