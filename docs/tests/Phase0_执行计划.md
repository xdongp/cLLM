# Phase 0: å‡†å¤‡é˜¶æ®µ æ‰§è¡Œè®¡åˆ’

**è´Ÿè´£Agent**: Agent-0  
**é¢„è®¡è€—æ—¶**: 2å°æ—¶5åˆ†é’Ÿ  
**ä¾èµ–**: æ—   
**æ‰§è¡Œæ—¶é—´**: T+0h ~ T+2h5m  

---

## ðŸ“‹ é˜¶æ®µç›®æ ‡

å‡†å¤‡å®Œæ•´çš„æµ‹è¯•çŽ¯å¢ƒï¼ŒåŒ…æ‹¬æ¨¡åž‹ä¸‹è½½ã€æµ‹è¯•æ•°æ®ç”Ÿæˆã€ç¼–è¯‘æµ‹è¯•ç¨‹åºå’ŒçŽ¯å¢ƒéªŒè¯ã€‚

---

## ðŸ“Š ä»»åŠ¡æ¸…å•

| ä»»åŠ¡ID | ä»»åŠ¡åç§° | è€—æ—¶ | ä¼˜å…ˆçº§ | çŠ¶æ€ |
|--------|---------|------|--------|------|
| P0.1 | éªŒè¯ Qwen3 æ¨¡åž‹ | 5min | é«˜ | â³ å¾…æ‰§è¡Œ |
| P0.2 | ç”Ÿæˆæµ‹è¯•æ•°æ® | 30min | é«˜ | â³ å¾…æ‰§è¡Œ |
| P0.3 | é…ç½®çŽ¯å¢ƒå˜é‡ | 15min | é«˜ | â³ å¾…æ‰§è¡Œ |
| P0.4 | ç¼–è¯‘æ‰€æœ‰æµ‹è¯•ç¨‹åº | 60min | é«˜ | â³ å¾…æ‰§è¡Œ |
| P0.5 | éªŒè¯çŽ¯å¢ƒå°±ç»ª | 15min | é«˜ | â³ å¾…æ‰§è¡Œ |

**æ€»è®¡**: 5ä¸ªä»»åŠ¡ï¼Œ125åˆ†é’Ÿï¼ˆ2å°æ—¶5åˆ†é’Ÿï¼‰

---

## ðŸ“ è¯¦ç»†ä»»åŠ¡è¯´æ˜Ž

### P0.1: éªŒè¯ Qwen3 æ¨¡åž‹ (5åˆ†é’Ÿ)

**ç›®æ ‡**: éªŒè¯æœ¬åœ°å·²æœ‰çš„ Qwen3-0.6B æ¨¡åž‹å®Œæ•´æ€§

**è¯´æ˜Ž**: æœ¬åœ°å·²å­˜åœ¨å®Œæ•´æ¨¡åž‹åœ¨ `model/Qwen/Qwen3-0.6B/` ç›®å½•ï¼Œæ— éœ€é‡æ–°ä¸‹è½½

**æ‰§è¡Œå‘½ä»¤**:
```bash
# æ£€æŸ¥æ¨¡åž‹æ–‡ä»¶å®Œæ•´æ€§
MODEL_PATH="model/Qwen/Qwen3-0.6B"

# éªŒè¯å¿…è¦æ–‡ä»¶
test -f "${MODEL_PATH}/tokenizer.json" && echo "âœ… tokenizer.json"
test -f "${MODEL_PATH}/tokenizer_config.json" && echo "âœ… tokenizer_config.json"
test -f "${MODEL_PATH}/config.json" && echo "âœ… config.json"
test -f "${MODEL_PATH}/model.safetensors" && echo "âœ… model.safetensors"
test -f "${MODEL_PATH}/vocab.json" && echo "âœ… vocab.json"
test -f "${MODEL_PATH}/merges.txt" && echo "âœ… merges.txt"

# æ£€æŸ¥æ¨¡åž‹å¤§å°
du -sh "${MODEL_PATH}"
```

**éªŒè¯æ ‡å‡†**:
```bash
# æ‰€æœ‰å¿…éœ€æ–‡ä»¶å¿…é¡»å­˜åœ¨
# æ¨¡åž‹å¤§å°çº¦ 1.5GB (model.safetensors çº¦ 1.5GB)
```

**è¾“å‡º**:
- `model/Qwen/Qwen3-0.6B/` ç›®å½•åŒ…å«å®Œæ•´æ¨¡åž‹æ–‡ä»¶
- æ¨¡åž‹å¤§å°çº¦ 1.5GB

---

### P0.2: ç”Ÿæˆæµ‹è¯•æ•°æ® (30åˆ†é’Ÿ)

**ç›®æ ‡**: ç”Ÿæˆæ‰€æœ‰æµ‹è¯•æ‰€éœ€çš„æ•°æ®æ–‡ä»¶

**æ‰§è¡Œå‘½ä»¤**:
```bash
# è¿è¡Œæµ‹è¯•æ•°æ®ç”Ÿæˆè„šæœ¬
python3 scripts/generate_test_data.py

# è„šæœ¬ä¼šç”Ÿæˆä»¥ä¸‹æ•°æ®ï¼š
# - test_data/tokenizer_test_data.json
# - test_data/inference_test_data.json
# - test_data/performance_test_data.json
# - test_data/stress_test_data.json
# - test_data/e2e_scenarios.json
```

**ç”Ÿæˆçš„æµ‹è¯•æ•°æ®**:

1. **Tokenizer æµ‹è¯•æ•°æ®** (`tokenizer_test_data.json`):
```json
{
  "english_texts": [
    "Hello, world!",
    "The quick brown fox jumps over the lazy dog.",
    "Artificial Intelligence is transforming our world."
  ],
  "chinese_texts": [
    "ä½ å¥½ï¼Œä¸–ç•Œï¼",
    "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜æˆ‘ä»¬çš„ä¸–ç•Œã€‚",
    "è‡ªç„¶è¯­è¨€å¤„ç†æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯ã€‚"
  ],
  "mixed_texts": [
    "Hello ä¸–ç•Œï¼",
    "AIäººå·¥æ™ºèƒ½ and Machine Learningæœºå™¨å­¦ä¹ "
  ],
  "special_chars": [
    "ðŸ˜€ðŸŽ‰ðŸš€",
    "Symbol: @#$%^&*()",
    "Unicode: \u4e2d\u6587"
  ]
}
```

2. **æŽ¨ç†æµ‹è¯•æ•°æ®** (`inference_test_data.json`):
```json
{
  "prompts": [
    "What is the capital of China?",
    "Explain quantum computing in simple terms.",
    "Write a Python function to calculate factorial."
  ],
  "expected_keywords": [
    ["Beijing", "capital"],
    ["quantum", "computing", "bits"],
    ["def", "factorial", "return"]
  ]
}
```

3. **æ€§èƒ½æµ‹è¯•æ•°æ®** (`performance_test_data.json`):
```json
{
  "batch_sizes": [1, 4, 8, 16],
  "sequence_lengths": [10, 50, 100, 500, 1000],
  "test_iterations": 100
}
```

**éªŒè¯æ ‡å‡†**:
```bash
# æ£€æŸ¥æ•°æ®æ–‡ä»¶
ls -lh test_data/*.json
wc -l test_data/*.json

# éªŒè¯JSONæ ¼å¼
python3 -m json.tool test_data/tokenizer_test_data.json > /dev/null && echo "âœ… Valid JSON"
```

**è¾“å‡º**:
- `test_data/` ç›®å½•åŒ…å«5ä¸ªæµ‹è¯•æ•°æ®æ–‡ä»¶
- æ€»å¤§å°çº¦ 10MB

---

### P0.3: é…ç½®çŽ¯å¢ƒå˜é‡ (15åˆ†é’Ÿ)

**ç›®æ ‡**: è®¾ç½®æµ‹è¯•æ‰€éœ€çš„æ‰€æœ‰çŽ¯å¢ƒå˜é‡

**æ‰§è¡Œå‘½ä»¤**:
```bash
# åˆ›å»ºçŽ¯å¢ƒé…ç½®æ–‡ä»¶
cat > test_env.sh << 'EOF'
#!/bin/bash

# é¡¹ç›®æ ¹ç›®å½•
export CLLM_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# æ¨¡åž‹è·¯å¾„ (ä½¿ç”¨æœ¬åœ°å·²æœ‰çš„ Qwen3-0.6B æ¨¡åž‹)
export CLLM_TEST_MODEL_PATH="${CLLM_ROOT}/model/Qwen/Qwen3-0.6B"

# æµ‹è¯•æ•°æ®è·¯å¾„
export CLLM_TEST_DATA_PATH="${CLLM_ROOT}/tests/data"

# æµ‹è¯•æŠ¥å‘Šè·¯å¾„
export CLLM_TEST_REPORTS="${CLLM_ROOT}/test_reports"

# æ—¥å¿—è·¯å¾„
export CLLM_LOG_DIR="${CLLM_ROOT}/logs"

# çº¿ç¨‹æ•°
export CLLM_NUM_THREADS=8

# è®¾å¤‡
export CLLM_DEVICE="cpu"  # æˆ– "cuda:0"

# æ—¥å¿—çº§åˆ«
export CLLM_LOG_LEVEL="INFO"

echo "âœ… Environment configured:"
echo "  MODEL_PATH: ${CLLM_TEST_MODEL_PATH}"
echo "  DATA_PATH: ${CLLM_TEST_DATA_PATH}"
echo "  REPORTS: ${CLLM_TEST_REPORTS}"
echo "  LOG_DIR: ${CLLM_LOG_DIR}"
EOF

chmod +x test_env.sh

# åŠ è½½çŽ¯å¢ƒå˜é‡
source test_env.sh

# åˆ›å»ºå¿…è¦ç›®å½•
mkdir -p "${CLLM_TEST_REPORTS}"
mkdir -p "${CLLM_LOG_DIR}"
```

**éªŒè¯æ ‡å‡†**:
```bash
# éªŒè¯çŽ¯å¢ƒå˜é‡
echo "MODEL_PATH: ${CLLM_TEST_MODEL_PATH}"
echo "DATA_PATH: ${CLLM_TEST_DATA_PATH}"

# éªŒè¯ç›®å½•å­˜åœ¨
test -d "${CLLM_TEST_MODEL_PATH}" && echo "âœ… Model directory exists"
test -d "${CLLM_TEST_DATA_PATH}" && echo "âœ… Data directory exists"
test -d "${CLLM_TEST_REPORTS}" && echo "âœ… Reports directory exists"
```

**è¾“å‡º**:
- `test_env.sh` é…ç½®æ–‡ä»¶
- æ‰€æœ‰å¿…è¦ç›®å½•å·²åˆ›å»º

---

### P0.4: ç¼–è¯‘æ‰€æœ‰æµ‹è¯•ç¨‹åº (60åˆ†é’Ÿ)

**ç›®æ ‡**: ç¼–è¯‘æ‰€æœ‰æµ‹è¯•äºŒè¿›åˆ¶æ–‡ä»¶

**æ‰§è¡Œå‘½ä»¤**:
```bash
# è¿›å…¥æž„å»ºç›®å½•
cd build

# é…ç½® CMakeï¼ˆå¯ç”¨æµ‹è¯•å’Œ tokenizers-cppï¼‰
cmake .. \
  -DCMAKE_BUILD_TYPE=Release \
  -DUSE_TOKENIZERS_CPP=ON \
  -DBUILD_TESTS=ON \
  -DCMAKE_CXX_STANDARD=17

# ç¼–è¯‘æ‰€æœ‰æµ‹è¯•ï¼ˆä½¿ç”¨8ä¸ªå¹¶è¡Œä»»åŠ¡ï¼‰
make -j8 all_tests

# æˆ–åˆ†åˆ«ç¼–è¯‘å„ä¸ªæµ‹è¯•
make -j8 test_http_server
make -j8 test_hf_tokenizer
make -j8 test_model_executor
make -j8 test_libtorch_backend
make -j8 test_qwen3_model
make -j8 test_http_tokenizer_integration
make -j8 test_tokenizer_executor_integration
make -j8 test_executor_backend_integration
make -j8 test_backend_qwen3_integration
make -j8 test_frontend_subsystem
make -j8 test_inference_subsystem
make -j8 test_e2e_subsystem
make -j8 test_system_functionality
make -j8 test_performance_benchmark
make -j8 test_stress_stability
make -j8 test_e2e_scenarios
```

**ç¼–è¯‘ç›®æ ‡åˆ—è¡¨**:

| æµ‹è¯•ç¨‹åº | è¯´æ˜Ž | å¤§å°ä¼°è®¡ |
|---------|------|----------|
| `test_http_server` | HTTP Server å•å…ƒæµ‹è¯• | ~5MB |
| `test_hf_tokenizer` | HFTokenizer å•å…ƒæµ‹è¯• | ~12MB |
| `test_model_executor` | ModelExecutor å•å…ƒæµ‹è¯• | ~8MB |
| `test_libtorch_backend` | LibTorch Backend å•å…ƒæµ‹è¯• | ~15MB |
| `test_qwen3_model` | Qwen3 æ¨¡åž‹æµ‹è¯• | ~10MB |
| `test_http_tokenizer_integration` | HTTP+Tokenizer é›†æˆ | ~10MB |
| `test_tokenizer_executor_integration` | Tokenizer+Executor é›†æˆ | ~12MB |
| `test_executor_backend_integration` | Executor+Backend é›†æˆ | ~15MB |
| `test_backend_qwen3_integration` | Backend+Qwen3 é›†æˆ | ~18MB |
| `test_frontend_subsystem` | å‰ç«¯å­ç³»ç»Ÿæµ‹è¯• | ~12MB |
| `test_inference_subsystem` | æŽ¨ç†å­ç³»ç»Ÿæµ‹è¯• | ~20MB |
| `test_e2e_subsystem` | E2E å­ç³»ç»Ÿæµ‹è¯• | ~22MB |
| `test_system_functionality` | ç³»ç»ŸåŠŸèƒ½æµ‹è¯• | ~25MB |
| `test_performance_benchmark` | æ€§èƒ½åŸºå‡†æµ‹è¯• | ~20MB |
| `test_stress_stability` | åŽ‹åŠ›ç¨³å®šæ€§æµ‹è¯• | ~20MB |
| `test_e2e_scenarios` | E2E åœºæ™¯æµ‹è¯• | ~25MB |

**éªŒè¯æ ‡å‡†**:
```bash
# æ£€æŸ¥æ‰€æœ‰æµ‹è¯•äºŒè¿›åˆ¶æ˜¯å¦å­˜åœ¨
cd build/bin
for test in test_*; do
  if [ -f "$test" ]; then
    echo "âœ… $test ($(du -h $test | cut -f1))"
  else
    echo "âŒ $test NOT FOUND"
  fi
done

# æµ‹è¯•æ˜¯å¦å¯æ‰§è¡Œ
./test_http_server --help > /dev/null 2>&1 && echo "âœ… Executable"
```

**è¾“å‡º**:
- `build/bin/` ç›®å½•åŒ…å«16ä¸ªæµ‹è¯•äºŒè¿›åˆ¶
- æ€»å¤§å°çº¦ 250MB

---

### P0.5: éªŒè¯çŽ¯å¢ƒå°±ç»ª (15åˆ†é’Ÿ)

**ç›®æ ‡**: ç¡®è®¤æ‰€æœ‰å‡†å¤‡å·¥ä½œå®Œæˆï¼ŒçŽ¯å¢ƒå¯ç”¨

**æ‰§è¡Œè„šæœ¬**:
```bash
#!/bin/bash
# verify_environment.sh

echo "========================================="
echo "çŽ¯å¢ƒéªŒè¯å¼€å§‹"
echo "========================================="
echo

# 1. æ£€æŸ¥æ¨¡åž‹æ–‡ä»¶
echo "1. æ£€æŸ¥æ¨¡åž‹æ–‡ä»¶..."
MODEL_PATH="${CLLM_TEST_MODEL_PATH}"
if [ -f "${MODEL_PATH}/tokenizer.json" ]; then
  echo "  âœ… tokenizer.json"
else
  echo "  âŒ tokenizer.json NOT FOUND"
  exit 1
fi

if [ -f "${MODEL_PATH}/config.json" ]; then
  echo "  âœ… config.json"
else
  echo "  âŒ config.json NOT FOUND"
  exit 1
fi

# 2. æ£€æŸ¥æµ‹è¯•æ•°æ®
echo
echo "2. æ£€æŸ¥æµ‹è¯•æ•°æ®..."
DATA_PATH="${CLLM_TEST_DATA_PATH}"
for data_file in tokenizer_test_data.json inference_test_data.json performance_test_data.json; do
  if [ -f "${DATA_PATH}/${data_file}" ]; then
    echo "  âœ… ${data_file}"
  else
    echo "  âŒ ${data_file} NOT FOUND"
    exit 1
  fi
done

# 3. æ£€æŸ¥çŽ¯å¢ƒå˜é‡
echo
echo "3. æ£€æŸ¥çŽ¯å¢ƒå˜é‡..."
for var in CLLM_TEST_MODEL_PATH CLLM_TEST_DATA_PATH CLLM_TEST_REPORTS; do
  if [ -n "${!var}" ]; then
    echo "  âœ… ${var}=${!var}"
  else
    echo "  âŒ ${var} NOT SET"
    exit 1
  fi
done

# 4. æ£€æŸ¥ç¼–è¯‘äº§ç‰©
echo
echo "4. æ£€æŸ¥ç¼–è¯‘äº§ç‰©..."
cd build/bin
TEST_COUNT=0
for test in test_*; do
  if [ -f "$test" ] && [ -x "$test" ]; then
    TEST_COUNT=$((TEST_COUNT + 1))
  fi
done
echo "  âœ… æ‰¾åˆ° ${TEST_COUNT} ä¸ªæµ‹è¯•ç¨‹åº"

if [ ${TEST_COUNT} -lt 10 ]; then
  echo "  âš ï¸  è­¦å‘Š: æµ‹è¯•ç¨‹åºæ•°é‡å°‘äºŽé¢„æœŸ"
fi

# 5. è¿è¡Œå¿«é€Ÿå¥åº·æ£€æŸ¥
echo
echo "5. è¿è¡Œå¥åº·æ£€æŸ¥..."

# æµ‹è¯• HFTokenizer æ˜¯å¦å¯ç”¨
./test_hf_tokenizer --gtest_list_tests > /dev/null 2>&1
if [ $? -eq 0 ]; then
  echo "  âœ… HFTokenizer æµ‹è¯•å¯æ‰§è¡Œ"
else
  echo "  âŒ HFTokenizer æµ‹è¯•æ‰§è¡Œå¤±è´¥"
  exit 1
fi

# 6. æ£€æŸ¥ç£ç›˜ç©ºé—´
echo
echo "6. æ£€æŸ¥ç£ç›˜ç©ºé—´..."
AVAILABLE_SPACE=$(df -h . | tail -1 | awk '{print $4}')
echo "  å¯ç”¨ç©ºé—´: ${AVAILABLE_SPACE}"

# 7. ç”ŸæˆéªŒè¯æŠ¥å‘Š
echo
echo "========================================="
echo "çŽ¯å¢ƒéªŒè¯å®Œæˆ âœ…"
echo "========================================="
echo
echo "éªŒè¯æŠ¥å‘Š:" > "${CLLM_TEST_REPORTS}/phase0_verification.txt"
echo "  - æ¨¡åž‹æ–‡ä»¶: âœ…" >> "${CLLM_TEST_REPORTS}/phase0_verification.txt"
echo "  - æµ‹è¯•æ•°æ®: âœ…" >> "${CLLM_TEST_REPORTS}/phase0_verification.txt"
echo "  - çŽ¯å¢ƒå˜é‡: âœ…" >> "${CLLM_TEST_REPORTS}/phase0_verification.txt"
echo "  - æµ‹è¯•ç¨‹åº: âœ… (${TEST_COUNT}ä¸ª)" >> "${CLLM_TEST_REPORTS}/phase0_verification.txt"
echo "  - å¥åº·æ£€æŸ¥: âœ…" >> "${CLLM_TEST_REPORTS}/phase0_verification.txt"
echo "  - éªŒè¯æ—¶é—´: $(date)" >> "${CLLM_TEST_REPORTS}/phase0_verification.txt"

echo "éªŒè¯æŠ¥å‘Šå·²ä¿å­˜: ${CLLM_TEST_REPORTS}/phase0_verification.txt"
```

**éªŒè¯æ ‡å‡†**:
- âœ… æ‰€æœ‰æ¨¡åž‹æ–‡ä»¶å­˜åœ¨
- âœ… æ‰€æœ‰æµ‹è¯•æ•°æ®å­˜åœ¨
- âœ… çŽ¯å¢ƒå˜é‡æ­£ç¡®é…ç½®
- âœ… è‡³å°‘10ä¸ªæµ‹è¯•ç¨‹åºç¼–è¯‘æˆåŠŸ
- âœ… å¥åº·æ£€æŸ¥é€šè¿‡

**è¾“å‡º**:
- `test_reports/phase0_verification.txt` éªŒè¯æŠ¥å‘Š
- çŽ¯å¢ƒå°±ç»ªæ ‡å¿—

---

## âœ… éªŒæ”¶æ ‡å‡†

### å¿…é¡»å®Œæˆ

- [ ] Qwen3-0.6B æ¨¡åž‹å®Œæ•´æ€§éªŒè¯ï¼ˆåŒ…å« tokenizer.jsonã€config.jsonã€weightsï¼‰
- [ ] 5ä¸ªæµ‹è¯•æ•°æ®æ–‡ä»¶ç”Ÿæˆ
- [ ] çŽ¯å¢ƒå˜é‡æ­£ç¡®é…ç½®
- [ ] è‡³å°‘16ä¸ªæµ‹è¯•ç¨‹åºç¼–è¯‘æˆåŠŸ
- [ ] çŽ¯å¢ƒéªŒè¯é€šè¿‡

### è´¨é‡æ£€æŸ¥

- [ ] æ¨¡åž‹æ–‡ä»¶å®Œæ•´æ€§æ ¡éªŒ
- [ ] æµ‹è¯•æ•°æ® JSON æ ¼å¼æ­£ç¡®
- [ ] æ‰€æœ‰æµ‹è¯•ç¨‹åºå¯æ‰§è¡Œ
- [ ] ç£ç›˜ç©ºé—´å……è¶³ï¼ˆ> 10GBï¼‰

---

## ðŸ“Š æ‰§è¡ŒæŠ¥å‘Š

**æ‰§è¡Œæ—¶é—´**: ________

**å®Œæˆæƒ…å†µ**:
- P0.1: â˜ å®Œæˆ / â˜ å¤±è´¥ (æ¨¡åž‹éªŒè¯)
- P0.2: â˜ å®Œæˆ / â˜ å¤±è´¥
- P0.3: â˜ å®Œæˆ / â˜ å¤±è´¥
- P0.4: â˜ å®Œæˆ / â˜ å¤±è´¥
- P0.5: â˜ å®Œæˆ / â˜ å¤±è´¥

**æ€»ä½“çŠ¶æ€**: â˜ æˆåŠŸ / â˜ éƒ¨åˆ†æˆåŠŸ / â˜ å¤±è´¥

**é—®é¢˜è®°å½•**:
```
ï¼ˆè®°å½•é‡åˆ°çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆï¼‰
```

---

## ðŸ”„ ä¸‹ä¸€æ­¥

Phase 0 å®ŒæˆåŽï¼Œåˆ›å»ºå®Œæˆæ ‡å¿—å¹¶é€šçŸ¥ Agent-1 å¯åŠ¨ Phase 1:

```bash
# åˆ›å»ºå®Œæˆæ ‡å¿—
touch /tmp/cllm_test_locks/phase0.done

# ç”Ÿæˆäº¤æŽ¥æŠ¥å‘Š
cat > test_reports/phase0_handoff.txt << EOF
Phase 0 å®Œæˆ
å®Œæˆæ—¶é—´: $(date)
æ¨¡åž‹è·¯å¾„: ${CLLM_TEST_MODEL_PATH}
æ•°æ®è·¯å¾„: ${CLLM_TEST_DATA_PATH}
æµ‹è¯•ç¨‹åºæ•°: 16ä¸ª
çŠ¶æ€: å°±ç»ª âœ…

Agent-1 å¯ä»¥å¼€å§‹æ‰§è¡Œ Phase 1 å•å…ƒæµ‹è¯•
EOF

echo "âœ… Phase 0 å®Œæˆï¼ŒAgent-1 å¯ä»¥å¯åŠ¨"
```

---

**Agent-0 å‡†å¤‡é˜¶æ®µæ‰§è¡Œè®¡åˆ’å®Œæˆ**
