# cLLM åˆ†è¯å™¨æµ‹è¯•éªŒè¯æ–¹æ¡ˆ

## 1. æµ‹è¯•ç­–ç•¥æ¦‚è¿°

### 1.1 æµ‹è¯•ç›®æ ‡
- éªŒè¯åˆ†è¯å™¨åŠŸèƒ½çš„æ­£ç¡®æ€§
- ç¡®ä¿å¤šæ¨¡å‹å…¼å®¹æ€§
- éªŒè¯æ€§èƒ½æŒ‡æ ‡è¾¾æ ‡
- é˜²æ­¢å›å½’é—®é¢˜

### 1.2 æµ‹è¯•åŸåˆ™
- **å…¨é¢è¦†ç›–**: æ¶µç›–æ‰€æœ‰åŠŸèƒ½æ¨¡å—
- **åˆ†å±‚éªŒè¯**: ä»å•å…ƒåˆ°é›†æˆé€å±‚éªŒè¯
- **è‡ªåŠ¨åŒ–æ‰§è¡Œ**: å®ç°CI/CDé›†æˆ
- **æ€§èƒ½å¯¼å‘**: é‡ç‚¹å…³æ³¨æ€§èƒ½æŒ‡æ ‡

## 2. æµ‹è¯•å±‚çº§

### 2.1 å•å…ƒæµ‹è¯•

#### 2.1.1 åŸºç¡€åŠŸèƒ½æµ‹è¯•
```cpp
TEST(LlamaCppTokenizerTest, QwenEncodeDecode) {
    LlamaCppTokenizer tokenizer(ModelType::QWEN);
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    std::string text = "Hello, world!";
    auto ids = tokenizer.encode(text);
    ASSERT_FALSE(ids.empty());
    
    std::string decoded = tokenizer.decode(ids);
    EXPECT_EQ(decoded, text);
}

TEST(DeepSeekTokenizerTest, DeepSeekCoderPreprocessing) {
    DeepSeekTokenizer tokenizer(ModelType::DEEPSEEK_CODER);
    ASSERT_TRUE(tokenizer.load("test_models/deepseek-coder/config.json"));
    
    std::string text = "def hello_world():\n    print('Hello')";
    auto ids = tokenizer.encode(text);
    ASSERT_FALSE(ids.empty());
}

TEST(QwenTokenizerTest, FimProcessing) {
    QwenTokenizer tokenizer;
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    // æµ‹è¯•FIMå¤„ç†
    std::string text = "def hello_world() -> str:\n    return \"Hello World\"";
    auto ids = tokenizer.encode(text);
    ASSERT_FALSE(ids.empty());
    
    std::string decoded = tokenizer.decode(ids);
    EXPECT_EQ(decoded, text);
}
```

#### 2.1.2 æ¨¡å‹å…¼å®¹æ€§æµ‹è¯•
```cpp
TEST(ModelDetectorTest, AutoDetection) {
    // æµ‹è¯•æ¨¡å‹è‡ªåŠ¨æ£€æµ‹åŠŸèƒ½
    ModelType type = ModelDetector::detectModelType("test_models/qwen/config.json");
    EXPECT_EQ(type, ModelType::QWEN);
    
    type = ModelDetector::detectModelType("test_models/deepseek-coder/config.json");
    EXPECT_EQ(type, ModelType::DEEPSEEK_CODER);
    
    type = ModelDetector::detectModelType("test_models/deepseek-llm/config.json");
    EXPECT_EQ(type, ModelType::DEEPSEEK_LLM);
}

TEST(TokenizerManagerTest, GetTokenizer) {
    TokenizerManager manager;
    
    auto qwenTokenizer = manager.getTokenizer("qwen");
    ASSERT_NE(qwenTokenizer, nullptr);
    EXPECT_EQ(qwenTokenizer->getModelType(), ModelType::QWEN);
    
    auto deepseekTokenizer = manager.getTokenizer("deepseek-coder");
    ASSERT_NE(deepseekTokenizer, nullptr);
    EXPECT_EQ(deepseekTokenizer->getModelType(), ModelType::DEEPSEEK_CODER);
}
```

#### 2.1.3 ç‰¹æ®ŠTokenå¤„ç†æµ‹è¯•
```cpp
TEST(CTokenizerTest, SpecialTokens) {
    LlamaCppTokenizer tokenizer(ModelType::QWEN);
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    // æµ‹è¯•ç‰¹æ®ŠToken
    int bosId = tokenizer.getBosId();
    int eosId = tokenizer.getEosId();
    int padId = tokenizer.getPadId();
    
    EXPECT_GT(bosId, 0);
    EXPECT_GT(eosId, 0);
    EXPECT_GE(padId, 0); // padIdå¯èƒ½ä¸º-1ï¼ˆæœªè®¾ç½®ï¼‰
    
    // æµ‹è¯•å¸¦ç‰¹æ®ŠTokençš„ç¼–ç 
    std::string text = "Hello";
    auto idsWithoutSpecial = tokenizer.encode(text, false);
    auto idsWithSpecial = tokenizer.encode(text, true);
    
    // å¸¦ç‰¹æ®ŠTokençš„åºåˆ—åº”è¯¥æ›´é•¿
    EXPECT_GE(idsWithSpecial.size(), idsWithoutSpecial.size());
}

TEST(CTokenizerTest, VocabOperations) {
    LlamaCppTokenizer tokenizer(ModelType::QWEN);
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    // æµ‹è¯•è¯æ±‡è¡¨æ“ä½œ
    int vocabSize = tokenizer.getVocabSize();
    EXPECT_GT(vocabSize, 0);
    
    // æµ‹è¯•IDåˆ°Tokençš„è½¬æ¢
    std::string token = tokenizer.idToToken(100); // å‡è®¾ID 100å­˜åœ¨
    EXPECT_FALSE(token.empty());
    
    // æµ‹è¯•Tokenåˆ°IDçš„è½¬æ¢
    int id = tokenizer.tokenToId(token);
    EXPECT_EQ(token, tokenizer.idToToken(id));
}
```

#### 2.1.4 è¾¹ç•Œæ¡ä»¶æµ‹è¯•
```cpp
TEST(CTokenizerTest, BoundaryConditions) {
    LlamaCppTokenizer tokenizer(ModelType::QWEN);
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    // ç©ºå­—ç¬¦ä¸²æµ‹è¯•
    auto emptyIds = tokenizer.encode("");
    EXPECT_TRUE(emptyIds.empty() || emptyIds.size() == 2); // å¯èƒ½åŒ…å«BOS/EOS
    
    // å•å­—ç¬¦æµ‹è¯•
    auto singleCharIds = tokenizer.encode("A");
    EXPECT_FALSE(singleCharIds.empty());
    
    std::string singleDecoded = tokenizer.decode(singleCharIds);
    EXPECT_EQ(singleDecoded, "A");
    
    // ç‰¹æ®Šå­—ç¬¦æµ‹è¯•
    std::string specialText = "Hello, ä¸–ç•Œ! ğŸŒ";
    auto specialIds = tokenizer.encode(specialText);
    ASSERT_FALSE(specialIds.empty());
    
    std::string specialDecoded = tokenizer.decode(specialIds);
    EXPECT_EQ(specialDecoded, specialText);
}
```

### 2.2 é›†æˆæµ‹è¯•

#### 2.2.1 ç«¯åˆ°ç«¯æµ‹è¯•
```cpp
TEST(IntegrationTest, EndToEnd) {
    // æ¨¡æ‹Ÿå®Œæ•´çš„å·¥ä½œæµ
    TokenizerManager manager;
    auto tokenizer = manager.getTokenizer("qwen");
    ASSERT_NE(tokenizer, nullptr);
    
    std::string input = "This is a test sentence for end-to-end validation.";
    auto tokens = tokenizer->encode(input);
    ASSERT_FALSE(tokens.empty());
    
    std::string output = tokenizer->decode(tokens);
    EXPECT_EQ(input, output);
    
    // éªŒè¯è¯æ±‡è¡¨å¤§å°çš„ä¸€è‡´æ€§
    int vocabSize = tokenizer->getVocabSize();
    EXPECT_GT(vocabSize, 1000); // åˆç†çš„è¯æ±‡è¡¨å¤§å°
}

TEST(IntegrationTest, MultiModelSupport) {
    TokenizerManager manager;
    
    // æµ‹è¯•ä¸åŒæ¨¡å‹ç±»å‹çš„åˆ†è¯å™¨
    std::vector<std::string> modelTypes = {"qwen", "deepseek-llm", "deepseek-coder"};
    
    for (const auto& modelType : modelTypes) {
        auto tokenizer = manager.getTokenizer(modelType);
        ASSERT_NE(tokenizer, nullptr) << "Failed to get tokenizer for " << modelType;
        
        std::string testText = "Test text for " + modelType;
        auto tokens = tokenizer->encode(testText);
        ASSERT_FALSE(tokens.empty()) << "Encoding failed for " << modelType;
        
        std::string decoded = tokenizer->decode(tokens);
        EXPECT_EQ(decoded, testText) << "Decoding mismatch for " << modelType;
    }
}
```

#### 2.2.2 æ‰¹å¤„ç†æµ‹è¯•
```cpp
TEST(BatchTokenizerTest, BatchEncodeDecode) {
    LlamaCppTokenizer tokenizer(ModelType::QWEN);
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    std::vector<std::string> texts = {
        "Hello, world!",
        "This is a test sentence.",
        "Another test with numbers: 12345",
        "Mixed content: Hello ä¸–ç•Œ ğŸŒ"
    };
    
    // æµ‹è¯•æ‰¹é‡ç¼–ç 
    auto batchResult = BatchTokenizer::batchEncode(&tokenizer, texts, true, 4);
    ASSERT_EQ(batchResult.tokenized.size(), texts.size());
    
    // éªŒè¯æ¯ä¸ªæ–‡æœ¬éƒ½è¢«æˆåŠŸç¼–ç 
    for (size_t i = 0; i < batchResult.success.size(); ++i) {
        EXPECT_TRUE(batchResult.success[i]) << "Batch encoding failed for text " << i;
        EXPECT_FALSE(batchResult.tokenized[i].empty()) << "Empty result for text " << i;
    }
    
    // æµ‹è¯•æ‰¹é‡è§£ç 
    std::vector<std::string> decoded = BatchTokenizer::batchDecode(
        &tokenizer, batchResult.tokenized, true, 4
    );
    
    ASSERT_EQ(decoded.size(), texts.size());
    for (size_t i = 0; i < texts.size(); ++i) {
        EXPECT_EQ(decoded[i], texts[i]) << "Batch decode mismatch for text " << i;
    }
}
```

## 3. æ€§èƒ½æµ‹è¯•

### 3.1 åŸºå‡†æµ‹è¯•
```cpp
TEST(PerformanceTest, EncodeSpeed) {
    LlamaCppTokenizer tokenizer(ModelType::QWEN);
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    std::string longText;
    for (int i = 0; i < 1000; ++i) {
        longText += "This is a test sentence for performance evaluation. ";
    }
    
    auto start = std::chrono::high_resolution_clock::now();
    auto tokens = tokenizer.encode(longText);
    auto end = std::chrono::high_resolution_clock::now();
    
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);
    EXPECT_LT(duration.count(), 1000); // åº”è¯¥åœ¨1ç§’å†…å®Œæˆ
    
    EXPECT_FALSE(tokens.empty());
    
    // è®¡ç®—ç¼–ç é€Ÿåº¦ (å­—ç¬¦/ç§’)
    double speed = (double)longText.length() / (duration.count() / 1000.0);
    EXPECT_GT(speed, 50000); // è‡³å°‘50KB/s
}

TEST(PerformanceTest, DecodeSpeed) {
    LlamaCppTokenizer tokenizer(ModelType::QWEN);
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    std::string text = "Performance test text. ";
    auto tokens = tokenizer.encode(text);
    
    // é‡å¤å¤šæ¬¡ä»¥è·å¾—æ›´å¥½çš„æµ‹é‡ç»“æœ
    std::vector<std::vector<int>> batchTokens;
    for (int i = 0; i < 1000; ++i) {
        batchTokens.push_back(tokens);
    }
    
    auto start = std::chrono::high_resolution_clock::now();
    std::vector<std::string> decoded = BatchTokenizer::batchDecode(
        &tokenizer, batchTokens, true, 4
    );
    auto end = std::chrono::high_resolution_clock::now();
    
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);
    EXPECT_LT(duration.count(), 1000); // åº”è¯¥åœ¨1ç§’å†…å®Œæˆ
    
    EXPECT_EQ(decoded.size(), batchTokens.size());
}

TEST(PerformanceTest, MemoryUsage) {
    LlamaCppTokenizer tokenizer(ModelType::QWEN);
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    // æ£€æŸ¥åˆå§‹å†…å­˜ä½¿ç”¨
    size_t initialMemory = getCurrentMemoryUsage();
    
    // æ‰§è¡Œå¤šæ¬¡ç¼–ç /è§£ç æ“ä½œ
    for (int i = 0; i < 10000; ++i) {
        std::string text = "Test " + std::to_string(i);
        auto tokens = tokenizer.encode(text);
        std::string decoded = tokenizer.decode(tokens);
    }
    
    size_t finalMemory = getCurrentMemoryUsage();
    
    // å†…å­˜å¢é•¿ä¸åº”è¶…è¿‡é˜ˆå€¼ï¼ˆä¾‹å¦‚10MBï¼‰
    EXPECT_LT(finalMemory - initialMemory, 10 * 1024 * 1024);
}
```

### 3.2 å‹åŠ›æµ‹è¯•
```cpp
TEST(StressTest, LongRunning) {
    LlamaCppTokenizer tokenizer(ModelType::QWEN);
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    // é•¿æ—¶é—´è¿è¡Œå‹åŠ›æµ‹è¯•
    auto startTime = std::chrono::steady_clock::now();
    auto endTime = startTime + std::chrono::minutes(5); // 5åˆ†é’Ÿ
    
    int iterationCount = 0;
    while (std::chrono::steady_clock::now() < endTime) {
        std::string text = "Stress test iteration: " + std::to_string(iterationCount++);
        auto tokens = tokenizer.encode(text);
        std::string decoded = tokenizer.decode(tokens);
        
        EXPECT_EQ(text, decoded);
        
        // å¶å°”æ£€æŸ¥å†…å­˜ä½¿ç”¨
        if (iterationCount % 1000 == 0) {
            // ç¡®ä¿æ²¡æœ‰å†…å­˜æ³„æ¼
            EXPECT_LT(getCurrentMemoryUsage(), MAX_EXPECTED_MEMORY);
        }
    }
}

TEST(StressTest, LargeInput) {
    LlamaCppTokenizer tokenizer(ModelType::QWEN);
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    // ç”Ÿæˆå¤§æ–‡æœ¬è¾“å…¥
    std::string largeText;
    largeText.reserve(10 * 1024 * 1024); // 10MB
    for (size_t i = 0; i < 10 * 1024 * 1024; ++i) {
        largeText += (char)('A' + (i % 26));
        if (i % 1000 == 0) largeText += ' ';
        if (i % 10000 == 0) largeText += '\n';
    }
    
    // æµ‹è¯•å¤§æ–‡æœ¬çš„ç¼–ç 
    auto start = std::chrono::high_resolution_clock::now();
    auto tokens = tokenizer.encode(largeText);
    auto end = std::chrono::high_resolution_clock::now();
    
    EXPECT_FALSE(tokens.empty());
    
    // æµ‹è¯•å¤§æ–‡æœ¬çš„è§£ç 
    auto decodeStart = std::chrono::high_resolution_clock::now();
    std::string decoded = tokenizer.decode(tokens);
    auto decodeEnd = std::chrono::high_resolution_clock::now();
    
    EXPECT_EQ(largeText, decoded);
    
    // éªŒè¯å¤„ç†æ—¶é—´åˆç†
    auto totalTime = std::chrono::duration_cast<std::chrono::seconds>(
        end - start + decodeEnd - decodeStart
    );
    EXPECT_LT(totalTime.count(), 60); // åº”è¯¥åœ¨1åˆ†é’Ÿå†…å®Œæˆ
}
```

## 4. éªŒè¯æµ‹è¯•

### 4.1 ç²¾åº¦éªŒè¯
```cpp
TEST(ValidationTest, CrossPlatformConsistency) {
    // éªŒè¯åœ¨ä¸åŒå¹³å°ä¸Šäº§ç”Ÿçš„ç»“æœä¸€è‡´æ€§
    LlamaCppTokenizer tokenizer(ModelType::QWEN);
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    std::vector<std::string> testCases = {
        "Hello, world!",
        "æµ‹è¯•ä¸­æ–‡åˆ†è¯",
        "Test with numbers: 123456789",
        "Mixed: Hello ä¸–ç•Œ ğŸŒ emoji",
        "Special chars: !@#$%^&*()",
        "Long text with multiple sentences. This is sentence two. And this is three."
    };
    
    for (const auto& testCase : testCases) {
        auto tokens = tokenizer.encode(testCase);
        std::string decoded = tokenizer.decode(tokens);
        
        EXPECT_EQ(testCase, decoded) << "Mismatch for test case: " << testCase;
        
        // éªŒè¯è¯æ±‡è¡¨å¤§å°çš„ä¸€è‡´æ€§
        int vocabSize = tokenizer.getVocabSize();
        EXPECT_GT(vocabSize, 0);
    }
}

TEST(ValidationTest, ModelSpecificFeatures) {
    // éªŒè¯ç‰¹å®šæ¨¡å‹çš„ç‰¹å¾
    {
        // Qwenæ¨¡å‹ç‰¹æœ‰åŠŸèƒ½æµ‹è¯•
        QwenTokenizer qwenTokenizer;
        ASSERT_TRUE(qwenTokenizer.load("test_models/qwen/tokenizer.json"));
        
        // æµ‹è¯•Qwenç‰¹æœ‰çš„FIMå¤„ç†
        std::string code = "def function():\n    pass";
        auto tokens = qwenTokenizer.encode(code);
        EXPECT_FALSE(tokens.empty());
        
        std::string decoded = qwenTokenizer.decode(tokens);
        EXPECT_EQ(decoded, code);
    }
    
    {
        // DeepSeekæ¨¡å‹ç‰¹æœ‰åŠŸèƒ½æµ‹è¯•
        DeepSeekTokenizer deepseekTokenizer(ModelType::DEEPSEEK_CODER);
        ASSERT_TRUE(deepseekTokenizer.load("test_models/deepseek-coder/config.json"));
        
        // æµ‹è¯•DeepSeekç‰¹å®šçš„é¢„å¤„ç†
        std::string code = "class MyClass:\n    def method(self):\n        return True";
        auto tokens = deepseekTokenizer.encode(code);
        EXPECT_FALSE(tokens.empty());
        
        std::string decoded = deepseekTokenizer.decode(tokens);
        EXPECT_EQ(decoded, code);
    }
}
```

### 4.2 å›å½’æµ‹è¯•
```cpp
TEST(RegressionTest, KnownIssues) {
    // é’ˆå¯¹å·²çŸ¥é—®é¢˜çš„å›å½’æµ‹è¯•
    LlamaCppTokenizer tokenizer(ModelType::QWEN);
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    // æµ‹è¯•å¯èƒ½å¯¼è‡´é—®é¢˜çš„ç‰¹å®šè¾“å…¥
    std::vector<std::string> problematicInputs = {
        "", // ç©ºå­—ç¬¦ä¸²
        " ", // å•ç©ºæ ¼
        "\n", // å•æ¢è¡Œ
        "\t", // å˜åˆ¶è¡¨ç¬¦
        "\r\n", // Windowsæ¢è¡Œ
        std::string(1000, 'A'), // é•¿é‡å¤å­—ç¬¦ä¸²
        "A" + std::string(1000, 'B') + "C", // é•¿ä¸­é—´å­—ç¬¦ä¸²
        "!@#$%^&*()_+-=[]{}|;:,.<>?", // æ‰€æœ‰ç‰¹æ®Šå­—ç¬¦
        "Î±Î²Î³Î´ÎµÎ¶Î·Î¸Î¹ÎºÎ»Î¼Î½Î¾Î¿Ï€ÏÏƒÏ„Ï…Ï†Ï‡ÏˆÏ‰", // å¸Œè…Šå­—æ¯
        "ã‚ã„ã†ãˆãŠã‹ããã‘ã“", // æ—¥æ–‡å¹³å‡å
        "í•œêµ­ì–´ í…ŒìŠ¤íŠ¸", // éŸ©æ–‡
        "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", // é˜¿æ‹‰ä¼¯æ–‡
        "Ğ ÑƒÑÑĞºĞ¸Ğ¹", // ä¿„æ–‡
        " ğŸŒ âœ¨ ğŸš€ " // è¡¨æƒ…ç¬¦å·
    };
    
    for (const auto& input : problematicInputs) {
        try {
            auto tokens = tokenizer.encode(input);
            std::string decoded = tokenizer.decode(tokens);
            
            // å¯¹äºå¤§å¤šæ•°è¾“å…¥ï¼Œç¼–ç åå†è§£ç åº”è¯¥å¾—åˆ°ç›¸åŒçš„ç»“æœ
            EXPECT_EQ(decoded, input) << "Regression detected for input: " << input;
        } catch (const std::exception& e) {
            ADD_FAILURE() << "Exception thrown for input '" << input << "': " << e.what();
        }
    }
}
```

## 5. æµ‹è¯•æ‰§è¡Œç­–ç•¥

### 5.1 æµ‹è¯•å±‚çº§
- **å•å…ƒæµ‹è¯•**: éªŒè¯å„ä¸ªç»„ä»¶çš„ç‹¬ç«‹åŠŸèƒ½
- **é›†æˆæµ‹è¯•**: éªŒè¯ç»„ä»¶é—´çš„åä½œ
- **æ€§èƒ½æµ‹è¯•**: éªŒè¯æ€§èƒ½æŒ‡æ ‡æ˜¯å¦è¾¾æ ‡
- **å‹åŠ›æµ‹è¯•**: éªŒè¯åœ¨æç«¯æ¡ä»¶ä¸‹çš„ç¨³å®šæ€§
- **å›å½’æµ‹è¯•**: é˜²æ­¢å¼•å…¥æ–°çš„bug

### 5.2 æµ‹è¯•è¦†ç›–ç‡
- åŠŸèƒ½è¦†ç›–ç‡: ç¡®ä¿æ‰€æœ‰åŠŸèƒ½éƒ½ç»è¿‡æµ‹è¯•
- ä»£ç è¦†ç›–ç‡: ç›®æ ‡è¾¾åˆ°85%ä»¥ä¸Š
- æ•°æ®è¦†ç›–ç‡: æ¶µç›–å„ç§è¾“å…¥ç±»å‹å’Œè¾¹ç•Œæ¡ä»¶

### 5.3 è‡ªåŠ¨åŒ–æµ‹è¯•
```bash
# å®Œæ•´æµ‹è¯•å¥—ä»¶æ‰§è¡Œ
./bin/tokenizer_tests --gtest_filter=* --verbose

# æ€§èƒ½æµ‹è¯•
./bin/tokenizer_benchmark --model=qwen --text=performance_test.txt --iterations=1000

# å‹åŠ›æµ‹è¯•
./bin/tokenizer_stress_test --duration=300 --threads=4

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
gcovr --html --html-details -o coverage.html
```

```cpp
// æµ‹è¯•åˆå§‹åŒ–å’Œæ¸…ç†
class TokenizerTestEnvironment : public ::testing::Environment {
public:
    void SetUp() override {
        // å‡†å¤‡æµ‹è¯•ç¯å¢ƒ
        prepareTestModels();
        initializeGlobalResources();
    }
    
    void TearDown() override {
        // æ¸…ç†æµ‹è¯•ç¯å¢ƒ
        cleanupTestModels();
        releaseGlobalResources();
    }
    
private:
    void prepareTestModels() {
        // ä¸‹è½½æˆ–å¤åˆ¶æµ‹è¯•æ¨¡å‹æ–‡ä»¶
    }
    
    void initializeGlobalResources() {
        // åˆå§‹åŒ–å…¨å±€èµ„æº
    }
    
    void cleanupTestModels() {
        // æ¸…ç†æµ‹è¯•æ¨¡å‹æ–‡ä»¶
    }
    
    void releaseGlobalResources() {
        // é‡Šæ”¾å…¨å±€èµ„æº
    }
};

// æ³¨å†Œæµ‹è¯•ç¯å¢ƒ
::testing::AddGlobalTestEnvironment(new TokenizerTestEnvironment());
```

### 5.4 CI/CDé›†æˆ
```bash
#!/bin/bash
# CI/CDæµ‹è¯•è„šæœ¬
echo "Running tokenizer tests..."

# ç¼–è¯‘æµ‹è¯•
make test_tokenizer

# è¿è¡Œå•å…ƒæµ‹è¯•
./bin/tokenizer_unit_tests --gtest_output=xml:test-results/unit.xml

# è¿è¡Œé›†æˆæµ‹è¯•
./bin/tokenizer_integration_tests --gtest_output=xml:test-results/integration.xml

# è¿è¡Œæ€§èƒ½æµ‹è¯•
./bin/tokenizer_performance_tests --gtest_output=xml:test-results/performance.xml

# æ£€æŸ¥æµ‹è¯•ç»“æœ
if [ $? -eq 0 ]; then
    echo "All tests passed!"
    exit 0
else
    echo "Some tests failed!"
    exit 1
fi
```

## 6. æµ‹è¯•æŠ¥å‘Š

### 6.1 æµ‹è¯•æŒ‡æ ‡
- **åŠŸèƒ½æ­£ç¡®æ€§**: 100% é€šè¿‡ç‡
- **æ€§èƒ½æŒ‡æ ‡**: æ»¡è¶³è®¾è®¡è¦æ±‚
- **ä»£ç è¦†ç›–ç‡**: â‰¥ 85%
- **ç¨³å®šæ€§**: æ— å†…å­˜æ³„æ¼ï¼Œé•¿æ—¶é—´è¿è¡Œç¨³å®š

### 6.2 æµ‹è¯•ç»“æœè·Ÿè¸ª
- æ¯æ¬¡æäº¤åè‡ªåŠ¨è¿è¡Œæµ‹è¯•
- ç”Ÿæˆæµ‹è¯•æŠ¥å‘Šå¹¶å­˜æ¡£
- å…³é”®æ€§èƒ½æŒ‡æ ‡è¶‹åŠ¿åˆ†æ
- é—®é¢˜è¿½è¸ªå’Œä¿®å¤éªŒè¯

## 7. æ€»ç»“

æœ¬æµ‹è¯•éªŒè¯æ–¹æ¡ˆç¡®ä¿äº†åˆ†è¯å™¨æ¨¡å—çš„å¯é æ€§ã€æ€§èƒ½å’Œç¨³å®šæ€§ã€‚é€šè¿‡å¤šå±‚æ¬¡ã€å…¨æ–¹ä½çš„æµ‹è¯•è¦†ç›–ï¼Œæˆ‘ä»¬èƒ½å¤Ÿä¿è¯åˆ†è¯å™¨åœ¨å„ç§ä½¿ç”¨åœºæ™¯ä¸‹çš„æ­£ç¡®æ€§ï¼Œå¹¶æ»¡è¶³æ€§èƒ½è¦æ±‚ã€‚æµ‹è¯•æ–¹æ¡ˆè¿˜è€ƒè™‘äº†æœªæ¥çš„æ‰©å±•æ€§ï¼Œå¯ä»¥æ–¹ä¾¿åœ°æ·»åŠ å¯¹æ–°æ¨¡å‹ç±»å‹çš„æ”¯æŒæµ‹è¯•ã€‚