# cLLM组件交互设计

**遵循 C++编程规范.md**

## 1. 系统架构概述

cLLM系统采用模块化设计，各组件之间通过明确的接口进行交互，实现了请求处理、模型推理、结果生成等核心功能。系统整体架构分为以下几个主要层次：

```
┌──────────────────────────────────────────────────────────┐
│                    HTTP Server Layer                      │
│          (HttpServer + RequestValidator)                  │
└────────────────────────┬─────────────────────────────────┘
                         │
┌────────────────────────▼─────────────────────────────────┐
│                     Scheduler                             │
│  (RequestQueue + RequestTracker + SchedulerBatchProcessor)│
└───────────┬─────────────┬──────────────┬─────────────────┘
            │             │              │
            │             │              ▼
            │             │        ┌────────────────┐
            │             │        │ TokenizerManager│  # 文本编解码管理
            │             │        └────────────────┘
            │             │
            │             ▼
            │      ┌──────────────┐       ┌──────────────┐
            │      │BatchManager  │◄──────│MemoryMonitor │ # 批处理管理与内存监控
            │      └──────┬───────┘       └──────────────┘
            │             │
            │             ▼
            │      ┌──────────────┐
            │      │  KVCache     │  # KV缓存管理
            │      └──────────────┘
            │
            ▼
     ┌──────────────┐
     │ModelExecutor │  # 模型加载和推理
     │  + Sampler   │  # (内含Token采样器)
     └──────┬───────┘
            │
            ▼
     ┌──────────────┐
     │ Thread Pool  │  # 线程池管理
     └──────────────┘
```

## 2. 组件职责与接口

### 2.1 HTTP Server
- **职责**: 处理HTTP请求，提供RESTful API接口
- **主要接口**:
  - `start()`: 启动HTTP服务器
  - `stop()`: 停止HTTP服务器
  - `setHandler()`: 设置请求处理器
  - `getStats()`: 获取服务器统计信息

### 2.2 RequestValidator
- **职责**: 验证HTTP请求参数的合法性
- **主要接口**:
  - `validateGenerateRequest()`: 验证生成请求参数
  - `validateEncodeRequest()`: 验证编码请求参数
  - `checkParameterBounds()`: 检查参数范围

### 2.3 Scheduler
- **职责**: 协调请求生命周期，管理请求队列
- **主要接口**:
  - `start()`: 启动调度器
  - `stop()`: 停止调度器
  - `addRequest()`: 添加新请求
  - `getRequestResult()`: 获取请求结果
  - `removeRequest()`: 移除请求
  - `getStats()`: 获取调度器统计信息

### 2.4 RequestQueue
- **职责**: 管理待处理的请求队列
- **主要接口**:
  - `push()`: 添加请求到队列
  - `pop()`: 从队列取出请求
  - `size()`: 获取队列大小
  - `formBatch()`: 组装批处理请求

### 2.5 RequestTracker
- **职责**: 跟踪请求状态和生命周期
- **主要接口**:
  - `addRequest()`: 添加请求跟踪
  - `updateRequest()`: 更新请求状态
  - `getRequest()`: 获取请求信息
  - `removeRequest()`: 移除请求跟踪

### 2.6 BatchManager
- **职责**: 形成和管理批处理
- **主要接口**:
  - `formBatch()`: 形成新的批处理
  - `prepareBatchInput()`: 准备批处理输入
  - `processBatchOutput()`: 处理批处理输出
  - `getStats()`: 获取批处理统计信息

### 2.7 TokenizerManager
- **职责**: 管理文本编解码，提供统一的Tokenizer接口
- **主要接口**:
  - `encode()`: 将文本编码为Token ID
  - `decode()`: 将Token ID解码为文本
  - `getTokenizer()`: 获取Tokenizer实例
  - `loadModel()`: 加载Tokenizer模型

### 2.8 KVCache
- **职责**: 存储和管理KV缓存
- **主要接口**:
  - `get()`: 获取缓存条目
  - `put()`: 存储缓存条目
  - `remove()`: 移除缓存条目
  - `updateIncremental()`: 增量更新缓存
  - `getStats()`: 获取缓存统计信息

### 2.9 MemoryMonitor
- **职责**: 监控和限制系统内存使用
- **主要接口**:
  - `allocate()`: 分配内存并记录
  - `deallocate()`: 释放内存并记录
  - `getUsedMemory()`: 获取当前内存使用量
  - `setLimit()`: 设置内存限制
  - `registerCallback()`: 注册内存超限回调

### 2.10 ModelExecutor
- **职责**: 模型加载和推理执行
- **主要接口**:
  - `forward()`: 执行前向传播
  - `generate()`: 生成文本
  - `loadModel()`: 加载模型
  - `unloadModel()`: 卸载模型
  - `getStats()`: 获取执行统计信息

### 2.11 Sampler
- **职责**: 从模型输出中采样Token
- **主要接口**:
  - `sample()`: 采样单个Token
  - `sampleGreedy()`: 贪心采样
  - `sampleTemperature()`: 温度采样

### 2.12 ThreadPool
- **职责**: 管理工作线程池，执行并行任务
- **主要接口**:
  - `submit()`: 提交任务到线程池
  - `shutdown()`: 关闭线程池
  - `getStats()`: 获取线程池统计信息

## 3. 系统初始化与关闭流程

### 3.1 系统初始化流程

系统初始化遵循严格的组件依赖顺序，确保底层组件优先初始化完成：

```
[系统启动]
    │
    ├─> 1. 内存监控器初始化 (MemoryMonitor)
    │     - 设置内存限制
    │     - 注册内存超限回调
    │
    ├─> 2. 线程池初始化 (ThreadPool)
    │     - 创建工作线程
    │     - 初始化任务队列
    │
    ├─> 3. Tokenizer初始化 (TokenizerManager)
    │     - 加载Tokenizer模型
    │     - 设置特殊Token (pad_token, eos_token, bos_token)
    │     - 验证模型加载成功
    │
    ├─> 4. 模型执行器初始化 (ModelExecutor)
    │     - 加载模型文件
    │     - 应用量化配置 (如果启用)
    │     - 初始化Sampler子组件
    │     - 预热模型 (warmup)
    │
    ├─> 5. KV缓存初始化 (KVCache)
    │     - 设置缓存大小限制
    │     - 设置内存限制
    │     - 初始化LRU数据结构
    │     - 注册到MemoryMonitor
    │
    ├─> 6. 批处理管理器初始化 (BatchManager)
    │     - 设置最大批处理大小
    │     - 设置最大上下文长度
    │     - 绑定ModelExecutor和KVCache
    │     - 注册到MemoryMonitor
    │
    ├─> 7. 调度器初始化 (Scheduler)
    │     - 初始化请求队列 (RequestQueue)
    │     - 初始化请求跟踪器 (RequestTracker)
    │     - 绑定BatchManager和ModelExecutor
    │     - 启动调度器线程
    │
    └─> 8. HTTP服务器初始化 (HttpServer)
          - 初始化请求验证器 (RequestValidator)
          - 注册API端点 (/generate, /encode, /health)
          - 绑定Scheduler和TokenizerManager
          - 启动HTTP服务监听

[系统就绪]
```

#### 3.1.1 初始化配置参数传递

配置参数采用自顶向下的传递方式：

```cpp
// 主程序配置
struct ServerConfig {
    std::string modelPath;          // 模型路径
    int port;                        // HTTP端口
    std::string quantization;        // 量化类型
    size_t maxBatchSize;            // 最大批处理大小
    size_t maxContextLength;        // 最大上下文长度
    size_t kvCacheMaxSize;          // KV缓存最大条目数
    size_t kvCacheMaxMemoryMB;      // KV缓存最大内存(MB)
    size_t memoryLimitMB;           // 总内存限制(MB)
    size_t numThreads;              // 线程池线程数
};

// 初始化流程示例
void initializeSystem(const ServerConfig& config) {
    // 1. 初始化内存监控器
    MemoryMonitor::instance().setLimit(config.memoryLimitMB * 1024 * 1024);
    
    // 2. 初始化线程池
    auto threadPool = std::make_unique<ThreadPool>(config.numThreads);
    
    // 3. 初始化Tokenizer
    auto tokenizer = std::make_unique<TokenizerManager>(config.modelPath);
    
    // 4. 初始化ModelExecutor
    auto modelExecutor = std::make_unique<ModelExecutor>(
        config.modelPath, 
        config.quantization
    );
    
    // 5. 初始化KVCache
    auto kvCache = std::make_unique<KVCache>(
        config.kvCacheMaxSize,
        config.kvCacheMaxMemoryMB
    );
    
    // 6. 初始化BatchManager
    auto batchManager = std::make_unique<BatchManager>(
        modelExecutor.get(),
        kvCache.get(),
        config.maxBatchSize,
        config.maxContextLength
    );
    
    // 7. 初始化Scheduler
    auto scheduler = std::make_unique<Scheduler>(
        config.modelPath,
        config.quantization,
        config.maxBatchSize,
        config.maxContextLength
    );
    scheduler->start();
    
    // 8. 初始化HttpServer
    auto httpServer = std::make_unique<HttpServer>("0.0.0.0", config.port);
    httpServer->setHandler(scheduler.get(), tokenizer.get());
    httpServer->start();
}
```

### 3.2 系统关闭流程

系统关闭流程与初始化顺序相反，确保高层组件优先停止：

```
[关闭信号接收]
    │
    ├─> 1. HTTP服务器停止 (HttpServer)
    │     - 停止接收新请求
    │     - 等待当前请求处理完成
    │     - 释放网络资源
    │
    ├─> 2. 调度器停止 (Scheduler)
    │     - 停止调度器线程
    │     - 等待当前批处理完成
    │     - 清理请求队列
    │     - 通知所有等待的客户端
    │
    ├─> 3. 批处理管理器清理 (BatchManager)
    │     - 取消进行中的批处理
    │     - 释放批处理资源
    │
    ├─> 4. KV缓存清理 (KVCache)
    │     - 清空所有缓存条目
    │     - 释放缓存内存
    │     - 从MemoryMonitor注销
    │
    ├─> 5. 模型执行器卸载 (ModelExecutor)
    │     - 卸载模型
    │     - 释放Sampler资源
    │     - 释放推理缓冲区
    │
    ├─> 6. Tokenizer清理 (TokenizerManager)
    │     - 卸载Tokenizer模型
    │     - 释放Tokenizer资源
    │
    ├─> 7. 线程池关闭 (ThreadPool)
    │     - 停止接收新任务
    │     - 等待所有任务完成
    │     - 销毁工作线程
    │
    └─> 8. 内存监控器清理 (MemoryMonitor)
          - 打印最终内存统计
          - 检查内存泄漏
          - 清理监控数据

[系统退出]
```

#### 3.2.1 优雅关闭机制

```cpp
// 优雅关闭实现示例
void shutdownSystem(int timeout_seconds = 30) {
    std::cout << "Shutting down cLLM server..." << std::endl;
    
    // 1. 停止HTTP服务器
    httpServer->stop();
    std::cout << "HTTP server stopped" << std::endl;
    
    // 2. 停止调度器
    scheduler->stop();
    std::cout << "Scheduler stopped" << std::endl;
    
    // 3-4. BatchManager和KVCache自动清理（RAII）
    batchManager.reset();
    kvCache.reset();
    std::cout << "Batch manager and KV cache cleaned" << std::endl;
    
    // 5. 卸载模型
    modelExecutor->unloadModel();
    modelExecutor.reset();
    std::cout << "Model executor unloaded" << std::endl;
    
    // 6. 清理Tokenizer
    tokenizer.reset();
    std::cout << "Tokenizer cleaned" << std::endl;
    
    // 7. 关闭线程池
    threadPool->shutdown();
    threadPool.reset();
    std::cout << "Thread pool shutdown" << std::endl;
    
    // 8. 打印内存统计
    auto& monitor = MemoryMonitor::instance();
    std::cout << "Peak memory usage: " 
              << monitor.getPeak() / (1024.0 * 1024.0) 
              << " MB" << std::endl;
    
    std::cout << "cLLM server shutdown complete" << std::endl;
}
```

### 3.3 配置管理

#### 3.3.1 配置文件格式（JSON）

```json
{
  "server": {
    "host": "0.0.0.0",
    "port": 8080,
    "log_level": "info"
  },
  "model": {
    "path": "/path/to/model",
    "quantization": "fp16",
    "warmup": true
  },
  "inference": {
    "max_batch_size": 8,
    "max_context_length": 2048,
    "enable_simd": true
  },
  "cache": {
    "kv_cache_max_entries": 100,
    "kv_cache_max_memory_mb": 4096
  },
  "resources": {
    "memory_limit_mb": 16384,
    "num_threads": 8
  }
}
```

#### 3.3.2 配置加载和验证

```cpp
// 配置加载器
class ConfigLoader {
public:
    static ServerConfig loadFromFile(const std::string& configPath);
    static ServerConfig loadFromCommandLine(int argc, char** argv);
    static void validateConfig(const ServerConfig& config);
    
private:
    static void checkModelPath(const std::string& path);
    static void checkMemoryLimits(const ServerConfig& config);
    static void checkPortAvailability(int port);
};

// 配置验证
void ConfigLoader::validateConfig(const ServerConfig& config) {
    // 验证模型路径
    checkModelPath(config.modelPath);
    
    // 验证批处理大小
    if (config.maxBatchSize == 0 || config.maxBatchSize > 128) {
        throw std::invalid_argument("Invalid max_batch_size");
    }
    
    // 验证上下文长度
    if (config.maxContextLength == 0 || config.maxContextLength > 32768) {
        throw std::invalid_argument("Invalid max_context_length");
    }
    
    // 验证内存限制
    checkMemoryLimits(config);
    
    // 验证端口
    checkPortAvailability(config.port);
}
```

## 4. 核心交互流程

### 4.1 文本生成流程

**步骤1: 请求接收**
```
客户端 → HTTP Server: POST /generate
     参数: prompt, max_tokens, temperature, top_k, top_p
```

**步骤2: 请求验证与预处理**
```
HTTP Server → RequestValidator: 验证请求参数
HTTP Server → Tokenizer: 对prompt进行编码
     Tokenizer返回: tokenized_prompt
```

**步骤3: 请求提交**
```
HTTP Server → Scheduler: 添加请求
     参数: tokenized_prompt, max_tokens, temperature
     Scheduler返回: request_id
```

**步骤4: 请求调度与批处理形成**
```
Scheduler → RequestQueue: 获取待处理请求
Scheduler → BatchManager: 形成批处理
     BatchManager返回: batch_requests
```

**步骤5: KV缓存准备**
```
BatchManager → KVCache: 获取现有缓存
     KVCache返回: existing_kv_cache
```

**步骤6: 模型推理**
```
BatchManager → ModelExecutor: 执行推理
     参数: batch_inputs, existing_kv_cache
     ModelExecutor返回: batch_outputs
```

**步骤7: Token采样**
```
ModelExecutor → Sampler: 采样下一个Token
     参数: logits, temperature
     Sampler返回: sampled_token
```

**步骤8: KV缓存更新**
```
ModelExecutor → KVCache: 更新缓存
     参数: sequence_id, new_key_part, new_value_part
```

**步骤9: 结果更新**
```
ModelExecutor → Scheduler: 更新请求结果
     参数: request_id, sampled_token
```

**步骤10: 检查生成完成**
```
Scheduler → BatchManager: 检查请求是否完成
     (检查是否达到max_tokens或生成eos_token)
```

**步骤11: 结果返回**
```
HTTP Server → Scheduler: 查询请求结果
     参数: request_id
     Scheduler返回: generated_tokens
HTTP Server → Tokenizer: 解码生成的Token
     Tokenizer返回: generated_text
HTTP Server → 客户端: 返回生成结果
     响应: {"generated_text": "..."}
```

### 4.2 流式生成流程

流式生成流程与普通生成流程类似，但在步骤11有所不同：

**步骤11: 流式结果返回**
```
HTTP Server → 客户端: 返回部分生成结果
     响应: data: {"token": "..."}
重复步骤5-11直到生成完成
HTTP Server → 客户端: 返回完成标记
     响应: data: [DONE]
```

### 4.3 文本编码流程

**步骤1: 请求接收**
```
客户端 → HTTP Server: POST /encode
     参数: text
```

**步骤2: 请求验证**
```
HTTP Server → RequestValidator: 验证请求参数
```

**步骤3: 文本编码**
```
HTTP Server → Tokenizer: 对文本进行编码
     参数: text
     Tokenizer返回: token_ids
```

**步骤4: 结果返回**
```
HTTP Server → 客户端: 返回编码结果
     响应: {"token_ids": [123, 456, ...]}
```

### 4.4 健康检查流程

**步骤1: 请求接收**
```
客户端 → HTTP Server: GET /health
```

**步骤2: 组件健康检查**
```
HTTP Server → Scheduler: 检查调度器状态
HTTP Server → ModelExecutor: 检查模型状态
HTTP Server → Tokenizer: 检查Tokenizer状态
```

**步骤3: 结果返回**
```
HTTP Server → 客户端: 返回健康状态
     响应: {"status": "healthy", "components": {"scheduler": "up", "model": "up", "tokenizer": "up"}}
```

## 4. 关键数据结构

### 4.1 RequestState
```cpp
struct RequestState {
    size_t requestId;                // 请求ID
    std::vector<int> tokenizedPrompt; // 编码后的提示
    std::vector<int> generatedTokens; // 生成的Token
    int maxTokens;                   // 最大生成Token数
    float temperature;               // 采样温度
    int topK;                        // Top-K参数
    float topP;                      // Top-P参数
    size_t arrivalTime;              // 请求到达时间
    size_t startTime;                // 请求开始处理时间
    size_t completionTime;           // 请求完成时间
    bool isCompleted;                // 是否已完成
    bool isRunning;                  // 是否正在运行
    bool isFailed;                   // 是否失败
    std::string errorMessage;        // 错误信息
};
```

### 4.2 BatchInput
```cpp
struct BatchInput {
    std::vector<RequestState> requests;  // 批处理中的请求
    size_t batchSize;                    // 批处理大小
    size_t maxContextLength;             // 最大上下文长度
};
```

### 4.3 BatchOutput
```cpp
struct BatchOutput {
    std::vector<std::vector<int>> generatedTokens; // 生成的Token批次
    std::vector<bool> isCompleted;                 // 每个请求是否完成
    std::vector<std::string> errorMessages;        // 错误信息（如果有）
};
```

## 5. 并发控制机制

### 5.1 线程安全保证

#### 5.1.1 锁分层策略

为了避免死锁，系统采用严格的锁分层策略：

```
锁层级顺序（从高到低）：

Level 1: HttpServer::mutex_           [最高层]
         |
         v
Level 2: Scheduler::mutex_
         |
         v
Level 3: BatchManager::mutex_
         |
         v
Level 4: RequestQueue::mutex_
         |
         v
Level 5: KVCache::cacheMutex_
         |
         v
Level 6: MemoryMonitor (atomic)       [最底层]
```

**锁获取规则**：
1. 只能从高层向低层获取锁
2. 禁止跨层级反向获取锁
3. 同层级的锁按固定顺序获取
4. 使用RAII（std::lock_guard）自动管理锁生命周期

#### 5.1.2 线程安全组件

| 组件 | 线程安全机制 | 说明 |
|------|--------------|------|
| **HttpServer** | 互斥锁 | 保护统计信息和请求处理 |
| **Scheduler** | 互斥锁 + 条件变量 | 同步请求队列和批处理 |
| **RequestQueue** | 互斥锁 | 保护队列操作 |
| **RequestTracker** | 互斥锁 | 保护请求状态更新 |
| **BatchManager** | 互斥锁 | 同步批处理操作 |
| **KVCache** | 互斥锁 | 保护缓存条目访问 |
| **MemoryMonitor** | 原子操作 | 无锁内存统计 |
| **ModelExecutor** | 互斥锁 | 保护模型推理操作 |
| **ThreadPool** | 互斥锁 + 条件变量 | 同步任务队列 |

#### 5.1.3 死锁避免策略

```cpp
// 正确示例：按层级获取锁
void Scheduler::processBatch() {
    std::lock_guard<std::mutex> schedulerLock(mutex_);  // Level 2
    
    // 获取请求
    {
        std::lock_guard<std::mutex> queueLock(requestQueue_.getMutex());  // Level 4
        // 处理请求队列
    }
    
    // 访问KV缓存
    {
        std::lock_guard<std::mutex> cacheLock(kvCache_->getMutex());  // Level 5
        // 访问缓存
    }
}

// 错误示例：反向获取锁（禁止）
void KVCache::someMethod() {
    std::lock_guard<std::mutex> cacheLock(cacheMutex_);  // Level 5
    
    // 禁止：从 Level 5 跳到 Level 2
    // scheduler_->updateRequest(...);  // 会获取 Level 2 的锁
}
```

### 5.2 并发场景分析

#### 5.2.1 请求并发处理

```
[多个并发请求]
     │
     ├─> 线程1: POST /generate → HttpServer
     │                              │
     ├─> 线程2: POST /generate → HttpServer
     │                              │
     └─> 线程3: POST /encode   → HttpServer
                                   │
                                   v
                              [RequestValidator]  # 线程安全，无状态
                                   │
                                   v
                              [Scheduler]         # 使用互斥锁
                                   │
                                   v
                              [RequestQueue]      # 线程安全队列
                                   │
                          [调度器线程异步处理]
```

#### 5.2.2 批处理并发控制

```cpp
// Scheduler中的批处理线程
void Scheduler::schedulerLoop() {
    while (running_) {
        std::unique_lock<std::mutex> lock(mutex_);
        
        // 等待新请求或超时
        cv_.wait_for(lock, std::chrono::milliseconds(10), [this] {
            return !requestQueue_.empty() || !running_;
        });
        
        if (!running_) break;
        
        // 处理批处理（持有锁）
        processBatch();
    }
}

// 批处理处理函数
void Scheduler::processBatch() {
    // mutex_ 已经被 schedulerLoop 持有
    
    // 形成批处理
    auto batch = batchManager_->formBatch(requestQueue_, config_.maxBatchSize);
    
    if (batch.requests.empty()) {
        return;
    }
    
    // 释放锁后执行推理（避免阻塞其他线程）
    mutex_.unlock();
    
    // 执行推理（无锁）
    auto output = modelExecutor_->forward(batch);
    
    // 重新获取锁更新结果
    mutex_.lock();
    
    // 更新请求状态
    updateRequests(batch, output);
}
```

### 5.3 读写锁优化

对于读多写少的场景，使用读写锁优化性能：

```cpp
// KVCache使用读写锁优化
class KVCache {
private:
    mutable std::shared_mutex cacheMutex_;  // 读写锁
    
public:
    // 读操作：多个线程可同时读取
    bool get(size_t sequenceId, KVCacheEntry& entry) const {
        std::shared_lock<std::shared_mutex> lock(cacheMutex_);
        // 读取缓存
        auto it = cache_.find(sequenceId);
        if (it == cache_.end()) {
            return false;
        }
        entry = it->second;
        return true;
    }
    
    // 写操作：独占访问
    void put(size_t sequenceId, const FloatArray& keyCache, 
             const FloatArray& valueCache) {
        std::unique_lock<std::shared_mutex> lock(cacheMutex_);
        // 写入缓存
        cache_[sequenceId] = KVCacheEntry(keyCache, valueCache, sequenceId);
        ensureMemoryLimit();
    }
};
```

## 6. 错误处理流程

### 6.1 请求验证错误
```
客户端 → HTTP Server: 无效请求参数
HTTP Server → RequestValidator: 验证失败
HTTP Server → 客户端: 返回400 Bad Request
     响应: {"error": "Invalid parameters", "details": "..."}
```

### 6.2 模型加载错误
```
Scheduler → ModelExecutor: 执行推理
ModelExecutor → 模型加载失败
ModelExecutor → Scheduler: 返回错误
Scheduler → HTTP Server: 返回500 Internal Server Error
     响应: {"error": "Model loading failed", "details": "..."}
```

### 6.3 推理错误
```
ModelExecutor → 推理失败
ModelExecutor → Scheduler: 更新请求状态为失败
Scheduler → HTTP Server: 返回500 Internal Server Error
     响应: {"error": "Inference failed", "details": "..."}
```

### 6.4 请求超时
```
Scheduler → BatchManager: 检查请求超时
Scheduler → 更新请求状态为失败
Scheduler → HTTP Server: 返回504 Gateway Timeout
     响应: {"error": "Request timeout", "details": "..."}
```

### 6.5 内存超限错误

```
MemoryMonitor → 检测到内存超限
MemoryMonitor → 触发内存限制回调
BatchManager → 收到回调，停止接收新请求
KVCache → 激进LRU淘汰策略
Scheduler → 返回503 Service Unavailable
     响应: {"error": "Memory limit exceeded", "details": "..."}
```

### 6.6 组件错误传播机制

```
[错误发生在 ModelExecutor]
         │
         v
  [抛出 ModelExecutionException]
         │
         v
  [BatchManager 捕获异常]
         │
         ├─> 记录错误日志
         ├─> 标记批处理失败
         └─> 返回错误给 Scheduler
                  │
                  v
         [Scheduler 处理错误]
                  │
                  ├─> 更新请求状态为 FAILED
                  ├─> 记录请求错误信息
                  └─> 通知 HttpServer
                           │
                           v
                  [HttpServer 构建错误响应]
                           │
                           v
                       [返回客户端]
```

#### 6.6.1 异常层次结构

```cpp
// 基础异常类
class cLLMException : public std::runtime_error {
public:
    cLLMException(const std::string& msg) : std::runtime_error(msg) {}
    virtual int getErrorCode() const = 0;
};

// 模型异常
class ModelException : public cLLMException {
public:
    enum ErrorCode {
        MODEL_NOT_FOUND = 1001,
        MODEL_LOAD_FAILED = 1002,
        INFERENCE_FAILED = 1003,
    };
    
    ModelException(ErrorCode code, const std::string& msg)
        : cLLMException(msg), code_(code) {}
    
    int getErrorCode() const override { return code_; }
    
private:
    ErrorCode code_;
};

// 内存异常
class MemoryException : public cLLMException {
public:
    enum ErrorCode {
        MEMORY_LIMIT_EXCEEDED = 2001,
        ALLOCATION_FAILED = 2002,
    };
    
    MemoryException(ErrorCode code, const std::string& msg)
        : cLLMException(msg), code_(code) {}
    
    int getErrorCode() const override { return code_; }
    
private:
    ErrorCode code_;
};

// 调度异常
class SchedulerException : public cLLMException {
public:
    enum ErrorCode {
        REQUEST_TIMEOUT = 3001,
        BATCH_PROCESSING_FAILED = 3002,
        INVALID_REQUEST = 3003,
    };
    
    SchedulerException(ErrorCode code, const std::string& msg)
        : cLLMException(msg), code_(code) {}
    
    int getErrorCode() const override { return code_; }
    
private:
    ErrorCode code_;
};
```

#### 6.6.2 错误处理示例

```cpp
// Scheduler中的错误处理
void Scheduler::processBatch() {
    try {
        // 形成批处理
        auto batch = batchManager_->formBatch(requestQueue_, config_.maxBatchSize);
        
        // 执行推理
        auto output = modelExecutor_->forward(batch);
        
        // 更新结果
        updateRequests(batch, output);
        
    } catch (const ModelException& e) {
        // 模型错误
        LOG_ERROR("Model execution failed: " << e.what());
        markBatchAsFailed(batch, e.getErrorCode(), e.what());
        
    } catch (const MemoryException& e) {
        // 内存错误
        LOG_ERROR("Memory error: " << e.what());
        markBatchAsFailed(batch, e.getErrorCode(), e.what());
        // 触发紧急清理
        emergencyCleanup();
        
    } catch (const std::exception& e) {
        // 通用异常
        LOG_ERROR("Unexpected error: " << e.what());
        markBatchAsFailed(batch, -1, e.what());
    }
}

// HttpServer中的错误响应
void HttpServer::handleGenerateRequest(const HttpRequest& req, HttpResponse& resp) {
    try {
        // 验证请求
        validator_->validateGenerateRequest(req);
        
        // 提交请求
        auto requestId = scheduler_->addRequest(req);
        
        // 等待结果
        auto result = scheduler_->getRequestResult(requestId);
        
        // 返回结果
        resp.setStatus(200);
        resp.setBody(result.toJson());
        
    } catch (const SchedulerException& e) {
        if (e.getErrorCode() == SchedulerException::REQUEST_TIMEOUT) {
            resp.setStatus(504);
        } else {
            resp.setStatus(500);
        }
        resp.setBody(buildErrorResponse(e.getErrorCode(), e.what()));
        
    } catch (const std::invalid_argument& e) {
        resp.setStatus(400);
        resp.setBody(buildErrorResponse(400, e.what()));
        
    } catch (const std::exception& e) {
        resp.setStatus(500);
        resp.setBody(buildErrorResponse(500, e.what()));
    }
}
```

## 7. 性能优化考虑

### 7.1 批处理优化
- **动态批处理**: BatchManager根据请求长度和系统负载动态调整批处理大小
- **批处理合并**: 相似长度的请求优先合并，减少内存碎片
- **批处理优先级**: 长时间运行的请求和短请求分开处理，避免饥饿

### 7.2 KV缓存优化
- **增量更新**: 仅更新新增的KV缓存部分，减少内存拷贝
- **LRU淘汰**: 当缓存达到上限时，淘汰最久未使用的条目
- **内存限制**: 严格控制缓存总大小，避免OOM

### 7.3 请求调度优化
- **优先级调度**: 基于请求长度、等待时间等因素计算优先级
- **请求分组**: 相似类型的请求分组处理，提高缓存命中率
- **超时处理**: 及时清理超时请求，释放资源

### 7.4 并发优化

- **无锁数据结构**: 在适合的场景使用lock-free queue
- **细粒度锁**: 减少锁的粒度，降低锁竞争
- **读写锁**: 对读多写少的场景使用std::shared_mutex
- **原子操作**: 对简单计数器使用std::atomic
- **线程局部存储**: 减少共享数据访问

### 7.5 内存优化

- **内存池**: 使用mimalloc优化内存分配
- **对象池**: 复用频繁创建的对象（如BatchInput/Output）
- **零拷贝**: 使用移动语义避免不必要的拷贝
- **内存对齐**: 确保数据对齐以支持SIMD优化

## 8. 监控与日志

### 8.1 组件监控点
- **HTTP Server**: 请求数、响应时间、错误率
- **Scheduler**: 队列长度、请求处理时间、批处理大小
- **ModelExecutor**: 推理延迟、内存使用、批处理吞吐量
- **Tokenizer**: 编码/解码延迟、缓存命中率
- **KVCache**: 缓存命中率、内存使用、淘汰数量

### 8.2 关键日志事件
- 请求开始/完成/失败
- 批处理形成/处理/完成
- 模型加载/卸载/推理
- KV缓存命中/未命中/淘汰
- 系统错误/异常

## 9. 扩展性设计

### 9.1 组件扩展点
- **API端点**: 支持动态注册新的API端点
- **批处理策略**: 支持自定义批处理形成算法
- **调度策略**: 支持自定义请求调度算法
- **采样策略**: 支持自定义Token采样策略
- **模型后端**: 支持不同的模型推理后端

### 9.2 扩展示例
```cpp
// 注册自定义批处理策略
batchManager->registerBatchStrategy("custom_strategy", customBatchFunction);

// 注册自定义采样策略
modelExecutor->getSampler()->registerSamplingStrategy("custom_sampling", customSamplingFunction);

// 注册自定义API端点
httpServer->registerEndpoint("/custom", CustomEndpoint());
```

## 10. 安全考虑

### 10.1 输入验证
- 所有HTTP请求参数必须经过严格验证
- 文本输入进行适当的转义和过滤
- 防止SQL注入、XSS等攻击

### 10.2 资源限制
- 限制每个请求的最大Token数
- 限制批处理大小，防止资源耗尽
- 限制并发请求数，避免系统过载

### 10.3 错误处理
- 避免返回详细的错误信息给客户端
- 所有错误记录到内部日志
- 敏感信息不包含在响应中

## 11. 测试考虑

### 11.1 组件交互测试
- **单元测试**: 测试每个组件的独立功能
- **集成测试**: 测试组件之间的交互
- **端到端测试**: 测试完整的请求处理流程

### 11.2 性能测试
- **负载测试**: 测试系统在高负载下的性能
- **并发测试**: 测试系统处理并发请求的能力
- **延迟测试**: 测试系统的响应延迟

### 11.3 故障测试
- **组件故障**: 测试单个组件故障时的系统行为
- **网络故障**: 测试网络故障时的系统行为
- **资源限制**: 测试资源限制时的系统行为

# 附录

## A. 组件交互序列图

### A.1 文本生成序列图

```
客户端 → HTTP Server: POST /generate
HTTP Server → RequestValidator: 验证参数
HTTP Server → Tokenizer: encode(prompt)
Tokenizer → HTTP Server: [token_ids]
HTTP Server → Scheduler: addRequest(token_ids, ...)
Scheduler → RequestQueue: push(request)
Scheduler → BatchManager: formBatch()
BatchManager → RequestQueue: popBatch()
BatchManager → ModelExecutor: forward(batch_inputs)
ModelExecutor → KVCache: get(sequence_id)
KVCache → ModelExecutor: [kv_cache]
ModelExecutor → Sampler: sample(logits)
Sampler → ModelExecutor: [sampled_token]
ModelExecutor → KVCache: update(sequence_id, new_kv)
ModelExecutor → BatchManager: [batch_outputs]
BatchManager → Scheduler: updateRequest(request_id, sampled_token)
Scheduler → HTTP Server: [generated_tokens]
HTTP Server → Tokenizer: decode(generated_tokens)
Tokenizer → HTTP Server: [generated_text]
HTTP Server → 客户端: 返回生成结果
```

### A.2 流式生成序列图

```
客户端 → HTTP Server: POST /generate (stream=true)
HTTP Server → RequestValidator: 验证参数
HTTP Server → Tokenizer: encode(prompt)
Tokenizer → HTTP Server: [token_ids]
HTTP Server → Scheduler: addRequest(token_ids, ...)
Scheduler → RequestQueue: push(request)

loop 直到生成完成
    Scheduler → BatchManager: formBatch()
    BatchManager → ModelExecutor: forward(batch_inputs)
    ModelExecutor → Sampler: sample(logits)
    ModelExecutor → Scheduler: updateRequest(request_id, sampled_token)
    Scheduler → HTTP Server: [sampled_token]
    HTTP Server → Tokenizer: decode(sampled_token)
    HTTP Server → 客户端: data: {"token": "..."}
end

HTTP Server → 客户端: data: [DONE]
```

## B. 组件依赖关系

| 组件 | 依赖组件 | 依赖原因 |
|------|----------|----------|
| HTTP Server | Scheduler, TokenizerManager, RequestValidator | 请求处理、文本编解码和参数验证 |
| RequestValidator | 无 | 独立组件，验证请求参数 |
| Scheduler | BatchManager, ModelExecutor, TokenizerManager, RequestQueue, RequestTracker | 批处理、模型推理、文本编解码、请求队列管理和跟踪 |
| RequestQueue | 无 | 独立组件，管理请求队列 |
| RequestTracker | 无 | 独立组件，跟踪请求状态 |
| BatchManager | ModelExecutor, KVCache, MemoryMonitor | 模型推理、KV缓存管理和内存监控 |
| TokenizerManager | Tokenizer, ModelExecutor (optional) | 文本编解码，可能需要模型信息 |
| ModelExecutor | Sampler, KVCache, ThreadPool | Token采样、KV缓存和线程池 |
| Sampler | 无 | 独立组件 |
| KVCache | MemoryMonitor | 内存使用监控 |
| MemoryMonitor | 无 | 独立组件 |
| ThreadPool | 无 | 独立组件 |
| Tokenizer | 无 | 独立组件 |

## C. 关键API参考

### C.1 HTTP API
- `POST /generate`: 文本生成
- `POST /encode`: 文本编码
- `GET /health`: 健康检查

### C.2 核心组件接口

#### Scheduler接口
```cpp
size_t addRequest(const RequestState& request);
bool removeRequest(size_t requestId);
RequestState getRequestResult(size_t requestId);
void start();
void stop();
```

#### ModelExecutor接口
```cpp
BatchOutput forward(const BatchInput& input);
std::vector<int> generate(const std::vector<int>& inputIds, size_t maxNewTokens, float temperature);
void loadModel();
void unloadModel();
```

#### Tokenizer接口
```cpp
std::vector<int> encode(const std::string& text, bool addSpecialTokens = false);
std::string decode(const std::vector<int>& tokenIds, bool skipSpecialTokens = true);
void loadModel(const std::string& modelPath);
```

#### KVCache接口
```cpp
bool get(size_t sequenceId, KVCacheEntry& entry);
void put(size_t sequenceId, const FloatArray& keyCache, const FloatArray& valueCache);
void updateIncremental(size_t sequenceId, const FloatArray& newKeyPart, const FloatArray& newValuePart);
void remove(size_t sequenceId);
```

#### Sampler接口
```cpp
int sample(const FloatArray& logits, float temperature = 1.0f);
void setTemperature(float temperature);
```