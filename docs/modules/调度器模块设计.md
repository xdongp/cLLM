# 调度器模块设计

## 编程规范

本模块的编码实现遵循以下规范和约定：
- [C++编程规范.md](../../C++编程规范.md)：定义编码风格、命名规范等
- [生成代码规范.md](../生成代码规范.md)：定义代码生成流程、设计文档一致性要求、优化同步机制等

## 0. 要生成的文件

### 0.1 头文件（include/cllm/scheduler/）

根据[C++编程规范.md](../../C++编程规范.md)的命名规范，本模块需要生成以下头文件：

| 文件名 | 对应类/结构体 | 说明 |
|--------|--------------|------|------|
| `scheduler.h` | `Scheduler` | 调度器主类，协调请求的生命周期 |
| `config.h` | `SchedulerConfig` | 调度器配置结构体 |
| `stats.h` | `SchedulerStats` | 调度器统计信息结构体 |
| `tracker.h` | `RequestTracker` | 请求跟踪器，管理请求状态 |
| `batch_processor.h` | `BatchProcessor` | 批处理处理器 |

### 0.2 源文件（src/scheduler/）

| 文件名 | 对应头文件 | 说明 |
|--------|-----------|------|
| `scheduler.cpp` | `scheduler.h` | Scheduler类的实现 |
| `stats.cpp` | `stats.h` | SchedulerStats类的实现 |
| `tracker.cpp` | `tracker.h` | RequestTracker类的实现 |
| `batch_processor.cpp` | `batch_processor.h` | BatchProcessor类的实现 |

### 0.3 测试文件（tests/）

| 文件名 | 测试目标 | 说明 |
|--------|---------|------|
| `test_scheduler.cpp` | Scheduler, RequestTracker, BatchProcessor | 调度器模块的单元测试 |

### 0.4 文件命名规范说明

- **头文件名**：使用小写字母+下划线，与类名对应（大驼峰转小写下划线）
- **源文件名**：与对应头文件名保持一致
- **目录结构**：头文件位于 `include/cllm/scheduler/`，源文件位于 `src/scheduler/`
- **一致性原则**：所有文件命名遵循[C++编程规范.md](../../C++编程规范.md)第1.1节

## 1. 模块概述

### 1.1 模块职责
调度器模块是整个推理系统的核心协调组件，负责管理请求的生命周期、协调各个子模块的工作、实现高效的请求调度和批处理策略。该模块确保系统在保证响应速度的同时最大化吞吐量。

### 1.2 核心功能
- 请求生命周期管理：从请求添加到完成的全流程管理
- 请求队列管理：基于优先级的请求调度
- 批处理协调：协调批处理形成和处理
- 状态跟踪：跟踪运行中和已完成的请求
- 结果查询：提供请求结果的查询接口
- 性能监控：监控调度器性能指标

### 1.3 设计原则
- 高效性：最大化系统吞吐量
- 响应性：保证请求的快速响应
- 可扩展性：易于添加新的调度策略
- 可靠性：保证请求的正确处理

### 1.4 模块依赖

本模块依赖以下模块：

| 依赖模块 | 依赖类/结构体 | 依赖原因 |
|----------|--------------|----------|
| `common` | `RequestQueue`, `RequestState` | 请求队列管理和请求状态 |
| `batch` | `BatchManager`, `BatchInput`, `BatchOutput` | 批处理管理 |
| `model` | `ModelExecutor` | 模型推理执行 |
| `kv_cache` | `KVCache` | KV缓存管理 |

**重要**：调度器模块是系统的中央协调器，它不被其他业务模块依赖，仅被HTTP Server调用。

### 1.5 命名空间

所有类和函数都在 `cllm` 命名空间下：

```cpp
namespace cllm {
    class Scheduler { ... };
    class RequestTracker { ... };
    class BatchProcessor { ... };
    struct SchedulerStats { ... };
    struct SchedulerConfig { ... };
}
```

## 2. 类设计

### 2.1 异常处理

调度器模块定义了专用的异常类型：

```cpp
enum class SchedulerError {
    SCHEDULER_NOT_RUNNING,      // 调度器未运行
    REQUEST_NOT_FOUND,          // 请求未找到
    REQUEST_TIMEOUT,            // 请求超时
    BATCH_PROCESSING_FAILED,    // 批处理失败
    INVALID_REQUEST             // 无效请求
};

class SchedulerException : public std::runtime_error {
public:
    SchedulerException(SchedulerError error, const std::string& message)
        : std::runtime_error(message), error_(error) {}
    
    SchedulerError getError() const { return error_; }
    
private:
    SchedulerError error_;
};
```

**异常处理策略**：
- 对于关键错误（如模型加载失败），抛出异常
- 对于非关键错误（如单个请求失败），记录日志并标记请求为失败
- 所有异常都应在HTTP Server层被捕获并转换为适当的HTTP响应

### 2.2 Scheduler
```cpp
class Scheduler {
public:
    Scheduler(
        const std::string& modelPath,
        const std::string& quantization = "",
        size_t maxBatchSize = 8,
        size_t maxContextLength = 2048
    );
    
    ~Scheduler();
    
    void start();
    void stop();
    
    size_t addRequest(const RequestState& request);
    bool removeRequest(size_t requestId);
    
    RequestState getRequestResult(size_t requestId);
    bool waitForRequest(size_t requestId, float timeout = 300.0f);
    
    std::vector<RequestState> getRunningRequests() const;
    std::vector<RequestState> getCompletedRequests() const;
    size_t getQueueSize() const;
    
    SchedulerStats getStats() const;
    void resetStats();
    
private:
    void schedulerLoop();
    void processRequests();
    void processBatch(std::vector<RequestState>& batch);
    float getCurrentTime();
    
    RequestQueue requestQueue_;
    BatchManager batchManager_;
    ModelExecutor* modelExecutor_;
    KVCache* kvCache_;
    RequestTracker requestTracker_;  // ← 在类图中明确添加
    
    std::map<size_t, RequestState> runningRequests_;
    std::map<size_t, RequestState> completedRequests_;
    
    std::thread schedulerThread_;
    std::atomic<bool> running_;
    
    size_t maxBatchSize_;
    size_t maxContextLength_;
    SchedulerConfig config_;
    
    mutable std::mutex requestsMutex_;
    std::condition_variable resultCondition_;
    
    SchedulerStats stats_;
};
```

**接口说明**：
- `requestTracker_`：用于跟踪请求状态，确保请求的正确处理和结果返回
- `requestQueue_`：管理待处理的请求队列
- `batchManager_`：负责批处理的形成和管理
- `modelExecutor_`：执行模型推理
- `kvCache_`：管理KV缓存

### 2.2 SchedulerStats
```cpp
struct SchedulerStats {
    size_t totalRequests;
    size_t completedRequests;
    size_t failedRequests;
    size_t totalBatches;
    float averageBatchSize;
    float averageRequestTime;
    float averageWaitTime;
    size_t peakQueueSize;
    
    void update(const RequestState& request);
    void updateBatch(const std::vector<RequestState>& batch);
    void reset();
    
    std::string toString() const;
};
```

### 2.3 SchedulerConfig
```cpp
struct SchedulerConfig {
    size_t maxBatchSize = 8;
    size_t maxContextLength = 2048;
    float contextUsageThreshold = 0.75f;
    float defaultTemperature = 0.7f;
    float defaultTopP = 0.9f;
    int defaultTopK = 50;
    size_t defaultMaxTokens = 100;
    float requestTimeout = 300.0f;
    
    size_t schedulerLoopInterval = 100;  // microseconds
    size_t idleLoopInterval = 10000;     // microseconds
};
```

### 2.4 RequestTracker
```cpp
class RequestTracker {
public:
    explicit RequestTracker();
    ~RequestTracker();
    
    size_t addRequest(const RequestState& request);
    bool updateRequest(size_t requestId, const RequestState& updated);
    bool removeRequest(size_t requestId);
    
    RequestState getRequest(size_t requestId) const;
    std::vector<RequestState> getRunningRequests() const;
    std::vector<RequestState> getCompletedRequests() const;
    
    bool markAsRunning(size_t requestId);
    bool markAsCompleted(size_t requestId);
    bool markAsFailed(size_t requestId, const std::string& error);
    
    size_t getRunningCount() const;
    size_t getCompletedCount() const;
    
private:
    std::map<size_t, RequestState> runningRequests_;
    std::map<size_t, RequestState> completedRequests_;
    
    mutable std::mutex mutex_;
    std::condition_variable condition_;
    
    std::atomic<size_t> nextRequestId_;
};
```

### 2.5 BatchProcessor
```cpp
class BatchProcessor {
public:
    explicit BatchProcessor(
        Scheduler* scheduler,
        ModelExecutor* executor,
        KVCache* cache
    );
    ~BatchProcessor();
    
    void processBatch(std::vector<RequestState>& batch);
    
    bool isBatchComplete(const std::vector<RequestState>& batch) const;
    std::vector<RequestState> getActiveRequests(
        const std::vector<RequestState>& batch
    ) const;
    
private:
    void processIteration(std::vector<RequestState>& batch);
    void updateRequestStates(
        std::vector<RequestState>& batch,
        const BatchOutput& output
    );
    
    Scheduler* scheduler_;
    ModelExecutor* executor_;
    KVCache* cache_;
};
```

## 3. 接口设计

### 3.1 Scheduler接口
```cpp
class Scheduler {
public:
    Scheduler(
        const std::string& modelPath,
        const std::string& quantization = "",
        size_t maxBatchSize = 8,
        size_t maxContextLength = 2048
    );
    
    ~Scheduler();
    
    void start();
    void stop();
    
    size_t addRequest(const RequestState& request);
    bool removeRequest(size_t requestId);
    
    RequestState getRequestResult(size_t requestId);
    bool waitForRequest(size_t requestId, float timeout = 300.0f);
    
    std::vector<RequestState> getRunningRequests() const;
    std::vector<RequestState> getCompletedRequests() const;
    size_t getQueueSize() const;
    
    SchedulerStats getStats() const;
    void resetStats();
    
private:
    void schedulerLoop();
    void processRequests();
    
    RequestQueue requestQueue_;
    BatchManager batchManager_;
    ModelExecutor* modelExecutor_;
    KVCache* kvCache_;
    
    std::map<size_t, RequestState> runningRequests_;
    std::map<size_t, RequestState> completedRequests_;
    
    std::thread schedulerThread_;
    std::atomic<bool> running_;
    
    size_t maxBatchSize_;
    size_t maxContextLength_;
    
    mutable std::mutex requestsMutex_;
    std::condition_variable resultCondition_;
    
    SchedulerStats stats_;
};
```

### 3.2 RequestTracker接口
```cpp
class RequestTracker {
public:
    explicit RequestTracker();
    ~RequestTracker();
    
    size_t addRequest(const RequestState& request);
    bool updateRequest(size_t requestId, const RequestState& updated);
    bool removeRequest(size_t requestId);
    
    RequestState getRequest(size_t requestId) const;
    std::vector<RequestState> getRunningRequests() const;
    std::vector<RequestState> getCompletedRequests() const;
    
    bool markAsRunning(size_t requestId);
    bool markAsCompleted(size_t requestId);
    bool markAsFailed(size_t requestId, const std::string& error);
    
    size_t getRunningCount() const;
    size_t getCompletedCount() const;
    
private:
    std::map<size_t, RequestState> runningRequests_;
    std::map<size_t, RequestState> completedRequests_;
    
    mutable std::mutex mutex_;
    std::condition_variable condition_;
    
    std::atomic<size_t> nextRequestId_;
};
```

## 4. 算法实现

### 4.1 调度器主循环
```cpp
void Scheduler::schedulerLoop() {
    while (running_) {
        try {
            stats_.totalRequests++;
            
            processRequests();
            
            size_t queueSize = requestQueue_.getQueueSize();
            size_t runningCount = runningRequests_.size();
            
            if (queueSize == 0 && runningCount == 0) {
                std::this_thread::sleep_for(
                    std::chrono::microseconds(config_.idleLoopInterval)
                );
            } else {
                std::this_thread::sleep_for(
                    std::chrono::microseconds(config_.schedulerLoopInterval)
                );
            }
            
        } catch (const std::exception& e) {
            std::cerr << "Error in scheduler loop: " << e.what() << std::endl;
            std::this_thread::sleep_for(std::chrono::seconds(1));
        }
    }
}
```

### 4.2 请求处理流程
```cpp
void Scheduler::processRequests() {
    if (requestQueue_.getQueueSize() == 0) {
        return;
    }
    
    std::vector<RequestState> running = getRunningRequests();
    
    auto batches = batchManager_.formMultipleBatches(
        requestQueue_.getPendingRequests(),
        running
    );
    
    if (batches.empty()) {
        return;
    }
    
    for (auto& batch : batches) {
        processBatch(batch);
    }
}
```

### 4.3 批处理处理
```cpp
void Scheduler::processBatch(std::vector<RequestState>& batch) {
    BatchProcessor processor(this, modelExecutor_, kvCache_);
    
    while (!processor.isBatchComplete(batch)) {
        auto activeRequests = processor.getActiveRequests(batch);
        
        if (activeRequests.empty()) {
            break;
        }
        
        BatchInput input = batchManager_.prepareBatchInput(activeRequests);
        
        BatchOutput output = modelExecutor_->forward(input);
        
        processor.updateRequestStates(batch, output);
        
        stats_.updateBatch(batch);
    }
    
    for (const auto& request : batch) {
        if (request.isCompleted) {
            requestTracker_.markAsCompleted(request.requestId);
            stats_.update(request);
        }
    }
}
```

### 4.4 请求添加
```cpp
size_t Scheduler::addRequest(const RequestState& request) {
    RequestState req = request;
    
    if (req.requestId == 0) {
        req.requestId = requestTracker_.addRequest(req);
    }
    
    req.arrivalTime = getCurrentTime();
    req.priority = req.calculatePriority(req.arrivalTime);
    
    requestQueue_.addRequest(req);
    
    return req.requestId;
}
```

### 4.5 请求等待
```cpp
bool Scheduler::waitForRequest(size_t requestId, float timeout) {
    auto startTime = std::chrono::steady_clock::now();
    
    while (true) {
        {
            std::lock_guard<std::mutex> lock(requestsMutex_);
            if (completedRequests_.find(requestId) != completedRequests_.end()) {
                return true;
            }
        }
        
        auto currentTime = std::chrono::steady_clock::now();
        auto elapsed = std::chrono::duration<float>(currentTime - startTime).count();
        
        if (elapsed >= timeout) {
            return false;
        }
        
        std::this_thread::sleep_for(std::chrono::milliseconds(10));
    }
}
```

## 5. 并发设计

### 5.1 线程模型
- 主调度线程：运行调度器循环
- 工作线程：处理批处理推理
- 请求线程：客户端请求处理

### 5.2 同步机制
```cpp
class Scheduler {
private:
    mutable std::mutex requestsMutex_;
    std::condition_variable resultCondition_;
    std::atomic<bool> running_;
};
```

### 5.3 线程安全保证
- 使用互斥锁保护共享状态
- 使用条件变量实现请求等待
- 使用原子变量保证状态可见性

## 6. 内存管理

### 6.1 内存分配策略
- 使用mimalloc进行高效内存分配
- 使用RAII包装器管理动态数组
- 限制运行中请求数量防止内存溢出

### 6.2 内存优化
```cpp
class Scheduler {
private:
    void optimizeMemoryUsage() {
        if (completedRequests_.size() > 1000) {
            auto it = completedRequests_.begin();
            std::advance(it, 500);
            completedRequests_.erase(completedRequests_.begin(), it);
        }
    }
};
```

## 7. 错误处理

### 7.1 错误类型
```cpp
enum class SchedulerError {
    SCHEDULER_NOT_RUNNING,
    REQUEST_NOT_FOUND,
    REQUEST_TIMEOUT,
    BATCH_PROCESSING_FAILED,
    INVALID_REQUEST
};

class SchedulerException : public std::runtime_error {
public:
    SchedulerException(SchedulerError error, const std::string& message)
        : std::runtime_error(message), error_(error) {}
    
    SchedulerError getError() const { return error_; }
    
private:
    SchedulerError error_;
};
```

### 7.2 错误处理策略
- 记录错误日志
- 标记失败请求
- 继续处理其他请求
- 提供错误信息给客户端

## 8. 性能优化

### 8.1 调度优化
- 动态调整批处理大小
- 优先处理短请求
- 智能负载均衡

### 8.2 内存优化
- 定期清理已完成请求
- 重用批处理缓冲区
- 优化KV缓存使用

### 8.3 并发优化
- 减少锁竞争
- 使用读写锁
- 批量操作优化

## 9. 测试策略

### 9.1 单元测试
```cpp
class SchedulerTest {
public:
    void testAddRequest();
    void testRemoveRequest();
    void testProcessBatch();
    void testWaitForRequest();
    void testGetRequestResult();
    void testConcurrency();
    void testErrorHandling();
};
```

### 9.2 性能测试
- 测试吞吐量（requests/s）
- 测试延迟（p50, p95, p99）
- 测试并发性能
- 测试内存使用

### 9.3 集成测试
- 与HTTP Server集成测试
- 与Model Executor集成测试
- 端到端性能测试

## 10. 使用示例

### 10.1 基本使用
```cpp
Scheduler scheduler("model_path", "int8", 8, 2048);

scheduler.start();

RequestState request;
request.prompt = "Hello, world!";
request.maxTokens = 100;
request.temperature = 0.7f;

size_t requestId = scheduler.addRequest(request);

if (scheduler.waitForRequest(requestId, 300.0f)) {
    auto result = scheduler.getRequestResult(requestId);
    std::cout << "Generated: " << result.generatedText << std::endl;
}

scheduler.stop();
```

### 10.2 批量请求
```cpp
std::vector<size_t> requestIds;

for (int i = 0; i < 10; ++i) {
    RequestState request;
    request.prompt = "Prompt " + std::to_string(i);
    request.maxTokens = 50;
    
    size_t id = scheduler.addRequest(request);
    requestIds.push_back(id);
}

for (size_t id : requestIds) {
    if (scheduler.waitForRequest(id, 300.0f)) {
        auto result = scheduler.getRequestResult(id);
        std::cout << "Request " << id << ": " << result.generatedText << std::endl;
    }
}
```

## 11. 配置参数

### 11.1 调度器配置
```cpp
struct SchedulerConfig {
    size_t maxBatchSize = 8;
    size_t maxContextLength = 2048;
    float contextUsageThreshold = 0.75f;
    float defaultTemperature = 0.7f;
    float defaultTopP = 0.9f;
    int defaultTopK = 50;
    size_t defaultMaxTokens = 100;
    float requestTimeout = 300.0f;
    
    size_t schedulerLoopInterval = 100;
    size_t idleLoopInterval = 10000;
};
```

### 11.2 性能配置
```cpp
struct PerformanceConfig {
    bool enableBatchReuse = true;
    bool enableCacheReuse = true;
    size_t maxRunningRequests = 100;
    size_t maxCompletedRequests = 1000;
    bool enableStatsCollection = true;
};
```

## 12. 监控指标

### 12.1 请求指标
- 总请求数
- 完成请求数
- 失败请求数
- 平均请求时间
- 平均等待时间

### 12.2 批处理指标
- 总批处理数
- 平均批处理大小
- 峰值队列大小

### 12.3 系统指标
- CPU使用率
- 内存使用量
- KV缓存命中率

## 13. 依赖关系

### 13.1 外部依赖
- C++标准库（std::thread, std::mutex, std::condition_variable）
- mimalloc（内存管理）
- 日志库（日志记录）

### 13.2 内部依赖
- RequestQueue（请求队列）
- BatchManager（批处理管理）
- ModelExecutor（模型执行）
- KVCache（KV缓存）
- RequestState（请求状态）

## 14. 后续优化方向

### 14.1 短期优化
- 实现更智能的调度策略
- 添加请求预测功能
- 优化批处理形成算法

### 14.2 长期优化
- 实现分布式调度
- 支持请求优先级调度
- 添加请求重试机制
- 实现自适应调度算法
