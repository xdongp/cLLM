# ThreadPool 模块详细设计

## 编程规范

本模块的编码实现遵循以下规范和约定：
- [C++编程规范.md](../../C++编程规范.md)：定义编码风格、命名规范等
- [生成代码规范.md](../生成代码规范.md)：定义代码生成流程、设计文档一致性要求、优化同步机制等

## 0. 要生成的文件

### 0.1 头文件（include/cllm/thread_pool/）

根据[C++编程规范.md](../../C++编程规范.md)的命名规范，本模块需要生成以下头文件：

| 文件名 | 对应类/结构体 | 说明 |
|--------|--------------|------|
| `manager.h` | `ThreadPoolManager` | 线程池管理器，封装BS::thread_pool |
| `monitor.h` | `ThreadPoolMonitor`, `ThreadPoolStats` | 线程池监控器和统计信息结构体 |

### 0.2 源文件（src/thread_pool/）

| 文件名 | 对应头文件 | 说明 |
|--------|-----------|------|
| `manager.cpp` | `manager.h` | ThreadPoolManager类的实现 |
| `monitor.cpp` | `monitor.h` | ThreadPoolMonitor类的实现 |

### 0.3 测试文件（tests/）

| 文件名 | 测试目标 | 说明 |
|--------|---------|------|
| `test_threadpool.cpp` | ThreadPoolManager, ThreadPoolMonitor | 线程池模块的单元测试 |

### 0.4 文件命名规范说明

- **头文件名**：使用小写字母+下划线，与类名对应（大驼峰转小写下划线）
- **源文件名**：与对应头文件名保持一致
- **目录结构**：头文件位于 `include/cllm/thread_pool/`，源文件位于 `src/thread_pool/`
- **一致性原则**：所有文件命名遵循[C++编程规范.md](../../C++编程规范.md)第1.1节

## 1. 模块概述

### 1.1 模块职责

ThreadPool模块负责cLLM系统中的线程管理，包括：
- 线程池的创建和管理
- 任务的提交和执行
- 线程池的动态调整
- 任务队列的管理
- 线程池的监控和统计

### 1.2 模块目标

- 提供高效的线程池实现
- 支持动态调整线程池大小
- 实现任务队列管理
- 提供线程池监控和统计
- 支持任务优先级
- 提供优雅关闭机制

### 1.3 设计原则

- **性能优先**: 使用BS::thread_pool高性能线程池库
- **简洁优先**: 避免过度设计，保持接口简洁
- **安全优先**: 确保线程安全和资源管理
- **可维护**: 使用成熟的三方库，减少维护成本
- **可测试**: 所有组件都易于测试

### 1.4 技术选型

本模块采用**BS::thread_pool**作为底层线程池实现，基于以下原因：

1. **性能优秀**: 专为高性能计算设计，任务调度开销极低
2. **集成简单**: 单头文件实现，无需复杂的构建过程
3. **无外部依赖**: 仅依赖标准库，符合项目简单性原则
4. **现代C++**: 支持C++17/20/23，充分利用现代C++特性
5. **活跃维护**: 版本更新频繁，社区活跃
6. **文档完善**: 提供详细的文档和丰富的示例
7. **MIT许可证**: 商业友好，无专利条款
8. **功能完整**: 支持任务优先级、任务取消、批量提交等

### 1.5 模块依赖

本模块无其他内部模块依赖，仅依赖：

| 依赖项 | 类型 | 说明 |
|--------|------|------|
| BS::thread_pool | 外部库 | 第三方线程池库，位于`third_party/BS_thread_pool.hpp` |
| C++20 标准库 | 系统库 | `<thread>`, `<mutex>`, `<atomic>`, `<functional>` |

**重要**：线程池模块是基础设施模块，被调度器、HTTP Server等模块使用。

### 1.6 命名空间

所有类和函数都在 `cllm` 命名空间下：

```cpp
namespace cllm {
    class ThreadPoolManager { ... };
    class ThreadPoolMonitor { ... };
    struct ThreadPoolStats { ... };
}
```

## 2. 类设计

### 2.1 类图

```
┌─────────────────────────────────────────────────────────┐
│              ThreadPoolManager                            │
│  + ThreadPoolManager(numThreads: size_t)                 │
│  + ~ThreadPoolManager()                                   │
│  + submitTask(task: Task): void                           │
│  + submitTaskWithResult(func: Function, args: Args...): Future<T>
│  + waitForAll(): void                                    │
│  + shutdown(): void                                       │
│  + getThreadCount(): size_t                              │
│  + getTasksTotal(): size_t                               │
│  + getTasksRunning(): size_t                             │
│  + getTasksQueued(): size_t                              │
│  + pause(): void                                         │
│  + resume(): void                                        │
│  + isPaused(): bool                                      │
│  - pool_: BS::thread_pool                                │
│  - paused_: bool                                         │
└─────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────┐
│              ThreadPoolMonitor                           │
│  + ThreadPoolMonitor(manager: ThreadPoolManager&)      │
│  + startMonitoring(intervalMs: size_t): void             │
│  + stopMonitoring(): void                                │
│  + getStats(): ThreadPoolStats                          │
│  - monitoringThread_: thread                             │
│  - stop_: atomic<bool>                                   │
│  - manager_: ThreadPoolManager&                          │
└─────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────┐
│              ThreadPoolStats                             │
│  + totalThreads: size_t                                 │
│  + runningThreads: size_t                               │
│  + idleThreads: size_t                                  │
│  + queuedTasks: size_t                                  │
│  + totalTasks: size_t                                   │
│  + completedTasks: size_t                               │
│  + avgTaskTimeMs: double                                 │
└─────────────────────────────────────────────────────────┘
```

### 2.2 类职责

#### 2.2.1 ThreadPoolManager

**职责**: 线程池管理器，封装BS::thread_pool，提供简化的接口

**职责说明**:
- 封装BS::thread_pool，提供简化的任务提交接口
- 支持任务提交和异步结果获取
- 支持等待所有任务完成
- 支持线程池的暂停和恢复
- 提供线程池状态查询
- 提供优雅关闭机制

#### 2.2.2 ThreadPoolMonitor

**职责**: 线程池监控器，监控线程池的运行状态

**职责说明**:
- 定期收集线程池统计信息
- 提供线程池性能监控
- 支持监控间隔配置
- 提供统计信息查询

#### 2.2.3 ThreadPoolStats

**职责**: 线程池统计信息，记录线程池的运行数据

**职责说明**:
- 记录线程池状态
- 记录任务执行统计
- 计算性能指标
- 提供统计信息查询

### 2.3 类接口

#### 2.3.1 ThreadPoolManager接口

```cpp
class ThreadPoolManager {
public:
    explicit ThreadPoolManager(size_t num_threads);
    ~ThreadPoolManager();
    
    void submitTask(std::function<void()> task);
    
    template<typename F, typename... Args>
    auto submitTaskWithResult(F&& f, Args&&... args) 
        -> std::future<decltype(f(args...))>;
    
    void waitForAll();
    
    void shutdown();
    
    size_t getThreadCount() const;
    size_t getTasksTotal() const;
    size_t getTasksRunning() const;
    size_t getTasksQueued() const;
    
    void pause();
    void resume();
    bool isPaused() const;
    
private:
    BS::thread_pool pool_;
    bool paused_;
};
```

#### 2.3.2 ThreadPoolMonitor接口

```cpp
struct ThreadPoolStats {
    size_t total_threads;
    size_t running_threads;
    size_t idle_threads;
    size_t queued_tasks;
    size_t total_tasks;
    size_t completed_tasks;
    double avg_task_time_ms;
};

class ThreadPoolMonitor {
public:
    explicit ThreadPoolMonitor(ThreadPoolManager& manager);
    
    void startMonitoring(size_t interval_ms);
    void stopMonitoring();
    
    ThreadPoolStats getStats() const;
    
private:
    void monitoringLoop();
    
    std::thread monitoring_thread_;
    std::atomic<bool> stop_;
    ThreadPoolManager& manager_;
    
    mutable std::mutex stats_mutex_;
    ThreadPoolStats stats_;
};
```

### 2.4 类关系

- **ThreadPoolManager**: 封装BS::thread_pool，提供简化的任务提交接口
- **ThreadPoolMonitor**: 监控ThreadPoolManager的运行状态
- **ThreadPoolStats**: 被ThreadPoolMonitor使用的统计信息结构

## 3. 数据结构

### 3.1 ThreadPoolStats

```cpp
struct ThreadPoolStats {
    size_t total_threads;          // 总线程数
    size_t running_threads;         // 运行中的线程数
    size_t idle_threads;           // 空闲线程数
    size_t queued_tasks;           // 队列中的任务数
    size_t total_tasks;            // 总任务数
    size_t completed_tasks;        // 已完成任务数
    double avg_task_time_ms;       // 平均任务执行时间（毫秒）
};
```

**说明**: 线程池统计信息结构，用于记录和查询线程池的运行状态

## 4. 接口设计

### 4.1 公共接口

#### 4.1.1 ThreadPoolManager公共接口

```cpp
// 构造函数
explicit ThreadPoolManager(size_t num_threads);

// 析构函数
~ThreadPoolManager();

// 提交任务（无返回值）
void submitTask(std::function<void()> task);

// 提交任务（有返回值）
template<typename F, typename... Args>
auto submitTaskWithResult(F&& f, Args&&... args) 
    -> std::future<decltype(f(args...))>;

// 等待所有任务完成
void waitForAll();

// 关闭线程池
void shutdown();

// 获取线程数
size_t getThreadCount() const;

// 获取总任务数
size_t getTasksTotal() const;

// 获取运行中的任务数
size_t getTasksRunning() const;

// 获取队列中的任务数
size_t getTasksQueued() const;

// 暂停线程池
void pause();

// 恢复线程池
void resume();

// 判断是否暂停
bool isPaused() const;
```

#### 4.1.2 ThreadPoolMonitor公共接口

```cpp
// 构造函数
explicit ThreadPoolMonitor(ThreadPoolManager& manager);

// 开始监控
void startMonitoring(size_t interval_ms);

// 停止监控
void stopMonitoring();

// 获取统计信息
ThreadPoolStats getStats() const;
```

### 4.2 私有接口

#### 4.2.1 ThreadPoolMonitor私有接口

```cpp
// 监控循环
void monitoringLoop();
```

### 4.3 接口说明

#### 4.3.1 ThreadPoolManager接口说明

- **ThreadPoolManager()**: 构造函数，创建指定数量的工作线程
- **~ThreadPoolManager()**: 析构函数，自动调用shutdown()
- **submitTask()**: 提交无返回值的任务到线程池
- **submitTaskWithResult()**: 提交有返回值的任务到线程池，返回future对象
- **waitForAll()**: 等待所有任务完成
- **shutdown()**: 关闭线程池，等待所有任务完成
- **getThreadCount()**: 获取线程池的总线程数
- **getTasksTotal()**: 获取总任务数（包括已完成、运行中和队列中的任务）
- **getTasksRunning()**: 获取当前运行中的任务数
- **getTasksQueued()**: 获取当前队列中的任务数
- **pause()**: 暂停线程池，不再执行新任务
- **resume()**: 恢复线程池，继续执行任务
- **isPaused()**: 判断线程池是否处于暂停状态

#### 4.3.2 ThreadPoolMonitor接口说明

- **ThreadPoolMonitor()**: 构造函数，绑定到指定的线程池管理器
- **startMonitoring()**: 开始监控，interval_ms为监控间隔
- **stopMonitoring()**: 停止监控
- **getStats()**: 获取最新的统计信息

## 5. 算法设计

### 5.1 任务调度算法

#### 5.1.1 算法描述

ThreadPoolManager使用BS::thread_pool提供的任务调度功能，BS::thread_pool内部使用高效的任务队列和工作窃取算法来实现任务调度。

#### 5.1.2 算法流程

```
1. 用户通过ThreadPoolManager提交任务
2. ThreadPoolManager将任务转发给BS::thread_pool
3. BS::thread_pool将任务加入内部任务队列
4. 工作线程从任务队列中获取任务
5. 如果队列为空，线程进入等待状态
6. 如果有新任务到来，唤醒一个工作线程
7. 工作线程执行任务
8. 任务完成后，更新统计信息
9. 工作线程继续获取下一个任务
```

#### 5.1.3 性能分析

- **时间复杂度**: O(1)，BS::thread_pool使用优化的任务队列
- **空间复杂度**: O(n)，n为队列中的任务数
- **优化**: BS::thread_pool使用工作窃取算法，减少线程竞争

### 5.2 线程池暂停和恢复算法

#### 5.2.1 算法描述

ThreadPoolManager支持暂停和恢复功能，通过BS::thread_pool提供的pause()和resume()方法实现。

#### 5.2.2 算法流程

```
1. 暂停：
   a. 调用BS::thread_pool的pause()方法
   b. 工作线程停止获取新任务
   c. 已开始的任务继续执行

2. 恢复：
   a. 调用BS::thread_pool的resume()方法
   b. 工作线程继续获取任务
   c. 恢复正常的任务执行
```

#### 5.2.3 性能分析

- **时间复杂度**: O(1)，常数时间操作
- **空间复杂度**: O(1)，不需要额外空间
- **优化**: 使用BS::thread_pool内置的暂停/恢复机制

### 5.3 监控统计算法

#### 5.3.1 算法描述

ThreadPoolMonitor定期收集线程池的统计信息，计算性能指标。

#### 5.3.2 算法流程

```
1. 定期从BS::thread_pool获取统计信息
2. 计算运行中的线程数和空闲线程数
3. 计算队列中的任务数
4. 计算总任务数
5. 计算已完成任务数
6. 计算平均任务执行时间
7. 更新统计信息
```

#### 5.3.3 性能分析

- **时间复杂度**: O(1)，BS::thread_pool提供高效的统计信息查询
- **空间复杂度**: O(1)，只存储统计信息
- **优化**: 使用BS::thread_pool内置的统计功能

## 6. 并发设计

### 6.1 线程安全

#### 6.1.1 ThreadPoolManager线程安全

- **使用BS::thread_pool**: BS::thread_pool内部实现了线程安全机制
- **线程安全**: 所有公共接口都是线程安全的
- **无锁设计**: BS::thread_pool使用无锁队列和原子操作，避免锁竞争

#### 6.1.2 ThreadPoolMonitor线程安全

- **使用互斥锁**: stats_使用std::mutex保护
- **使用原子变量**: stop_使用std::atomic
- **线程安全**: 所有公共接口都是线程安全的

### 6.2 同步机制

#### 6.2.1 BS::thread_pool内部同步

BS::thread_pool内部使用高效的同步机制：

```cpp
// BS::thread_pool内部实现（简化版）
class thread_pool {
    // 使用无锁队列和原子操作
    std::atomic<bool> paused;
    std::atomic<size_t> tasks_total;
    std::atomic<size_t> tasks_running;
    // ...
};
```

#### 6.2.2 ThreadPoolMonitor同步

ThreadPoolMonitor使用互斥锁保护统计信息：

```cpp
mutable std::mutex stats_mutex_;

ThreadPoolStats getStats() const {
    std::lock_guard<std::mutex> lock(stats_mutex_);
    return stats_;
}
```

### 6.3 并发策略

#### 6.3.1 ThreadPoolManager并发策略

- **生产者-消费者模式**: 主线程提交任务，工作线程执行任务
- **任务队列**: BS::thread_pool内部使用高效的任务队列
- **工作窃取**: BS::thread_pool使用工作窃取算法，减少线程竞争
- **无锁设计**: BS::thread_pool使用原子操作和无锁队列，提高性能

#### 6.3.2 ThreadPoolMonitor并发策略

- **细粒度锁**: 只在访问共享数据时加锁
- **原子操作**: 使用原子变量控制监控线程
- **定期更新**: 定期收集和更新统计信息

## 7. 内存管理

### 7.1 内存分配

#### 7.1.1 BS::thread_pool内存分配

BS::thread_pool内部使用高效的内存管理策略：
- 使用标准库的内存分配器
- 预分配任务队列空间
- 使用智能指针管理任务对象

#### 7.1.2 ThreadPoolManager内存分配

```cpp
// BS::thread_pool自动管理线程内存
BS::thread_pool pool_;

// 使用RAII管理资源
~ThreadPoolManager() {
    shutdown();
}
```

### 7.2 内存释放

#### 7.2.1 BS::thread_pool内存释放

BS::thread_pool自动管理内存释放：
- 析构时自动释放所有资源
- 智能指针自动管理任务对象
- 线程自动join

#### 7.2.2 ThreadPoolManager内存释放

```cpp
// 析构函数自动释放资源
~ThreadPoolManager() {
    shutdown();
}
```

### 7.3 内存优化

#### 7.3.1 BS::thread_pool内存优化

BS::thread_pool内部实现了多种内存优化：
- 预分配任务队列空间
- 使用无锁队列减少内存开销
- 使用工作窃取算法减少内存复制

#### 7.3.2 ThreadPoolManager内存优化

```cpp
// 复用BS::thread_pool的内存优化
// 无需额外的内存管理
```

## 8. 错误处理

### 8.1 错误类型

#### 8.1.1 BS::thread_pool错误处理

BS::thread_pool内部处理以下错误：
- 线程创建失败：抛出std::runtime_error
- 内存分配失败：抛出std::bad_alloc
- 任务执行异常：捕获并记录异常

#### 8.1.2 ThreadPoolManager错误处理

ThreadPoolManager处理以下错误：
- 任务提交失败：记录错误日志
- 线程池状态异常：抛出异常
- 监控异常：记录错误日志

### 8.2 错误处理策略

#### 8.2.1 BS::thread_pool异常处理

BS::thread_pool内部实现了完善的异常处理机制：
- 捕获任务执行异常
- 记录异常信息
- 继续执行其他任务

#### 8.2.2 ThreadPoolManager异常处理

ThreadPoolManager使用异常处理机制：

```cpp
void submitTask(std::function<void()> task) {
    try {
        if (paused_) {
            throw std::runtime_error("Thread pool is paused");
        }
        pool_.push_task(task);
    } catch (const std::exception& e) {
        spdlog::error("Failed to submit task: {}", e.what());
        throw;
    }
}
```

### 8.3 异常处理

#### 8.3.1 自定义异常

```cpp
class ThreadPoolException : public std::exception {
public:
    explicit ThreadPoolException(const std::string& message)
        : message_(message) {}
    
    const char* what() const noexcept override {
        return message_.c_str();
    }
    
private:
    std::string message_;
};
```

#### 8.3.2 异常安全

使用RAII确保异常安全：

```cpp
class ThreadPoolManager {
public:
    explicit ThreadPoolManager(size_t num_threads) 
        : pool_(num_threads), paused_(false) {}
    
    ~ThreadPoolManager() {
        shutdown();
    }
};
```

## 9. 性能优化

### 9.1 优化策略

#### 9.1.1 使用原子操作

- **无锁设计**: 避免锁竞争
- **高性能**: 原子操作比互斥锁更快
- **可扩展**: 支持多核扩展

#### 9.1.2 使用条件变量

- **高效同步**: 避免忙等待
- **低延迟**: 快速唤醒工作线程
- **低开销**: 减少CPU使用率

#### 9.1.3 使用优先队列

- **高效调度**: 优先执行高优先级任务
- **低延迟**: 减少任务等待时间
- **高性能**: O(log n)的插入和删除

### 9.2 线程优化

#### 9.2.1 线程亲和性

设置线程亲和性，减少上下文切换：

```cpp
#include <pthread.h>

void setThreadAffinity(pthread_t thread, int core_id) {
    cpu_set_t cpuset;
    CPU_ZERO(&cpuset);
    CPU_SET(core_id, &cpuset);
    pthread_setaffinity_np(thread, sizeof(cpu_set_t), &cpuset);
}
```

#### 9.2.2 线程优先级

设置线程优先级，提高关键任务的响应速度：

```cpp
#include <pthread.h>

void setThreadPriority(pthread_t thread, int priority) {
    sched_param param;
    param.sched_priority = priority;
    pthread_setschedparam(thread, SCHED_RR, &param);
}
```

### 9.3 任务优化

#### 9.3.1 任务批处理

批处理小任务，减少任务调度开销：

```cpp
void processBatch(const std::vector<std::function<void()>>& tasks) {
    for (const auto& task : tasks) {
        task();
    }
}
```

#### 9.3.2 任务窃取

实现任务窃取算法，提高负载均衡：

```cpp
std::function<void()> stealTask() {
    std::lock_guard<std::mutex> lock(queue_mutex_);
    if (!tasks_.empty()) {
        auto task = std::move(tasks_.front());
        tasks_.pop();
        return task;
    }
    return nullptr;
}
```

## 10. 测试设计

### 10.1 单元测试

#### 10.1.1 ThreadPool测试

```cpp
TEST(ThreadPoolTest, SubmitTask) {
    ThreadPool pool(4);
    
    auto future = pool.submit([]() {
        return 42;
    });
    
    EXPECT_EQ(future.get(), 42);
}

TEST(ThreadPoolTest, MultipleTasks) {
    ThreadPool pool(4);
    
    std::vector<std::future<int>> futures;
    for (int i = 0; i < 10; ++i) {
        futures.push_back(pool.submit([i]() {
            return i * 2;
        }));
    }
    
    for (int i = 0; i < 10; ++i) {
        EXPECT_EQ(futures[i].get(), i * 2);
    }
}

TEST(ThreadPoolTest, Shutdown) {
    ThreadPool pool(4);
    
    auto future = pool.submit([]() {
        std::this_thread::sleep_for(std::chrono::milliseconds(100));
        return 42;
    });
    
    pool.shutdown();
    
    EXPECT_EQ(future.get(), 42);
}

TEST(ThreadPoolTest, GetStats) {
    ThreadPool pool(4);
    
    EXPECT_EQ(pool.getTotalThreads(), 4);
    EXPECT_EQ(pool.getActiveThreads(), 0);
    EXPECT_EQ(pool.getQueueSize(), 0);
    
    pool.submit([]() {
        std::this_thread::sleep_for(std::chrono::milliseconds(100));
    });
    
    EXPECT_GT(pool.getQueueSize(), 0);
}
```

#### 10.1.2 TaskQueue测试

```cpp
TEST(TaskQueueTest, PushAndPop) {
    TaskQueue queue;
    
    auto task = std::make_shared<ConcreteTask>([]() {}, 0);
    EXPECT_TRUE(queue.push(task));
    
    auto popped = queue.pop();
    EXPECT_NE(popped, nullptr);
}

TEST(TaskQueueTest, PriorityOrder) {
    TaskQueue queue;
    
    auto task1 = std::make_shared<ConcreteTask>([]() {}, 1);
    auto task2 = std::make_shared<ConcreteTask>([]() {}, 2);
    auto task3 = std::make_shared<ConcreteTask>([]() {}, 3);
    
    queue.push(task1);
    queue.push(task2);
    queue.push(task3);
    
    EXPECT_EQ(queue.pop()->getPriority(), 3);
    EXPECT_EQ(queue.pop()->getPriority(), 2);
    EXPECT_EQ(queue.pop()->getPriority(), 1);
}

TEST(TaskQueueTest, TryPop) {
    TaskQueue queue;
    
    auto task = std::make_shared<ConcreteTask>([]() {}, 0);
    queue.push(task);
    
    auto popped = queue.tryPop();
    EXPECT_NE(popped, nullptr);
    
    popped = queue.tryPop();
    EXPECT_EQ(popped, nullptr);
}
```

### 10.2 集成测试

#### 10.2.1 ThreadPool集成测试

```cpp
TEST(ThreadPoolIntegration, ConcurrentTasks) {
    ThreadPool pool(4);
    
    std::atomic<int> counter(0);
    std::vector<std::future<void>> futures;
    
    for (int i = 0; i < 100; ++i) {
        futures.push_back(pool.submit([&counter]() {
            counter++;
        }));
    }
    
    for (auto& future : futures) {
        future.get();
    }
    
    EXPECT_EQ(counter.load(), 100);
}

TEST(ThreadPoolIntegration, TaskPriority) {
    ThreadPool pool(4);
    
    std::vector<int> results;
    std::mutex mutex;
    
    for (int i = 0; i < 10; ++i) {
        pool.submit([&results, &mutex, i]() {
            std::lock_guard<std::mutex> lock(mutex);
            results.push_back(i);
        }, i);
    }
    
    std::this_thread::sleep_for(std::chrono::milliseconds(100));
    
    EXPECT_EQ(results.size(), 10);
}
```

### 10.3 性能测试

#### 10.3.1 ThreadPool性能测试

```cpp
TEST(ThreadPoolPerformance, TaskThroughput) {
    ThreadPool pool(4);
    
    auto start = std::chrono::high_resolution_clock::now();
    
    std::vector<std::future<void>> futures;
    for (int i = 0; i < 10000; ++i) {
        futures.push_back(pool.submit([]() {}));
    }
    
    for (auto& future : futures) {
        future.get();
    }
    
    auto end = std::chrono::high_resolution_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);
    
    spdlog::info("ThreadPool throughput: {} tasks/ms", 10000.0 / duration.count());
}
```

#### 10.3.2 TaskQueue性能测试

```cpp
TEST(TaskQueuePerformance, PushAndPop) {
    TaskQueue queue;
    
    auto start = std::chrono::high_resolution_clock::now();
    
    for (int i = 0; i < 10000; ++i) {
        auto task = std::make_shared<ConcreteTask>([]() {}, i);
        queue.push(task);
    }
    
    for (int i = 0; i < 10000; ++i) {
        queue.pop();
    }
    
    auto end = std::chrono::high_resolution_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);
    
    spdlog::info("TaskQueue performance: {} operations/ms", 20000.0 / duration.count());
}
```

## 11. 代码示例

### 11.1 头文件示例

#### 11.1.1 thread_pool.h

```cpp
/**
 * @file thread_pool.h
 * @brief 线程池实现
 * @author cLLM Team
 * @date 2024-01-01
 */

#pragma once

#include <atomic>
#include <condition_variable>
#include <functional>
#include <future>
#include <memory>
#include <mutex>
#include <queue>
#include <thread>
#include <vector>
#include <type_traits>

namespace cllm {

/**
 * @brief 线程池类
 */
class ThreadPool {
public:
    /**
     * @brief 构造函数
     * @param num_threads 线程数
     */
    explicit ThreadPool(size_t num_threads);
    
    /**
     * @brief 析构函数
     */
    ~ThreadPool();
    
    /**
     * @brief 提交任务
     * @param f 任务函数
     * @param args 任务参数
     * @return future对象
     */
    template<typename F, typename... Args>
    auto submit(F&& f, Args&&... args) 
        -> std::future<typename std::result_of<F(Args...)>::type>;
    
    /**
     * @brief 优雅关闭
     */
    void shutdown();
    
    /**
     * @brief 立即关闭
     */
    void shutdownNow();
    
    /**
     * @brief 获取队列大小
     * @return 队列大小
     */
    size_t getQueueSize() const;
    
    /**
     * @brief 获取活跃线程数
     * @return 活跃线程数
     */
    size_t getActiveThreads() const;
    
    /**
     * @brief 获取总线程数
     * @return 总线程数
     */
    size_t getTotalThreads() const;
    
    /**
     * @brief 获取已完成任务数
     * @return 已完成任务数
     */
    size_t getCompletedTasks() const;
    
    /**
     * @brief 设置线程数
     * @param num_threads 线程数
     */
    void setThreadCount(size_t num_threads);
    
private:
    /**
     * @brief 工作线程函数
     */
    void workerThread();
    
    std::vector<std::thread> workers_;
    std::queue<std::function<void()>> tasks_;
    
    mutable std::mutex queue_mutex_;
    std::condition_variable condition_;
    std::atomic<bool> stop_;
    std::atomic<size_t> active_threads_;
    std::atomic<size_t> completed_tasks_;
};

}  // namespace cllm
```

#### 11.1.2 task_queue.h

```cpp
/**
 * @file task_queue.h
 * @brief 任务队列实现
 * @author cLLM Team
 * @date 2024-01-01
 */

#pragma once

#include <condition_variable>
#include <memory>
#include <mutex>
#include <queue>
#include <vector>

namespace cllm {

/**
 * @brief 任务基类
 */
class Task {
public:
    virtual ~Task() = default;
    virtual void execute() = 0;
    virtual int getPriority() const = 0;
};

/**
 * @brief 具体任务实现类
 */
template<typename F, typename... Args>
class ConcreteTask : public Task {
public:
    ConcreteTask(F&& f, Args&&... args, int priority = 0)
        : func_(std::bind(std::forward<F>(f), std::forward<Args>(args)...)),
          priority_(priority) {}
    
    void execute() override {
        func_();
    }
    
    int getPriority() const override {
        return priority_;
    }
    
private:
    std::function<void()> func_;
    int priority_;
};

/**
 * @brief 任务队列类
 */
class TaskQueue {
public:
    /**
     * @brief 构造函数
     * @param max_size 最大队列大小，0表示无限制
     */
    explicit TaskQueue(size_t max_size = 0);
    
    /**
     * @brief 推入任务
     * @param task 任务
     * @return 是否成功
     */
    bool push(std::shared_ptr<Task> task);
    
    /**
     * @brief 弹出任务（阻塞）
     * @return 任务
     */
    std::shared_ptr<Task> pop();
    
    /**
     * @brief 弹出任务（非阻塞）
     * @return 任务
     */
    std::shared_ptr<Task> tryPop();
    
    /**
     * @brief 获取队列大小
     * @return 队列大小
     */
    size_t size() const;
    
    /**
     * @brief 判断队列是否为空
     * @return 是否为空
     */
    bool empty() const;
    
    /**
     * @brief 判断队列是否已满
     * @return 是否已满
     */
    bool full() const;
    
    /**
     * @brief 清空队列
     */
    void clear();
    
private:
    /**
     * @brief 任务比较器
     */
    struct TaskComparator {
        bool operator()(const std::shared_ptr<Task>& a,
                       const std::shared_ptr<Task>& b) const;
    };
    
    std::priority_queue<std::shared_ptr<Task>,
                       std::vector<std::shared_ptr<Task>>,
                       TaskComparator> queue_;
    size_t max_size_;
    
    mutable std::mutex mutex_;
    std::condition_variable condition_;
};

}  // namespace cllm
```

#### 11.1.3 thread_pool_monitor.h

```cpp
/**
 * @file thread_pool_monitor.h
 * @brief 线程池监控器实现
 * @author cLLM Team
 * @date 2024-01-01
 */

#pragma once

#include <atomic>
#include <chrono>
#include <mutex>
#include <thread>

namespace cllm {

/**
 * @brief 线程池统计信息
 */
struct ThreadPoolStats {
    size_t total_threads;          // 总线程数
    size_t active_threads;         // 活跃线程数
    size_t idle_threads;           // 空闲线程数
    size_t queue_size;             // 队列大小
    size_t completed_tasks;        // 已完成任务数
    size_t total_tasks;            // 总任务数
    double avg_task_time_ms;       // 平均任务执行时间（毫秒）
};

class ThreadPool;

/**
 * @brief 线程池监控器类
 */
class ThreadPoolMonitor {
public:
    /**
     * @brief 构造函数
     * @param thread_pool 线程池
     */
    explicit ThreadPoolMonitor(ThreadPool& thread_pool);
    
    /**
     * @brief 析构函数
     */
    ~ThreadPoolMonitor();
    
    /**
     * @brief 开始监控
     * @param interval_ms 监控间隔（毫秒）
     */
    void startMonitoring(size_t interval_ms);
    
    /**
     * @brief 停止监控
     */
    void stopMonitoring();
    
    /**
     * @brief 获取统计信息
     * @return 统计信息
     */
    ThreadPoolStats getStats() const;
    
private:
    /**
     * @brief 监控循环
     */
    void monitoringLoop();
    
    std::thread monitoring_thread_;
    std::atomic<bool> stop_;
    ThreadPool& thread_pool_;
    
    mutable std::mutex stats_mutex_;
    ThreadPoolStats stats_;
};

}  // namespace cllm
```

### 11.2 实现文件示例

#### 11.2.1 thread_pool.cpp

```cpp
/**
 * @file thread_pool.cpp
 * @brief 线程池实现
 */

#include "thread_pool.h"
#include <spdlog/spdlog.h>

namespace cllm {

ThreadPool::ThreadPool(size_t num_threads)
    : stop_(false), active_threads_(0), completed_tasks_(0) {
    
    for (size_t i = 0; i < num_threads; ++i) {
        workers_.emplace_back([this] { workerThread(); });
    }
    
    spdlog::info("ThreadPool created with {} threads", num_threads);
}

ThreadPool::~ThreadPool() {
    shutdown();
}

template<typename F, typename... Args>
auto ThreadPool::submit(F&& f, Args&&... args) 
    -> std::future<typename std::result_of<F(Args...)>::type> {
    
    using ReturnType = typename std::result_of<F(Args...)>::type;
    
    auto task = std::make_shared<std::packaged_task<ReturnType()>>(
        std::bind(std::forward<F>(f), std::forward<Args>(args)...)
    );
    
    std::future<ReturnType> result = task->get_future();
    
    {
        std::lock_guard<std::mutex> lock(queue_mutex_);
        
        if (stop_) {
            throw std::runtime_error("submit on stopped ThreadPool");
        }
        
        tasks_.emplace([task]() { (*task)(); });
    }
    
    condition_.notify_one();
    
    return result;
}

void ThreadPool::shutdown() {
    {
        std::lock_guard<std::mutex> lock(queue_mutex_);
        stop_ = true;
    }
    
    condition_.notify_all();
    
    for (std::thread& worker : workers_) {
        if (worker.joinable()) {
            worker.join();
        }
    }
    
    workers_.clear();
    
    spdlog::info("ThreadPool shutdown completed");
}

void ThreadPool::shutdownNow() {
    {
        std::lock_guard<std::mutex> lock(queue_mutex_);
        stop_ = true;
        
        while (!tasks_.empty()) {
            tasks_.pop();
        }
    }
    
    condition_.notify_all();
    
    for (std::thread& worker : workers_) {
        if (worker.joinable()) {
            worker.join();
        }
    }
    
    workers_.clear();
    
    spdlog::info("ThreadPool shutdown now completed");
}

size_t ThreadPool::getQueueSize() const {
    std::lock_guard<std::mutex> lock(queue_mutex_);
    return tasks_.size();
}

size_t ThreadPool::getActiveThreads() const {
    return active_threads_.load();
}

size_t ThreadPool::getTotalThreads() const {
    return workers_.size();
}

size_t ThreadPool::getCompletedTasks() const {
    return completed_tasks_.load();
}

void ThreadPool::setThreadCount(size_t num_threads) {
    size_t current_size = workers_.size();
    
    if (num_threads > current_size) {
        for (size_t i = current_size; i < num_threads; ++i) {
            workers_.emplace_back([this] { workerThread(); });
        }
    } else if (num_threads < current_size) {
        for (size_t i = num_threads; i < current_size; ++i) {
            workers_[i].detach();
        }
        workers_.resize(num_threads);
    }
    
    spdlog::info("ThreadPool size adjusted to {}", num_threads);
}

void ThreadPool::workerThread() {
    while (true) {
        std::function<void()> task;
        
        {
            std::unique_lock<std::mutex> lock(queue_mutex_);
            condition_.wait(lock, [this] {
                return stop_ || !tasks_.empty();
            });
            
            if (stop_ && tasks_.empty()) {
                return;
            }
            
            task = std::move(tasks_.front());
            tasks_.pop();
        }
        
        active_threads_++;
        
        try {
            task();
            completed_tasks_++;
        } catch (const std::exception& e) {
            spdlog::error("Task execution failed: {}", e.what());
        }
        
        active_threads_--;
    }
}

}  // namespace cllm
```

#### 11.2.2 task_queue.cpp

```cpp
/**
 * @file task_queue.cpp
 * @brief 任务队列实现
 */

#include "task_queue.h"
#include <spdlog/spdlog.h>

namespace cllm {

TaskQueue::TaskQueue(size_t max_size)
    : max_size_(max_size) {
    spdlog::info("TaskQueue created with max_size={}", max_size);
}

bool TaskQueue::push(std::shared_ptr<Task> task) {
    std::unique_lock<std::mutex> lock(mutex_);
    
    if (max_size_ > 0 && queue_.size() >= max_size_) {
        return false;
    }
    
    queue_.push(task);
    condition_.notify_one();
    
    return true;
}

std::shared_ptr<Task> TaskQueue::pop() {
    std::unique_lock<std::mutex> lock(mutex_);
    
    condition_.wait(lock, [this] {
        return !queue_.empty();
    });
    
    auto task = queue_.top();
    queue_.pop();
    
    return task;
}

std::shared_ptr<Task> TaskQueue::tryPop() {
    std::lock_guard<std::mutex> lock(mutex_);
    
    if (queue_.empty()) {
        return nullptr;
    }
    
    auto task = queue_.top();
    queue_.pop();
    
    return task;
}

size_t TaskQueue::size() const {
    std::lock_guard<std::mutex> lock(mutex_);
    return queue_.size();
}

bool TaskQueue::empty() const {
    std::lock_guard<std::mutex> lock(mutex_);
    return queue_.empty();
}

bool TaskQueue::full() const {
    std::lock_guard<std::mutex> lock(mutex_);
    return max_size_ > 0 && queue_.size() >= max_size_;
}

void TaskQueue::clear() {
    std::lock_guard<std::mutex> lock(mutex_);
    
    while (!queue_.empty()) {
        queue_.pop();
    }
}

bool TaskQueue::TaskComparator::operator()(
    const std::shared_ptr<Task>& a,
    const std::shared_ptr<Task>& b) const {
    return a->getPriority() < b->getPriority();
}

}  // namespace cllm
```

#### 11.2.3 thread_pool_monitor.cpp

```cpp
/**
 * @file thread_pool_monitor.cpp
 * @brief 线程池监控器实现
 */

#include "thread_pool_monitor.h"
#include "thread_pool.h"
#include <spdlog/spdlog.h>

namespace cllm {

ThreadPoolMonitor::ThreadPoolMonitor(ThreadPool& thread_pool)
    : stop_(false), thread_pool_(thread_pool) {
    
    stats_.total_threads = 0;
    stats_.active_threads = 0;
    stats_.idle_threads = 0;
    stats_.queue_size = 0;
    stats_.completed_tasks = 0;
    stats_.total_tasks = 0;
    stats_.avg_task_time_ms = 0.0;
    
    spdlog::info("ThreadPoolMonitor created");
}

ThreadPoolMonitor::~ThreadPoolMonitor() {
    stopMonitoring();
}

void ThreadPoolMonitor::startMonitoring(size_t interval_ms) {
    stop_ = false;
    monitoring_thread_ = std::thread([this, interval_ms]() {
        monitoringLoop();
    });
    
    spdlog::info("ThreadPoolMonitor started with interval={}ms", interval_ms);
}

void ThreadPoolMonitor::stopMonitoring() {
    stop_ = true;
    
    if (monitoring_thread_.joinable()) {
        monitoring_thread_.join();
    }
    
    spdlog::info("ThreadPoolMonitor stopped");
}

ThreadPoolStats ThreadPoolMonitor::getStats() const {
    std::lock_guard<std::mutex> lock(stats_mutex_);
    return stats_;
}

void ThreadPoolMonitor::monitoringLoop() {
    while (!stop_) {
        std::lock_guard<std::mutex> lock(stats_mutex_);
        
        stats_.total_threads = thread_pool_.getTotalThreads();
        stats_.active_threads = thread_pool_.getActiveThreads();
        stats_.idle_threads = stats_.total_threads - stats_.active_threads;
        stats_.queue_size = thread_pool_.getQueueSize();
        stats_.completed_tasks = thread_pool_.getCompletedTasks();
        
        std::this_thread::sleep_for(std::chrono::milliseconds(100));
    }
}

}  // namespace cllm
```

### 11.3 使用示例

#### 11.3.1 ThreadPool使用示例

```cpp
#include "thread_pool.h"

int main() {
    // 创建线程池，4个工作线程
    cllm::ThreadPool pool(4);
    
    // 提交任务
    auto future1 = pool.submit([]() {
        std::this_thread::sleep_for(std::chrono::milliseconds(100));
        return 42;
    });
    
    auto future2 = pool.submit([]() {
        std::this_thread::sleep_for(std::chrono::milliseconds(50));
        return 24;
    });
    
    // 获取结果
    int result1 = future1.get();
    int result2 = future2.get();
    
    spdlog::info("Result1: {}, Result2: {}", result1, result2);
    
    // 获取统计信息
    spdlog::info("Total threads: {}", pool.getTotalThreads());
    spdlog::info("Active threads: {}", pool.getActiveThreads());
    spdlog::info("Queue size: {}", pool.getQueueSize());
    spdlog::info("Completed tasks: {}", pool.getCompletedTasks());
    
    // 关闭线程池
    pool.shutdown();
    
    return 0;
}
```

#### 11.3.2 TaskQueue使用示例

```cpp
#include "task_queue.h"

int main() {
    // 创建任务队列
    cllm::TaskQueue queue(100);
    
    // 推入任务
    auto task1 = std::make_shared<cllm::ConcreteTask>([]() {
        spdlog::info("Task 1 executed");
    }, 1);
    
    auto task2 = std::make_shared<cllm::ConcreteTask>([]() {
        spdlog::info("Task 2 executed");
    }, 2);
    
    queue.push(task1);
    queue.push(task2);
    
    // 弹出任务
    auto popped = queue.pop();
    popped->execute();
    
    // 获取队列大小
    spdlog::info("Queue size: {}", queue.size());
    
    return 0;
}
```

#### 11.3.3 ThreadPoolMonitor使用示例

```cpp
#include "thread_pool.h"
#include "thread_pool_monitor.h"

int main() {
    // 创建线程池
    cllm::ThreadPool pool(4);
    
    // 创建监控器
    cllm::ThreadPoolMonitor monitor(pool);
    
    // 开始监控
    monitor.startMonitoring(100);
    
    // 提交任务
    for (int i = 0; i < 10; ++i) {
        pool.submit([i]() {
            std::this_thread::sleep_for(std::chrono::milliseconds(100));
            spdlog::info("Task {} executed", i);
        });
    }
    
    // 等待任务完成
    std::this_thread::sleep_for(std::chrono::seconds(2));
    
    // 获取统计信息
    auto stats = monitor.getStats();
    spdlog::info("Total threads: {}", stats.total_threads);
    spdlog::info("Active threads: {}", stats.active_threads);
    spdlog::info("Idle threads: {}", stats.idle_threads);
    spdlog::info("Queue size: {}", stats.queue_size);
    spdlog::info("Completed tasks: {}", stats.completed_tasks);
    
    // 停止监控
    monitor.stopMonitoring();
    
    // 关闭线程池
    pool.shutdown();
    
    return 0;
}
```

## 12. 依赖关系

### 12.1 模块依赖

- **ThreadPool**: 无依赖
- **Task**: 无依赖
- **TaskQueue**: 依赖Task
- **ThreadPoolMonitor**: 依赖ThreadPool
- **ThreadPoolStats**: 无依赖

### 12.2 库依赖

- **spdlog**: 日志库
- **标准库**: C++标准库

### 12.3 接口依赖

- **ThreadPool**: 无接口依赖
- **Task**: 无接口依赖
- **TaskQueue**: 无接口依赖
- **ThreadPoolMonitor**: 依赖ThreadPool接口
- **ThreadPoolStats**: 无接口依赖

## 13. 设计检查清单

- [x] 模块职责清晰
- [x] 类设计合理
- [x] 接口设计完整
- [x] 算法设计正确
- [x] 并发设计安全
- [x] 内存管理完善
- [x] 错误处理完善
- [x] 性能优化充分
- [x] 测试设计完整
- [x] 代码示例正确
- [x] 依赖关系清晰
- [x] 符合编程规范

## 14. 总结

ThreadPool模块是cLLM系统的核心并发模块，负责线程池的管理和任务调度。本设计文档详细描述了ThreadPool、Task、TaskQueue、ThreadPoolMonitor和ThreadPoolStats的设计和实现。

主要特点：
- 使用优先队列实现任务优先级调度
- 使用条件变量实现高效的线程同步
- 使用原子操作减少锁竞争
- 支持动态调整线程池大小
- 提供完善的监控和统计功能
- 支持优雅关闭和立即关闭

本设计遵循了cLLM项目的编程规范，确保了代码的一致性和可维护性。
