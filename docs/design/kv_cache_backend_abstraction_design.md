# KV Cache åç«¯æŠ½è±¡è®¾è®¡æ–¹æ¡ˆ

**è®¾è®¡æ—¥æœŸ**: 2026-01-22  
**é—®é¢˜èƒŒæ™¯**: `cllm::KVCache` å¯¹äº llama.cpp åç«¯ä¸å¿…è¦ï¼Œéœ€è¦çµæ´»å¤„ç†

---

## ä¸€ã€é—®é¢˜åˆ†æ

### 1.1 å½“å‰æ¶æ„é—®é¢˜

```
Scheduler
    â”‚
    â”œâ”€ åˆ›å»º KVCache (cllm::KVCache)        â† å¯¹ llama.cpp åç«¯å†—ä½™
    â”‚
    â””â”€ åˆ›å»º BatchProcessor
           â”‚
           â””â”€ æ¥æ”¶ KVCache* cache å‚æ•°    â† ä»æœªå®é™…ä½¿ç”¨
```

### 1.2 åç«¯å·®å¼‚

| åç«¯ | KV Cache ç®¡ç†æ–¹å¼ | éœ€è¦ cllm::KVCache |
|------|------------------|-------------------|
| llama.cpp | llama.cpp å†…éƒ¨ç®¡ç† + inference::KVCacheManager ç»Ÿè®¡ | âŒ ä¸éœ€è¦ |
| Kylin | å¯èƒ½éœ€è¦å¤–éƒ¨ KV Cache | âœ… éœ€è¦ |
| LibTorch | å¯èƒ½éœ€è¦å¤–éƒ¨ KV Cache | âœ… éœ€è¦ |

---

## äºŒã€æ¨èæ–¹æ¡ˆï¼šæ··åˆæ–¹æ¡ˆï¼ˆæ¡ä»¶ç¼–è¯‘ + è¿è¡Œæ—¶é…ç½®ï¼‰

### 2.1 è®¾è®¡åŸåˆ™

1. **ç¼–è¯‘æœŸ**: ä½¿ç”¨ `#ifdef CLLM_USE_LLAMA_CPP` æ’é™¤ä¸éœ€è¦çš„ä»£ç 
2. **è¿è¡Œæ—¶**: ä½¿ç”¨ `backendType` é…ç½®æŒ‰éœ€åˆ›å»º KVCache
3. **å…¼å®¹æ€§**: ä¿ç•™å¯¹é llama.cpp åç«¯çš„æ”¯æŒ

### 2.2 æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         æ··åˆæ–¹æ¡ˆæ¶æ„                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Scheduler                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  init(backendType) {                                                â”‚   â”‚
â”‚  â”‚      #ifndef CLLM_LLAMA_CPP_ONLY  // ä¸æ˜¯çº¯ llama.cpp æ„å»º           â”‚   â”‚
â”‚  â”‚          if (backendType != "llama_cpp") {                          â”‚   â”‚
â”‚  â”‚              kvCache_ = new KVCache(...);  // æŒ‰éœ€åˆ›å»º               â”‚   â”‚
â”‚  â”‚          }                                                          â”‚   â”‚
â”‚  â”‚      #endif                                                         â”‚   â”‚
â”‚  â”‚  }                                                                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â”‚  BatchProcessor                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  // KVCache å‚æ•°å¯é€‰                                                 â”‚   â”‚
â”‚  â”‚  BatchProcessor(scheduler, executor, batchManager, kvCache = nullptr)â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  processIteration() {                                               â”‚   â”‚
â”‚  â”‚      if (cache_ != nullptr) {                                       â”‚   â”‚
â”‚  â”‚          // ä½¿ç”¨ KVCacheï¼ˆé llama.cpp åç«¯ï¼‰                         â”‚   â”‚
â”‚  â”‚      }                                                              â”‚   â”‚
â”‚  â”‚      // llama.cpp åç«¯: cache_ == nullptrï¼Œè·³è¿‡                      â”‚   â”‚
â”‚  â”‚  }                                                                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ä¸‰ã€å®ç°æ–¹æ¡ˆ

### 3.1 æ–¹æ¡ˆA: æœ€å°æ”¹åŠ¨ï¼ˆæ¨èï¼‰

ä¿æŒæ¥å£ä¸å˜ï¼Œè¿è¡Œæ—¶æŒ‰éœ€åˆ›å»º KVCacheã€‚

#### ä¿®æ”¹ 1: Scheduler æ„é€ å‡½æ•°

```cpp
// src/scheduler/scheduler.cpp

Scheduler::Scheduler(ModelExecutor* executor) 
    : modelExecutor_(executor)
    , ownsModelExecutor_(false)
{
    // ... å…¶ä»–åˆå§‹åŒ– ...
    
    // ğŸ”§ ä¿®æ”¹: æ ¹æ®åç«¯ç±»å‹å†³å®šæ˜¯å¦åˆ›å»º KVCache
    std::string backendType = modelExecutor_->getBackendType();
    
    if (needsExternalKVCache(backendType)) {
        kvCache_ = new KVCache(
            Config::instance().serverKvCacheMaxSize(),
            Config::instance().serverKvCacheMaxMemoryMb()
        );
        CLLM_INFO("[Scheduler] Created KVCache for backend: %s", backendType.c_str());
    } else {
        kvCache_ = nullptr;
        CLLM_INFO("[Scheduler] KVCache not needed for backend: %s (managed internally)", 
                  backendType.c_str());
    }
}

// è¾…åŠ©å‡½æ•°ï¼šåˆ¤æ–­æ˜¯å¦éœ€è¦å¤–éƒ¨ KVCache
bool Scheduler::needsExternalKVCache(const std::string& backendType) const {
    // llama.cpp åç«¯å†…éƒ¨ç®¡ç† KV Cacheï¼Œä¸éœ€è¦å¤–éƒ¨ KVCache
    if (backendType == "llama_cpp" || backendType == "llama.cpp" || backendType == "LlamaCpp") {
        return false;
    }
    // Kylin å’Œ LibTorch å¯èƒ½éœ€è¦å¤–éƒ¨ KVCache
    return true;
}
```

#### ä¿®æ”¹ 2: BatchProcessor å¤„ç† nullptr

```cpp
// src/scheduler/batch_processor.cpp

void SchedulerBatchProcessor::processIteration(...) {
    // ... ç°æœ‰é€»è¾‘ ...
    
    // ğŸ”§ ä¿®æ”¹: æ£€æŸ¥ KVCache æ˜¯å¦å¯ç”¨
    if (cache_ != nullptr) {
        // é llama.cpp åç«¯: ä½¿ç”¨å¤–éƒ¨ KVCache
        // ... KVCache ç›¸å…³æ“ä½œ ...
    }
    // llama.cpp åç«¯: cache_ == nullptrï¼ŒKV Cache ç”±å†…éƒ¨ç®¡ç†
}
```

#### ä¿®æ”¹ 3: ææ„å‡½æ•°å®‰å…¨åˆ é™¤

```cpp
// src/scheduler/scheduler.cpp

Scheduler::~Scheduler() {
    stop();
    
    // ğŸ”§ ä¿®æ”¹: å®‰å…¨åˆ é™¤
    if (kvCache_ != nullptr) {
        delete kvCache_;
        kvCache_ = nullptr;
    }
    
    // ...
}
```

### 3.2 æ–¹æ¡ˆB: æ¡ä»¶ç¼–è¯‘ï¼ˆæœ€å¤§æ€§èƒ½ï¼‰

ä»…åœ¨é llama.cpp æ„å»ºæ—¶åŒ…å« KVCache ä»£ç ã€‚

#### CMakeLists.txt æ·»åŠ é€‰é¡¹

```cmake
option(CLLM_LLAMA_CPP_ONLY "Build for llama.cpp backend only" OFF)

if(CLLM_LLAMA_CPP_ONLY)
    add_definitions(-DCLLM_LLAMA_CPP_ONLY)
endif()
```

#### å¤´æ–‡ä»¶æ¡ä»¶ç¼–è¯‘

```cpp
// include/cllm/scheduler/scheduler.h

class Scheduler {
private:
#ifndef CLLM_LLAMA_CPP_ONLY
    KVCache* kvCache_ = nullptr;  // ä»…é llama.cpp æ„å»ºåŒ…å«
#endif
};
```

---

## å››ã€æ–¹æ¡ˆå¯¹æ¯”

| ç»´åº¦ | æ–¹æ¡ˆA (è¿è¡Œæ—¶) | æ–¹æ¡ˆB (æ¡ä»¶ç¼–è¯‘) |
|------|---------------|-----------------|
| ä»£ç æ”¹åŠ¨é‡ | å° | ä¸­ |
| è¿è¡Œæ—¶å¼€é”€ | æä½ (nullptr æ£€æŸ¥) | é›¶ |
| çµæ´»æ€§ | é«˜ | ä½ |
| æ„å»ºå¤æ‚åº¦ | ä¸å˜ | å¢åŠ é€‰é¡¹ |
| æ¨èåœºæ™¯ | é€šç”¨åœºæ™¯ | çº¯ llama.cpp éƒ¨ç½² |

---

## äº”ã€æ¨èå®æ–½æ­¥éª¤

### ç¬¬ä¸€é˜¶æ®µ: æ–¹æ¡ˆAï¼ˆè¿è¡Œæ—¶é…ç½®ï¼‰

1. ä¿®æ”¹ `Scheduler` æŒ‰ `backendType` å†³å®šæ˜¯å¦åˆ›å»º `KVCache`
2. ä¿®æ”¹ `BatchProcessor` å®‰å…¨å¤„ç† `nullptr`
3. æµ‹è¯•éªŒè¯

### ç¬¬äºŒé˜¶æ®µ: å¯é€‰ - æ–¹æ¡ˆBï¼ˆæ¡ä»¶ç¼–è¯‘ï¼‰

å¦‚æœéœ€è¦æè‡´æ€§èƒ½ä¼˜åŒ–ï¼Œå¯ä»¥æ·»åŠ  `CLLM_LLAMA_CPP_ONLY` ç¼–è¯‘é€‰é¡¹ã€‚

---

## å…­ã€é…ç½®ç¤ºä¾‹

```yaml
# config/config.yaml

# åç«¯ç±»å‹: llama_cpp / kylin / libtorch
backend:
  type: llama_cpp  # ä½¿ç”¨ llama.cpp åç«¯ï¼Œä¸åˆ›å»ºå¤–éƒ¨ KVCache
  
  llama_cpp:
    n_batch: 512
    n_threads: 0
    n_gpu_layers: 0
    n_seq_max: 8
```

---

**è®¾è®¡å®Œæˆæ—¶é—´**: 2026-01-22
