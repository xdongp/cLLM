# HuggingFace Tokenizeré›†æˆå®æ–½çŠ¶æ€

> **æ›´æ–°æ—¶é—´**: 2026-01-11  
> **å½“å‰é˜¶æ®µ**: é˜¶æ®µ1å®Œæˆ âœ…

---

## âœ… å·²å®Œæˆå·¥ä½œ

### é˜¶æ®µ0: ç¯å¢ƒå‡†å¤‡ âœ…

- [x] æ›´æ–°CMakeLists.txtä»¥æ”¯æŒtokenizers-cpp
  - é»˜è®¤å¯ç”¨`USE_TOKENIZERS_CPP=ON`
  - è‡ªåŠ¨æ£€æµ‹tokenizers-cppå®‰è£…è·¯å¾„
  - æä¾›è¯¦ç»†çš„å®‰è£…æç¤ºä¿¡æ¯
  - æ·»åŠ `TOKENIZERS_LIBRARIES`åˆ°é“¾æ¥åº“

- [x] åˆ›å»ºå®‰è£…è„šæœ¬`scripts/install_tokenizers_cpp.sh`
  - æ”¯æŒmacOSå’ŒLinuxè‡ªåŠ¨å®‰è£…
  - è‡ªåŠ¨æ£€æµ‹å¹¶å®‰è£…Rustä¾èµ–
  - å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œç”¨æˆ·æç¤º

- [x] ç¼–å†™å®‰è£…æ–‡æ¡£`docs/Tokenizersåº“å®‰è£…æŒ‡å—.md`
  - è¯¦ç»†çš„å®‰è£…æ­¥éª¤
  - æ•…éšœæ’æŸ¥æŒ‡å—
  - æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨

### é˜¶æ®µ1: HFTokenizeråŸºç¡€åŠŸèƒ½å®ç° âœ…

#### 1.1 HFTokenizerå¤´æ–‡ä»¶æ›´æ–° âœ…

**æ–‡ä»¶**: `include/cllm/tokenizer/hf_tokenizer.h`

- [x] æ·»åŠ `USE_TOKENIZERS_CPP`æ¡ä»¶ç¼–è¯‘
- [x] å¼•å…¥`tokenizers_cpp.h`å¤´æ–‡ä»¶
- [x] æ·»åŠ `std::unordered_set<int> specialTokenIds_`å­˜å‚¨ç‰¹æ®ŠToken
- [x] æ–°å¢`tokenize()`æ–¹æ³•
- [x] æ–°å¢`isSpecialToken()`æ–¹æ³•
- [x] æ–°å¢`loadConfig()`ç§æœ‰æ–¹æ³•

#### 1.2 HFTokenizerå®ç°æ–‡ä»¶æ›´æ–° âœ…

**æ–‡ä»¶**: `src/tokenizer/hf_tokenizer.cpp`

- [x] **`load()`æ–¹æ³•**: 
  - æ£€æµ‹`tokenizer.json`æ–‡ä»¶
  - ä½¿ç”¨`tokenizers::Tokenizer::FromFile()`åŠ è½½
  - è°ƒç”¨`loadConfig()`åŠ è½½ç‰¹æ®ŠTokené…ç½®
  - å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è¾“å‡º

- [x] **`encode()`æ–¹æ³•**:
  - è°ƒç”¨tokenizers-cppçš„`Encode()`æ–¹æ³•
  - ç±»å‹è½¬æ¢`uint32_t` â†’ `int`
  - å¼‚å¸¸å¤„ç†

- [x] **`decode()`æ–¹æ³•**:
  - ç±»å‹è½¬æ¢`int` â†’ `uint32_t`
  - è°ƒç”¨tokenizers-cppçš„`Decode()`æ–¹æ³•
  - å¼‚å¸¸å¤„ç†

- [x] **`loadConfig()`æ–¹æ³•**:
  - è¯»å–`tokenizer_config.json`å’Œ`config.json`
  - è§£æç‰¹æ®ŠToken IDs (bos/eos/pad/unk)
  - è§£æ`added_tokens_decoder`è·å–å®Œæ•´ç‰¹æ®ŠTokenåˆ—è¡¨
  - JSONè§£æé”™è¯¯å¤„ç†

- [x] **å…¶ä»–æ–¹æ³•å®ç°**:
  - `getVocabSize()`: è°ƒç”¨`GetVocabSize()`
  - `idToToken()`: è°ƒç”¨`IdToToken()`
  - `tokenToId()`: è°ƒç”¨`TokenToId()`
  - `tokenize()`: ç¼–ç åè¿”å›Tokenå­—ç¬¦ä¸²åˆ—è¡¨
  - `isSpecialToken()`: æ£€æŸ¥Tokenæ˜¯å¦åœ¨ç‰¹æ®ŠTokené›†åˆä¸­

#### 1.3 TokenizerManageræ›´æ–° âœ…

**æ–‡ä»¶**: `src/tokenizer/manager.cpp`

- [x] **ä¼˜å…ˆçº§è°ƒæ•´**: HuggingFaceä¼˜å…ˆ â†’ SentencePieceå›é€€
  
- [x] **æ–°å¢æ£€æµ‹å‡½æ•°**:
  - `hasTokenizerJson()`: æ£€æµ‹tokenizer.jsonå­˜åœ¨
  - `hasTokenizerModel()`: æ£€æµ‹tokenizer.modelå­˜åœ¨

- [x] **å¢å¼º`detectModelType()`**:
  - è¯»å–`config.json`
  - è§£æ`model_type`å­—æ®µ
  - è§£æ`tokenizer_class`å­—æ®µ
  - æ”¯æŒQwen/Qwen2/DeepSeekç­‰æ¨¡å‹

- [x] **æ„é€ å‡½æ•°é€»è¾‘ä¼˜åŒ–**:
  ```cpp
  TokenizerImpl::AUTO:
    if (hasTokenizerJson(modelPath)) {
        // âœ… ä¼˜å…ˆä½¿ç”¨HFTokenizer
        tokenizer_ = new HFTokenizer(modelType);
    } else if (hasTokenizerModel(modelPath)) {
        // å›é€€åˆ°NativeTokenizer (SentencePiece)
        tokenizer_ = new NativeTokenizer(modelType);
    } else {
        // æœ€åå°è¯•NativeTokenizer
        tokenizer_ = new NativeTokenizer(modelType);
    }
  ```

- [x] **å¢å¼ºæ—¥å¿—è¾“å‡º**:
  - ä½¿ç”¨emojiæ ‡è®°å…³é”®ä¿¡æ¯
  - è¾“å‡ºæ£€æµ‹åˆ°çš„tokenizeræ ¼å¼
  - è¾“å‡ºåŠ è½½çŠ¶æ€

- [x] **æ”¹è¿›`loadStopTokens()`**:
  - åŒæ—¶åŠ è½½`stop_token_ids`å’Œ`eos_token_id`
  - å¼‚å¸¸å¤„ç†

---

## ğŸ“Š æ¶æ„æ”¹è¿›

### ä¼˜å…ˆçº§è°ƒæ•´

**ä¹‹å‰**:
```
1. å°è¯•SentencePiece (æ‰¾ä¸åˆ°tokenizer.modelå°±å¤±è´¥)
2. å›é€€åˆ°HF (ä½†HFæœªå®ç°)
```

**ç°åœ¨**:
```
1. âœ… ä¼˜å…ˆæ£€æµ‹HuggingFace (tokenizer.json)
2. å›é€€åˆ°SentencePiece (tokenizer.model)
3. æœ€åå°è¯•NativeTokenizer
```

### æ¡ä»¶ç¼–è¯‘æ”¯æŒ

```cpp
#ifdef USE_TOKENIZERS_CPP
    // ä½¿ç”¨tokenizers-cppå®ç°
    tokenizer_ = tokenizers::Tokenizer::FromFile(...);
#else
    // æä¾›æ¸…æ™°çš„é”™è¯¯ä¿¡æ¯
    CLLM_ERROR("HFTokenizer requires USE_TOKENIZERS_CPP");
#endif
```

---

## ğŸ¯ åŠŸèƒ½è¦†ç›–

| åŠŸèƒ½ | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| **åŠ è½½tokenizer.json** | âœ… | å®Œæ•´å®ç° |
| **æ–‡æœ¬ç¼–ç ** | âœ… | æ”¯æŒ`addSpecialTokens`å‚æ•° |
| **æ–‡æœ¬è§£ç ** | âœ… | æ”¯æŒ`skipSpecialTokens`å‚æ•° |
| **ç‰¹æ®ŠTokenè¯†åˆ«** | âœ… | BOS/EOS/PAD/UNK |
| **è¯è¡¨å¤§å°æŸ¥è¯¢** | âœ… | è°ƒç”¨tokenizers-cpp API |
| **Tokenâ†”IDè½¬æ¢** | âœ… | åŒå‘è½¬æ¢æ”¯æŒ |
| **åˆ†è¯(tokenize)** | âœ… | è¿”å›Tokenå­—ç¬¦ä¸²åˆ—è¡¨ |
| **è‡ªåŠ¨æ ¼å¼æ£€æµ‹** | âœ… | HFä¼˜å…ˆ |
| **æ¡ä»¶ç¼–è¯‘** | âœ… | å¯é€‰å¯ç”¨/ç¦ç”¨ |

---

## ğŸ§ª å¾…æµ‹è¯•åŠŸèƒ½

### éœ€è¦å®‰è£…tokenizers-cppåæµ‹è¯•

1. **Qwen3-0.6BåŠ è½½æµ‹è¯•**
   ```bash
   ./scripts/install_tokenizers_cpp.sh
   cd build && cmake .. -DUSE_TOKENIZERS_CPP=ON
   make -j8
   ./bin/test_hf_tokenizer
   ```

2. **ç¼–ç è§£ç roundtripæµ‹è¯•**
   ```cpp
   auto ids = tokenizer->encode("Hello, world!");
   auto decoded = tokenizer->decode(ids);
   assert(decoded == "Hello, world!");
   ```

3. **ç‰¹æ®ŠTokenæµ‹è¯•**
   ```cpp
   assert(tokenizer->getBosId() == 151643);
   assert(tokenizer->getEosId() == 151645);
   ```

---

## ğŸ“‹ ä¸‹ä¸€æ­¥å·¥ä½œ

### é˜¶æ®µ1å‰©ä½™ä»»åŠ¡ (éœ€è¦tokenizers-cppå®‰è£…åå®Œæˆ)

- [ ] **ä»»åŠ¡5**: æµ‹è¯•Qwen3-0.6Bæ¨¡å‹åŠ è½½
  - å®‰è£…tokenizers-cpp
  - ç¼–è¯‘cLLM (å¯ç”¨USE_TOKENIZERS_CPP)
  - è¿è¡Œæµ‹è¯•éªŒè¯

### é˜¶æ®µ2: æ¶æ„ç»Ÿä¸€ (åç»­)

- [ ] **ä»»åŠ¡6**: ç»Ÿä¸€Tokenç±»å‹å®šä¹‰
  - åˆ›å»º`include/cllm/tokenizer/types.h`
  - å®šä¹‰`token_id_t = int32_t`
  - å®šä¹‰`TokenSequence`ç±»å‹
  - å®šä¹‰`SpecialTokens`ç»“æ„ä½“

- [ ] **ä»»åŠ¡7**: é‡æ„BaseTokenizerç»Ÿä¸€æ¥å£
  - åˆ›å»º`include/cllm/tokenizer/base_tokenizer.h`
  - ç»Ÿä¸€`encode()`/`decode()`æ¥å£
  - ç»Ÿä¸€ç‰¹æ®ŠTokenè®¿é—®æ¥å£
  - å®ç°`TokenizerFactory`å·¥å‚ç±»

---

## ğŸ“„ ç”Ÿæˆçš„æ–‡æ¡£

1. âœ… `docs/Tokenizersåº“å®‰è£…æŒ‡å—.md` - å®‰è£…æŒ‡å—
2. âœ… `scripts/install_tokenizers_cpp.sh` - è‡ªåŠ¨å®‰è£…è„šæœ¬
3. âœ… `docs/analysis/README_TOKENIZER_MIGRATION.md` - è¿ç§»æ–¹æ¡ˆç´¢å¼• (ä¹‹å‰ç”Ÿæˆ)
4. âœ… `docs/analysis/hf_tokenizer_migration_strategy.md` - å®Œæ•´æŠ€æœ¯æ–¹æ¡ˆ (ä¹‹å‰ç”Ÿæˆ)
5. âœ… `docs/å®æ–½çŠ¶æ€æŠ¥å‘Š.md` - æœ¬æ–‡æ¡£

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼1: å·²å®‰è£…tokenizers-cpp

```bash
cd /Users/dannypan/PycharmProjects/xllm/cpp/cLLM/build
cmake .. -DUSE_TOKENIZERS_CPP=ON
make -j8

# æµ‹è¯•Qwen3æ¨¡å‹
./bin/test_http_server_direct
```

### æ–¹å¼2: å°šæœªå®‰è£…tokenizers-cpp

```bash
# è‡ªåŠ¨å®‰è£…
cd /Users/dannypan/PycharmProjects/xllm/cpp/cLLM
./scripts/install_tokenizers_cpp.sh

# ç¼–è¯‘
cd build
cmake .. -DUSE_TOKENIZERS_CPP=ON
make -j8
```

### æ–¹å¼3: ä¸ä½¿ç”¨HF (ä»…NativeTokenizer)

```bash
cd build
cmake .. -DUSE_TOKENIZERS_CPP=OFF
make -j8
```

---

## âœ… éªŒæ”¶æ ‡å‡† (é˜¶æ®µ1)

å®‰è£…tokenizers-cppåéœ€éªŒè¯:

1. âœ… CMakeèƒ½æ£€æµ‹åˆ°tokenizers-cpp
   ```
   âœ… Found tokenizers-cpp:
      Include: /opt/homebrew/include
      Library: /opt/homebrew/lib/libtokenizers_cpp.dylib
   ```

2. â³ HFTokenizerèƒ½åŠ è½½Qwen3-0.6B (å¾…éªŒè¯)
   ```
   âœ… HFTokenizer loaded successfully from: .../tokenizer.json
      Vocab size: 151936, BOS: 151643, EOS: 151645
   ```

3. â³ ç¼–ç è§£ç æ­£å¸¸å·¥ä½œ (å¾…éªŒè¯)
   ```
   âœ… Test: EncodeDecodeRoundtrip ... PASSED
   ```

4. â³ HTTP Serveræµ‹è¯•é€šè¿‡ (å¾…éªŒè¯)
   ```
   âœ… Test: GenerateBasic ... PASSED
   ```

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [å®Œæ•´æŠ€æœ¯æ–¹æ¡ˆ](./analysis/hf_tokenizer_migration_strategy.md)
- [è¿ç§»æ–¹æ¡ˆç´¢å¼•](./analysis/README_TOKENIZER_MIGRATION.md)
- [å¿«é€Ÿä¸Šæ‰‹æŒ‡å—](./analysis/QUICK_START_HF_TOKENIZER.md)
- [å¯¹æ¯”åˆ†æçŸ©é˜µ](./analysis/tokenizer_comparison_matrix.md)
- [tokenizers-cppå®‰è£…æŒ‡å—](./Tokenizersåº“å®‰è£…æŒ‡å—.md)

---

**çŠ¶æ€æ›´æ–°é¢‘ç‡**: æ¯å®Œæˆä¸€ä¸ªä»»åŠ¡åæ›´æ–°  
**è´Ÿè´£äºº**: cLLM Core Team  
**å®¡æ ¸äºº**: Tech Lead
