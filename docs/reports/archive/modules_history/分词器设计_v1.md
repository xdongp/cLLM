# cLLM CTokenizeræ¨¡å—è®¾è®¡ï¼ˆé€šç”¨ç‰ˆï¼‰

## ç¼–ç¨‹è§„èŒƒ

æœ¬æ¨¡å—çš„ç¼–ç å®ç°éµå¾ªä»¥ä¸‹è§„èŒƒå’Œçº¦å®šï¼š
- [C++ç¼–ç¨‹è§„èŒƒ.md](../C++ç¼–ç¨‹è§„èŒƒ.md)ï¼šå®šä¹‰ç¼–ç é£æ ¼ã€å‘½åè§„èŒƒç­‰
- [ç”Ÿæˆä»£ç è§„èŒƒ.md](../ç”Ÿæˆä»£ç è§„èŒƒ.md)ï¼šå®šä¹‰ä»£ç ç”Ÿæˆæµç¨‹ã€è®¾è®¡æ–‡æ¡£ä¸€è‡´æ€§è¦æ±‚ã€ä¼˜åŒ–åŒæ­¥æœºåˆ¶ç­‰


## 1. è®¾è®¡ç›®æ ‡

### 1.1 æ ¸å¿ƒåŠŸèƒ½
- æ–‡æœ¬ â†” Token ID åŒå‘è½¬æ¢
- æ”¯æŒä¸»æµæ¨¡å‹æ ¼å¼ï¼ˆHuggingFace/SentencePiece/Qwen/DeepSeek/Llamaç­‰ï¼‰
- ç‰¹æ®Š Token å¤„ç†ï¼ˆBOS/EOS/PAD/FIMç­‰ï¼‰
- æµå¼å¤„ç†æ”¯æŒ
- é«˜æ€§èƒ½åˆ†è¯ç®—æ³•

### 1.2 æ€§èƒ½æŒ‡æ ‡
- ç¼–ç é€Ÿåº¦ â‰¥ 50MB/s
- å†…å­˜å ç”¨ â‰¤ 50MB
- åŠ è½½æ—¶é—´ â‰¤ 100ms
- æ”¯æŒå¤šç§é¢„å¤„ç†å™¨ï¼ˆDeepSeekã€Qwenç­‰ç‰¹å®šé¢„å¤„ç†ï¼‰

### 1.3 å…¼å®¹æ€§ç›®æ ‡
- æ”¯æŒQwenç³»åˆ—æ¨¡å‹ï¼ˆQwenã€Qwen2ç­‰ï¼‰
- æ”¯æŒDeepSeekç³»åˆ—æ¨¡å‹ï¼ˆDeepSeek-LLMã€DeepSeek-Coderã€DeepSeek3ç­‰ï¼‰
- æ”¯æŒLlamaç³»åˆ—æ¨¡å‹
- å‘åå…¼å®¹ç°æœ‰SentencePieceæ¨¡å‹

## 2. æ¶æ„è®¾è®¡

### 2.1 æ¨¡å—ç»„æˆ
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            TokenizerManager         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚         CTokenizer             â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚   SentencePieceEngine   â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚    BPEEngine            â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚     JsonTokenizer       â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚        ModelDetector           â”‚ â”‚
â”‚  â”‚  Detect model type (Qwen,     â”‚ â”‚
â”‚  â”‚  DeepSeek, Llama, etc.)      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 ç±»å…³ç³»å›¾
```mermaid
classDiagram
    class CTokenizer {
        <<interface>>
        +encode(text: str): int[]
        +decode(ids: int[]): str
        +getVocabSize(): int
        +getModelType(): ModelType
    }
    
    class SentencePieceTokenizer {
        -processor: SentencePieceProcessor
        +loadModel(path: str)
    }
    
    class BPETokenizer {
        -merges: map[str, int]
        -vocab: map[str, int]
        +initialize(modelPath: str)
    }
    
    class QwenTokenizer {
        -processor: SentencePieceProcessor
        -specialTokens: map[str, int]
        +encodeWithFim(text: str)
    }
    
    class DeepSeekTokenizer {
        -processor: SentencePieceProcessor
        -regex_patterns: vector[str]
        +applyPreprocessing(text: str)
    }
    
    class TokenizerManager {
        -tokenizers: Map<string, CTokenizer>
        +getTokenizer(modelType: str): CTokenizer
        +detectModelType(configPath: str): ModelType
    }
    
    CTokenizer <|-- SentencePieceTokenizer
    CTokenizer <|-- BPETokenizer
    CTokenizer <|-- QwenTokenizer
    CTokenizer <|-- DeepSeekTokenizer
    TokenizerManager --> CTokenizer
```

## 3. è¯¦ç»†è®¾è®¡

### 3.1 æ¥å£å®šä¹‰

```cpp
enum class ModelType {
    AUTO,           // è‡ªåŠ¨æ£€æµ‹
    QWEN,           // Qwenç³»åˆ—æ¨¡å‹
    QWEN2,          // Qwen2ç³»åˆ—æ¨¡å‹
    DEEPSEEK_LLM,   // DeepSeek LLMæ¨¡å‹
    DEEPSEEK_CODER, // DeepSeek Coderæ¨¡å‹
    DEEPSEEK3_LLM,  // DeepSeek3 LLMæ¨¡å‹
    LLAMA,          // Llamaç³»åˆ—æ¨¡å‹
    BERT,           // BERTç³»åˆ—æ¨¡å‹
    GPT2,           // GPT2ç³»åˆ—æ¨¡å‹
    SPM,            // SentencePieceæ¨¡å‹
    BPE,            // BPEæ¨¡å‹
    WPM             // WordPieceæ¨¡å‹
};

class CTokenizer {
public:
    virtual ~CTokenizer() = default;
    
    // æ ¸å¿ƒåŠŸèƒ½
    virtual std::vector<int> encode(
        const std::string& text, 
        bool addSpecialTokens = true
    ) = 0;
    
    virtual std::string decode(
        const std::vector<int>& ids,
        bool skipSpecialTokens = true
    ) = 0;
    
    // è¯æ±‡è¡¨æ“ä½œ
    virtual int getVocabSize() const = 0;
    virtual std::string idToToken(int id) const = 0;
    virtual int tokenToId(const std::string& token) const = 0;
    
    // ç‰¹æ®ŠToken
    virtual int getBosId() const = 0;
    virtual int getEosId() const = 0;
    virtual int getPadId() const = 0;
    virtual int getUnkId() const = 0;
    
    // æ¨¡å‹ç±»å‹
    virtual ModelType getModelType() const = 0;
    
    // åŠ è½½æ¨¡å‹
    virtual bool load(const std::string& modelPath) = 0;
};
```

### 3.2 é€šç”¨åˆ†è¯å™¨å®ç°

#### 3.2.1 SentencePieceTokenizer å®ç°

```cpp
class SentencePieceTokenizer : public CTokenizer {
private:
    std::unique_ptr<sentencepiece::SentencePieceProcessor> processor_;
    ModelType modelType_;
    std::unordered_map<std::string, int> specialTokens_;
    std::unordered_map<int, std::string> idToTokenMap_;
    
    // ç‰¹æ®Štoken ID
    int bosId_{-1};
    int eosId_{-1};
    int padId_{-1};
    int unkId_{-1};
    
public:
    explicit SentencePieceTokenizer(ModelType modelType);
    ~SentencePieceTokenizer() override;
    
    bool load(const std::string& modelPath) override;
    std::vector<int> encode(const std::string& text, bool addSpecialTokens = true) override;
    std::string decode(const std::vector<int>& ids, bool skipSpecialTokens = true) override;
    
    int getVocabSize() const override;
    std::string idToToken(int id) const override;
    int tokenToId(const std::string& token) const override;
    
    int getBosId() const override { return bosId_; }
    int getEosId() const override { return eosId_; }
    int getPadId() const override { return padId_; }
    int getUnkId() const override { return unkId_; }
    
    ModelType getModelType() const override { return modelType_; }
    
private:
    void loadModelConfig(const std::string& configPath);
    void loadSpecialTokens(const std::string& configPath);
    void initializeRegexPatterns();
};
```

#### 3.2.2 DeepSeek åˆ†è¯å™¨å®ç°

```cpp
class DeepSeekTokenizer : public SentencePieceTokenizer {
public:
    explicit DeepSeekTokenizer(ModelType modelType) : SentencePieceTokenizer(modelType) {}
    
    std::vector<int> encode(const std::string& text, bool addSpecialTokens = true) override {
        // åº”ç”¨DeepSeekç‰¹å®šçš„é¢„å¤„ç†
        std::string processedText = applyDeepSeekPreprocessing(text);
        return SentencePieceTokenizer::encode(processedText, addSpecialTokens);
    }
    
private:
    std::string applyDeepSeekPreprocessing(const std::string& text) {
        // DeepSeekç‰¹å®šçš„é¢„å¤„ç†é€»è¾‘
        // æ ¹æ®æ¨¡å‹ç±»å‹åº”ç”¨ä¸åŒçš„æ­£åˆ™è¡¨è¾¾å¼
        switch(getModelType()) {
            case ModelType::DEEPSEEK_LLM:
                return applyDeepSeekLLMPreprocessing(text);
            case ModelType::DEEPSEEK_CODER:
                return applyDeepSeekCoderPreprocessing(text);
            case ModelType::DEEPSEEK3_LLM:
                return applyDeepSeek3Preprocessing(text);
            default:
                return text;
        }
    }
    
    std::string applyDeepSeekLLMPreprocessing(const std::string& text) {
        // DeepSeek LLMä½¿ç”¨çš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ï¼š
        // - "[\r\n]": åŒ¹é…æ¢è¡Œç¬¦
        // - "\\s?[A-Za-z...]": åŒ¹é…å­—æ¯å­—ç¬¦
        // - "\\s?[!-/:-~...]": åŒ¹é…æ ‡ç‚¹ç¬¦å·
        // - "[ä¸€-é¾¥...]": åŒ¹é…ä¸­æ–‡å­—ç¬¦
        // - "\\p{N}+": åŒ¹é…æ•°å­—
        return text; // å®é™…å®ç°å°†åœ¨cppæ–‡ä»¶ä¸­
    }
    
    std::string applyDeepSeekCoderPreprocessing(const std::string& text) {
        // DeepSeek Coderä½¿ç”¨çš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ï¼š
        // - "[\r\n]": åŒ¹é…æ¢è¡Œç¬¦
        // - "\\s?\\p{L}+": åŒ¹é…å­—æ¯
        // - "\\s?\\p{P}+": åŒ¹é…æ ‡ç‚¹
        // - "[ä¸€-é¾¥...]": åŒ¹é…ä¸­æ–‡å­—ç¬¦
        // - "\\p{N}": åŒ¹é…æ•°å­—
        return text; // å®é™…å®ç°å°†åœ¨cppæ–‡ä»¶ä¸­
    }
    
    std::string applyDeepSeek3Preprocessing(const std::string& text) {
        // DeepSeek3ä½¿ç”¨çš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ï¼š
        // - "\\p{N}{1,3}": åŒ¹é…1-3ä½æ•°å­—
        // - "[ä¸€-é¾¥...]": åŒ¹é…ä¸­æ–‡å­—ç¬¦
        // - å¤æ‚çš„æ··åˆæ¨¡å¼ç”¨äºåŒ¹é…å„ç§å­—ç¬¦ç»„åˆ
        return text; // å®é™…å®ç°å°†åœ¨cppæ–‡ä»¶ä¸­
    }
};
```

#### 3.2.3 Qwen åˆ†è¯å™¨å®ç°

```cpp
class QwenTokenizer : public SentencePieceTokenizer {
public:
    explicit QwenTokenizer() : SentencePieceTokenizer(ModelType::QWEN) {}
    
    std::vector<int> encode(const std::string& text, bool addSpecialTokens = true) override {
        // Qwenç‰¹å®šçš„FIMï¼ˆFill-in-the-Middleï¼‰å¤„ç†
        if (needsFimProcessing(text)) {
            return encodeWithFim(text, addSpecialTokens);
        }
        return SentencePieceTokenizer::encode(text, addSpecialTokens);
    }
    
private:
    bool needsFimProcessing(const std::string& text) {
        // æ£€æŸ¥æ˜¯å¦éœ€è¦FIMå¤„ç†
        // Qwenæ¨¡å‹ç‰¹æœ‰çš„FIM tokens: <ï½œfim_beginï½œ>, <ï½œfim_endï½œ>, <ï½œfim_padï½œ>, <ï½œfim_sufï½œ>, <ï½œfim_preï½œ>
        return text.find("<ï½œfim_beginï½œ>") != std::string::npos || 
               text.find("<ï½œfim_endï½œ>") != std::string::npos;
    }
    
    std::vector<int> encodeWithFim(const std::string& text, bool addSpecialTokens) {
        // Qwençš„FIMå¤„ç†é€»è¾‘
        // è¿™é‡Œå®ç°Qwenç‰¹æœ‰çš„FIMï¼ˆFill-in-the-Middleï¼‰åˆ†è¯é€»è¾‘
        std::vector<int> result;
        
        // å®é™…çš„FIMå¤„ç†å°†åœ¨cppæ–‡ä»¶ä¸­å®ç°
        return SentencePieceTokenizer::encode(text, addSpecialTokens);
    }
    
    std::string applyQwenPreprocessing(const std::string& text) {
        // Qwen2ä½¿ç”¨çš„é¢„å¤„ç†é€»è¾‘
        // æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ï¼š
        // - "(?:'[sS]|'[tT]|'[rR][eE]|'[vV][eE]|'[mM]|'[lL][lL]|'[dD])": åŒ¹é…è‹±è¯­ç¼©å†™
        // - "[^\\r\\n\\p{L}\\p{N}]?\\p{L}+": åŒ¹é…å­—æ¯åºåˆ—
        // - "\\p{N}": åŒ¹é…æ•°å­—
        // - å¤æ‚çš„ç©ºç™½å’Œæ ‡ç‚¹å¤„ç†æ¨¡å¼
        return text; // å®é™…å®ç°å°†é€šè¿‡é¢„å¤„ç†å™¨å¤„ç†
    }
};
```

### 3.3 æ€§èƒ½ä¼˜åŒ–

#### 3.3.1 å†…å­˜ç¼“å­˜è®¾è®¡

```cpp
class TokenCache {
private:
    std::unordered_map<std::string, std::vector<int>> encodeCache_;
    std::unordered_map<std::vector<int>, std::string, VectorHash> decodeCache_;
    mutable std::shared_mutex mutex_;
    size_t maxSize_;
    
public:
    TokenCache(size_t maxSize = 10000) : maxSize_(maxSize) {}
    
    void putEncode(const std::string& text, const std::vector<int>& tokens) {
        std::unique_lock lock(mutex_);
        if (encodeCache_.size() >= maxSize_) {
            encodeCache_.erase(encodeCache_.begin()); // ç®€å•çš„LRUç­–ç•¥
        }
        encodeCache_[text] = tokens;
    }
    
    std::optional<std::vector<int>> getEncode(const std::string& text) const {
        std::shared_lock lock(mutex_);
        auto it = encodeCache_.find(text);
        return it != encodeCache_.end() ? std::make_optional(it->second) : std::nullopt;
    }
    
    void putDecode(const std::vector<int>& tokens, const std::string& text) {
        std::unique_lock lock(mutex_);
        if (decodeCache_.size() >= maxSize_) {
            decodeCache_.erase(decodeCache_.begin()); // ç®€å•çš„LRUç­–ç•¥
        }
        decodeCache_[tokens] = text;
    }
    
    std::optional<std::string> getDecode(const std::vector<int>& tokens) const {
        std::shared_lock lock(mutex_);
        auto it = decodeCache_.find(tokens);
        return it != decodeCache_.end() ? std::make_optional(it->second) : std::nullopt;
    }
};
```

#### 3.3.2 æ‰¹å¤„ç†æ¥å£

```cpp
class BatchTokenizer {
public:
    struct BatchResult {
        std::vector<std::vector<int>> tokenized;
        std::vector<bool> success;
        std::vector<std::string> errors;
    };
    
    static BatchResult batchEncode(
        CTokenizer* tokenizer,
        const std::vector<std::string>& texts,
        bool addSpecialTokens = true,
        int maxParallel = 4
    );
    
    static std::vector<std::string> batchDecode(
        CTokenizer* tokenizer,
        const std::vector<std::vector<int>>& tokenLists,
        bool skipSpecialTokens = true,
        int maxParallel = 4
    );
};
```

## 4. æ¨¡å‹å…¼å®¹æ€§

### 4.1 æ”¯æŒæ ¼å¼
| æ ¼å¼ç±»å‹ | æ–‡ä»¶ç¤ºä¾‹ | åŠ è½½æ–¹å¼ | é€‚ç”¨æ¨¡å‹ |
|---------|---------|---------|----------|
| SentencePiece | model.spm | ç›´æ¥åŠ è½½ | Llamaã€æ—©æœŸæ¨¡å‹ |
| HuggingFace | tokenizer.json | è§£æé…ç½® | å¤§å¤šæ•°ç°ä»£æ¨¡å‹ |
| BPE | vocab.json + merges.txt | è§£æè¯æ±‡è¡¨å’Œåˆå¹¶è§„åˆ™ | GPTç³»åˆ—æ¨¡å‹ |
| TikToken | qwen.tiktoken | è‡ªå®šä¹‰è§£æ | Qwenç³»åˆ— |

### 4.2 è‡ªåŠ¨æ£€æµ‹æœºåˆ¶

```cpp
class ModelDetector {
public:
    static ModelType detectModelType(const std::string& configPath) {
        try {
            auto config = readJson(configPath);
            
            // æ£€æŸ¥tokenizer_classå­—æ®µ
            if (config.contains("tokenizer_class")) {
                std::string tokenizerClass = config["tokenizer_class"].get<std::string>();
                
                if (tokenizerClass.find("Qwen") != std::string::npos) {
                    return ModelType::QWEN;
                } else if (tokenizerClass.find("DeepSeek") != std::string::npos) {
                    if (tokenizerClass.find("DeepSeek3") != std::string::npos) {
                        return ModelType::DEEPSEEK3_LLM;
                    } else if (tokenizerClass.find("Coder") != std::string::npos) {
                        return ModelType::DEEPSEEK_CODER;
                    } else {
                        return ModelType::DEEPSEEK_LLM;
                    }
                } else if (tokenizerClass.find("Llama") != std::string::npos) {
                    return ModelType::LLAMA;
                } else if (tokenizerClass.find("Bert") != std::string::npos) {
                    return ModelType::BERT;
                } else if (tokenizerClass.find("GPT2") != std::string::npos) {
                    return ModelType::GPT2;
                }
            }
            
            // æ£€æŸ¥chat_templateå­—æ®µ
            if (config.contains("chat_template")) {
                std::string chatTemplate = config["chat_template"].get<std::string>();
                
                if (chatTemplate.find("qwen") != std::string::npos) {
                    return ModelType::QWEN;
                } else if (chatTemplate.find("deepseek") != std::string::npos) {
                    if (chatTemplate.find("deepseek3") != std::string::npos) {
                        return ModelType::DEEPSEEK3_LLM;
                    } else if (chatTemplate.find("coder") != std::string::npos) {
                        return ModelType::DEEPSEEK_CODER;
                    } else {
                        return ModelType::DEEPSEEK_LLM;
                    }
                }
            }
            
            // æ£€æŸ¥model_typeå­—æ®µ
            if (config.contains("model_type")) {
                std::string modelType = config["model_type"].get<std::string>();
                
                if (modelType.find("qwen") != std::string::npos) {
                    return ModelType::QWEN;
                } else if (modelType.find("deepseek") != std::string::npos) {
                    if (modelType.find("deepseek3") != std::string::npos) {
                        return ModelType::DEEPSEEK3_LLM;
                    } else if (modelType.find("coder") != std::string::npos) {
                        return ModelType::DEEPSEEK_CODER;
                    } else {
                        return ModelType::DEEPSEEK_LLM;
                    }
                }
            }
            
            // æ£€æŸ¥ç‰¹æ®Štokenåç§°æ¨¡å¼
            if (config.contains("added_tokens_decoder")) {
                auto tokens = config["added_tokens_decoder"];
                for (auto& item : tokens.items()) {
                    if (item.value().contains("content")) {
                        std::string content = item.value()["content"];
                        if (content == "<ï½œfim_beginï½œ>" || content == "<ï½œfim_endï½œ>" || content == "<ï½œfim_padï½œ>" || 
                            content == "<ï½œfim_sufï½œ>" || content == "<ï½œfim_preï½œ>") {
                            return ModelType::QWEN;  // Qwenç‰¹æœ‰çš„FIM tokens
                        } else if (content.find("deepseek") != std::string::npos) {
                            return ModelType::DEEPSEEK_LLM;
                        }
                    }
                }
            }
            
            // é»˜è®¤è¿”å›SPM
            return ModelType::SPM;
        } catch (const std::exception& e) {
            // å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤ç±»å‹
            return ModelType::SPM;
        }
    }
};
```

### 4.3 ç‰¹æ®ŠTokenå¤„ç†

``cpp
// ä»é…ç½®æ–‡ä»¶åŠ è½½ç‰¹æ®ŠToken
void loadSpecialTokens(CTokenizer* tokenizer, const std::string& configPath) {
    auto json = readJson(configPath);
    
    // æ ‡å‡†ç‰¹æ®ŠToken
    if (json.contains("bos_token_id")) {
        // è®¾ç½®BOS ID
    }
    if (json.contains("eos_token_id")) {
        // è®¾ç½®EOS ID
    }
    if (json.contains("pad_token_id")) {
        // è®¾ç½®PAD ID
    }
    if (json.contains("unk_token_id")) {
        // è®¾ç½®UNK ID
    }
    
    // æ¨¡å‹ç‰¹å®šçš„ç‰¹æ®ŠToken
    if (json.contains("additional_special_tokens")) {
        // å¤„ç†é¢å¤–çš„ç‰¹æ®ŠToken
    }
}
```

## 5. å®ç°ç­–ç•¥

### 5.1 é€šç”¨åˆ†è¯å™¨é›†æˆæ–¹æ¡ˆ
- ä½¿ç”¨SentencePieceä½œä¸ºåŸºç¡€åˆ†è¯å¼•æ“
- å°è£…ä¸åŒæ¨¡å‹çš„ç‰¹æ®Šå¤„ç†é€»è¾‘
- ä¿æŒä¸ç°æœ‰APIçš„å…¼å®¹æ€§
- å®ç°æ¨¡å‹ç‰¹å®šçš„é¢„å¤„ç†å™¨æ”¯æŒ

### 5.2 é€æ­¥è¿ç§»ç­–ç•¥
1. **ç¬¬ä¸€é˜¶æ®µ**: å®ç°åŸºç¡€SentencePieceåˆ†è¯å™¨å°è£…
2. **ç¬¬äºŒé˜¶æ®µ**: æ·»åŠ DeepSeekå’ŒQwenæ¨¡å‹æ”¯æŒ
3. **ç¬¬ä¸‰é˜¶æ®µ**: ä¼˜åŒ–æ€§èƒ½å’Œå†…å­˜ä½¿ç”¨
4. **ç¬¬å››é˜¶æ®µ**: é›†æˆåˆ°cLLMä¸»æµç¨‹

### 5.3 æ€§èƒ½ä¼˜åŒ–è€ƒè™‘
- å®ç°tokenç¼“å­˜æœºåˆ¶
- ä¼˜åŒ–å­—ç¬¦ä¸²å¤„ç†
- ä½¿ç”¨é«˜æ•ˆçš„æ­£åˆ™è¡¨è¾¾å¼å¼•æ“
- é¢„åˆ†é…å†…å­˜å‡å°‘åŠ¨æ€åˆ†é…å¼€é”€
- å¹¶è¡Œæ‰¹å¤„ç†æ”¯æŒ

## 6. æµ‹è¯•éªŒè¯æ–¹æ¡ˆ

### 6.1 å•å…ƒæµ‹è¯•

#### 6.1.1 åŸºç¡€åŠŸèƒ½æµ‹è¯•
``cpp
TEST(SentencePieceTokenizerTest, QwenEncodeDecode) {
    SentencePieceTokenizer tokenizer(ModelType::QWEN);
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    std::string text = "Hello, world!";
    auto ids = tokenizer.encode(text);
    ASSERT_FALSE(ids.empty());
    
    std::string decoded = tokenizer.decode(ids);
    EXPECT_EQ(decoded, text);
}

TEST(DeepSeekTokenizerTest, DeepSeekCoderPreprocessing) {
    DeepSeekTokenizer tokenizer(ModelType::DEEPSEEK_CODER);
    ASSERT_TRUE(tokenizer.load("test_models/deepseek-coder/config.json"));
    
    std::string text = "def hello_world():\n    print('Hello')";
    auto ids = tokenizer.encode(text);
    ASSERT_FALSE(ids.empty());
}

TEST(QwenTokenizerTest, FimProcessing) {
    QwenTokenizer tokenizer;
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    // æµ‹è¯•FIMå¤„ç†
    std::string text = "def hello_world() -> str:\n    return \"Hello World\"";
    auto ids = tokenizer.encode(text);
    ASSERT_FALSE(ids.empty());
    
    std::string decoded = tokenizer.decode(ids);
    EXPECT_EQ(decoded, text);
}
```

#### 6.1.2 æ¨¡å‹å…¼å®¹æ€§æµ‹è¯•
``cpp
TEST(ModelDetectorTest, AutoDetection) {
    // æµ‹è¯•æ¨¡å‹è‡ªåŠ¨æ£€æµ‹åŠŸèƒ½
    ModelType type = ModelDetector::detectModelType("test_models/qwen/config.json");
    EXPECT_EQ(type, ModelType::QWEN);
    
    type = ModelDetector::detectModelType("test_models/deepseek-coder/config.json");
    EXPECT_EQ(type, ModelType::DEEPSEEK_CODER);
    
    type = ModelDetector::detectModelType("test_models/deepseek-llm/config.json");
    EXPECT_EQ(type, ModelType::DEEPSEEK_LLM);
}

TEST(TokenizerManagerTest, GetTokenizer) {
    TokenizerManager manager;
    
    auto qwenTokenizer = manager.getTokenizer("qwen");
    ASSERT_NE(qwenTokenizer, nullptr);
    EXPECT_EQ(qwenTokenizer->getModelType(), ModelType::QWEN);
    
    auto deepseekTokenizer = manager.getTokenizer("deepseek-coder");
    ASSERT_NE(deepseekTokenizer, nullptr);
    EXPECT_EQ(deepseekTokenizer->getModelType(), ModelType::DEEPSEEK_CODER);
}
```

#### 6.1.3 ç‰¹æ®ŠTokenå¤„ç†æµ‹è¯•
``cpp
TEST(CTokenizerTest, SpecialTokens) {
    CTokenizer tokenizer(ModelType::QWEN);
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    // æµ‹è¯•ç‰¹æ®ŠToken
    int bosId = tokenizer.getBosId();
    int eosId = tokenizer.getEosId();
    int padId = tokenizer.getPadId();
    
    EXPECT_GT(bosId, 0);
    EXPECT_GT(eosId, 0);
    EXPECT_GE(padId, 0); // padIdå¯èƒ½ä¸º-1ï¼ˆæœªè®¾ç½®ï¼‰
    
    // æµ‹è¯•å¸¦ç‰¹æ®ŠTokençš„ç¼–ç 
    std::string text = "Hello";
    auto idsWithoutSpecial = tokenizer.encode(text, false);
    auto idsWithSpecial = tokenizer.encode(text, true);
    
    // å¸¦ç‰¹æ®ŠTokençš„åºåˆ—åº”è¯¥æ›´é•¿
    EXPECT_GE(idsWithSpecial.size(), idsWithoutSpecial.size());
}

TEST(CTokenizerTest, VocabOperations) {
    CTokenizer tokenizer(ModelType::QWEN);
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    // æµ‹è¯•è¯æ±‡è¡¨æ“ä½œ
    int vocabSize = tokenizer.getVocabSize();
    EXPECT_GT(vocabSize, 0);
    
    // æµ‹è¯•IDåˆ°Tokençš„è½¬æ¢
    std::string token = tokenizer.idToToken(100); // å‡è®¾ID 100å­˜åœ¨
    EXPECT_FALSE(token.empty());
    
    // æµ‹è¯•Tokenåˆ°IDçš„è½¬æ¢
    int id = tokenizer.tokenToId(token);
    EXPECT_EQ(token, tokenizer.idToToken(id));
}
```

#### 6.1.4 è¾¹ç•Œæ¡ä»¶æµ‹è¯•
``cpp
TEST(CTokenizerTest, BoundaryConditions) {
    CTokenizer tokenizer(ModelType::QWEN);
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    // ç©ºå­—ç¬¦ä¸²æµ‹è¯•
    auto emptyIds = tokenizer.encode("");
    EXPECT_TRUE(emptyIds.empty() || emptyIds.size() == 2); // å¯èƒ½åŒ…å«BOS/EOS
    
    // å•å­—ç¬¦æµ‹è¯•
    auto singleCharIds = tokenizer.encode("A");
    EXPECT_FALSE(singleCharIds.empty());
    
    std::string singleDecoded = tokenizer.decode(singleCharIds);
    EXPECT_EQ(singleDecoded, "A");
    
    // ç‰¹æ®Šå­—ç¬¦æµ‹è¯•
    std::string specialText = "Hello, ä¸–ç•Œ! ğŸŒ";
    auto specialIds = tokenizer.encode(specialText);
    ASSERT_FALSE(specialIds.empty());
    
    std::string specialDecoded = tokenizer.decode(specialIds);
    EXPECT_EQ(specialDecoded, specialText);
}
```

### 6.2 é›†æˆæµ‹è¯•

#### 6.2.1 ç«¯åˆ°ç«¯æµ‹è¯•
``cpp
TEST(IntegrationTest, EndToEnd) {
    // æ¨¡æ‹Ÿå®Œæ•´çš„å·¥ä½œæµ
    TokenizerManager manager;
    auto tokenizer = manager.getTokenizer("qwen");
    ASSERT_NE(tokenizer, nullptr);
    
    std::string input = "This is a test sentence for end-to-end validation.";
    auto tokens = tokenizer->encode(input);
    ASSERT_FALSE(tokens.empty());
    
    std::string output = tokenizer->decode(tokens);
    EXPECT_EQ(input, output);
    
    // éªŒè¯è¯æ±‡è¡¨å¤§å°çš„ä¸€è‡´æ€§
    int vocabSize = tokenizer->getVocabSize();
    EXPECT_GT(vocabSize, 1000); // åˆç†çš„è¯æ±‡è¡¨å¤§å°
}

TEST(IntegrationTest, MultiModelSupport) {
    TokenizerManager manager;
    
    // æµ‹è¯•ä¸åŒæ¨¡å‹ç±»å‹çš„åˆ†è¯å™¨
    std::vector<std::string> modelTypes = {"qwen", "deepseek-llm", "deepseek-coder"};
    
    for (const auto& modelType : modelTypes) {
        auto tokenizer = manager.getTokenizer(modelType);
        ASSERT_NE(tokenizer, nullptr) << "Failed to get tokenizer for " << modelType;
        
        std::string testText = "Test text for " + modelType;
        auto tokens = tokenizer->encode(testText);
        ASSERT_FALSE(tokens.empty()) << "Encoding failed for " << modelType;
        
        std::string decoded = tokenizer->decode(tokens);
        EXPECT_EQ(decoded, testText) << "Decoding mismatch for " << modelType;
    }
}
```

#### 6.2.2 æ‰¹å¤„ç†æµ‹è¯•
``cpp
TEST(BatchTokenizerTest, BatchEncodeDecode) {
    LlamaCppTokenizer tokenizer(ModelType::QWEN);
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    std::vector<std::string> texts = {
        "Hello, world!",
        "This is a test sentence.",
        "Another test with numbers: 12345",
        "Mixed content: Hello ä¸–ç•Œ ğŸŒ"
    };
    
    // æµ‹è¯•æ‰¹é‡ç¼–ç 
    auto batchResult = BatchTokenizer::batchEncode(&tokenizer, texts, true, 4);
    ASSERT_EQ(batchResult.tokenized.size(), texts.size());
    
    // éªŒè¯æ¯ä¸ªæ–‡æœ¬éƒ½è¢«æˆåŠŸç¼–ç 
    for (size_t i = 0; i < batchResult.success.size(); ++i) {
        EXPECT_TRUE(batchResult.success[i]) << "Batch encoding failed for text " << i;
        EXPECT_FALSE(batchResult.tokenized[i].empty()) << "Empty result for text " << i;
    }
    
    // æµ‹è¯•æ‰¹é‡è§£ç 
    std::vector<std::string> decoded = BatchTokenizer::batchDecode(
        &tokenizer, batchResult.tokenized, true, 4
    );
    
    ASSERT_EQ(decoded.size(), texts.size());
    for (size_t i = 0; i < texts.size(); ++i) {
        EXPECT_EQ(decoded[i], texts[i]) << "Batch decode mismatch for text " << i;
    }
}
```

### 6.3 æ€§èƒ½æµ‹è¯•

#### 6.3.1 åŸºå‡†æµ‹è¯•
``cpp
TEST(PerformanceTest, EncodeSpeed) {
    CTokenizer tokenizer(ModelType::QWEN);
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    std::string longText;
    for (int i = 0; i < 1000; ++i) {
        longText += "This is a test sentence for performance evaluation. ";
    }
    
    auto start = std::chrono::high_resolution_clock::now();
    auto tokens = tokenizer.encode(longText);
    auto end = std::chrono::high_resolution_clock::now();
    
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);
    EXPECT_LT(duration.count(), 1000); // åº”è¯¥åœ¨1ç§’å†…å®Œæˆ
    
    EXPECT_FALSE(tokens.empty());
    
    // è®¡ç®—ç¼–ç é€Ÿåº¦ (å­—ç¬¦/ç§’)
    double speed = (double)longText.length() / (duration.count() / 1000.0);
    EXPECT_GT(speed, 50000); // è‡³å°‘50KB/s
}

TEST(PerformanceTest, DecodeSpeed) {
    CTokenizer tokenizer(ModelType::QWEN);
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    std::string text = "Performance test text. ";
    auto tokens = tokenizer.encode(text);
    
    // é‡å¤å¤šæ¬¡ä»¥è·å¾—æ›´å¥½çš„æµ‹é‡ç»“æœ
    std::vector<std::vector<int>> batchTokens;
    for (int i = 0; i < 1000; ++i) {
        batchTokens.push_back(tokens);
    }
    
    auto start = std::chrono::high_resolution_clock::now();
    std::vector<std::string> decoded = BatchTokenizer::batchDecode(
        &tokenizer, batchTokens, true, 4
    );
    auto end = std::chrono::high_resolution_clock::now();
    
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);
    EXPECT_LT(duration.count(), 1000); // åº”è¯¥åœ¨1ç§’å†…å®Œæˆ
    
    EXPECT_EQ(decoded.size(), batchTokens.size());
}

TEST(PerformanceTest, MemoryUsage) {
    CTokenizer tokenizer(ModelType::QWEN);
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    // æ£€æŸ¥åˆå§‹å†…å­˜ä½¿ç”¨
    size_t initialMemory = getCurrentMemoryUsage();
    
    // æ‰§è¡Œå¤šæ¬¡ç¼–ç /è§£ç æ“ä½œ
    for (int i = 0; i < 10000; ++i) {
        std::string text = "Test " + std::to_string(i);
        auto tokens = tokenizer.encode(text);
        std::string decoded = tokenizer.decode(tokens);
    }
    
    size_t finalMemory = getCurrentMemoryUsage();
    
    // å†…å­˜å¢é•¿ä¸åº”è¶…è¿‡é˜ˆå€¼ï¼ˆä¾‹å¦‚10MBï¼‰
    EXPECT_LT(finalMemory - initialMemory, 10 * 1024 * 1024);
}
```

### 6.4 éªŒè¯æµ‹è¯•

#### 6.4.1 ç²¾åº¦éªŒè¯
``cpp
TEST(ValidationTest, CrossPlatformConsistency) {
    // éªŒè¯åœ¨ä¸åŒå¹³å°ä¸Šäº§ç”Ÿçš„ç»“æœä¸€è‡´æ€§
    CTokenizer tokenizer(ModelType::QWEN);
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    std::vector<std::string> testCases = {
        "Hello, world!",
        "æµ‹è¯•ä¸­æ–‡åˆ†è¯",
        "Test with numbers: 123456789",
        "Mixed: Hello ä¸–ç•Œ ğŸŒ emoji",
        "Special chars: !@#$%^&*()",
        "Long text with multiple sentences. This is sentence two. And this is three."
    };
    
    for (const auto& testCase : testCases) {
        auto tokens = tokenizer.encode(testCase);
        std::string decoded = tokenizer.decode(tokens);
        
        EXPECT_EQ(testCase, decoded) << "Mismatch for test case: " << testCase;
        
        // éªŒè¯è¯æ±‡è¡¨å¤§å°çš„ä¸€è‡´æ€§
        int vocabSize = tokenizer.getVocabSize();
        EXPECT_GT(vocabSize, 0);
    }
}

TEST(ValidationTest, ModelSpecificFeatures) {
    // éªŒè¯ç‰¹å®šæ¨¡å‹çš„ç‰¹å¾
    {
        // Qwenæ¨¡å‹ç‰¹æœ‰åŠŸèƒ½æµ‹è¯•
        QwenTokenizer qwenTokenizer;
        ASSERT_TRUE(qwenTokenizer.load("test_models/qwen/tokenizer.json"));
        
        // æµ‹è¯•Qwenç‰¹æœ‰çš„FIMå¤„ç†
        std::string code = "def function():\n    pass";
        auto tokens = qwenTokenizer.encode(code);
        EXPECT_FALSE(tokens.empty());
        
        std::string decoded = qwenTokenizer.decode(tokens);
        EXPECT_EQ(decoded, code);
    }
    
    {
        // DeepSeekæ¨¡å‹ç‰¹æœ‰åŠŸèƒ½æµ‹è¯•
        DeepSeekTokenizer deepseekTokenizer(ModelType::DEEPSEEK_CODER);
        ASSERT_TRUE(deepseekTokenizer.load("test_models/deepseek-coder/config.json"));
        
        // æµ‹è¯•DeepSeekç‰¹å®šçš„é¢„å¤„ç†
        std::string code = "class MyClass:\n    def method(self):\n        return True";
        auto tokens = deepseekTokenizer.encode(code);
        EXPECT_FALSE(tokens.empty());
        
        std::string decoded = deepseekTokenizer.decode(tokens);
        EXPECT_EQ(decoded, code);
    }
}
```

#### 6.4.2 å›å½’æµ‹è¯•
``cpp
TEST(RegressionTest, KnownIssues) {
    // é’ˆå¯¹å·²çŸ¥é—®é¢˜çš„å›å½’æµ‹è¯•
    CTokenizer tokenizer(ModelType::QWEN);
    ASSERT_TRUE(tokenizer.load("test_models/qwen/tokenizer.json"));
    
    // æµ‹è¯•å¯èƒ½å¯¼è‡´é—®é¢˜çš„ç‰¹å®šè¾“å…¥
    std::vector<std::string> problematicInputs = {
        "", // ç©ºå­—ç¬¦ä¸²
        " ", // å•ç©ºæ ¼
        "\n", // å˜æ¢è¡Œ
        "\t", // å˜åˆ¶è¡¨ç¬¦
        "\r\n", // Windowsæ¢è¡Œ
        std::string(1000, 'A'), // é•¿é‡å¤å­—ç¬¦ä¸²
        "A" + std::string(1000, 'B') + "C", // é•¿ä¸­é—´å­—ç¬¦ä¸²
        "!@#$%^&*()_+-=[]{}|;:,.<>?", // æ‰€æœ‰ç‰¹æ®Šå­—ç¬¦
        "Î±Î²Î³Î´ÎµÎ¶Î·Î¸Î¹ÎºÎ»Î¼Î½Î¾Î¿Ï€ÏÏƒÏ„Ï…Ï†Ï‡ÏˆÏ‰", // å¸Œè…Šå­—æ¯
        "ã‚ã„ã†ãˆãŠã‹ããã‘ã“", // æ—¥æ–‡å¹³å‡å
        "í•œêµ­ì–´ í…ŒìŠ¤íŠ¸", // éŸ©æ–‡
        "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", // é˜¿æ‹‰ä¼¯æ–‡
        "Ğ ÑƒÑÑĞºĞ¸Ğ¹", // ä¿„æ–‡
        " ğŸŒ âœ¨ ğŸš€ " // è¡¨æƒ…ç¬¦å·
    };
    
    for (const auto& input : problematicInputs) {
        try {
            auto tokens = tokenizer.encode(input);
            std::string decoded = tokenizer.decode(tokens);
            
            // å¯¹äºå¤§å¤šæ•°è¾“å…¥ï¼Œç¼–ç åå†è§£ç åº”è¯¥å¾—åˆ°ç›¸åŒçš„ç»“æœ
            EXPECT_EQ(decoded, input) << "Regression detected for input: " << input;
        } catch (const std::exception& e) {
            ADD_FAILURE() << "Exception thrown for input '" << input << "': " << e.what();
        }
    }
}
```

### 6.5 æµ‹è¯•æ‰§è¡Œç­–ç•¥

#### 6.5.1 æµ‹è¯•å±‚çº§
- **å•å…ƒæµ‹è¯•**: éªŒè¯å„ä¸ªç»„ä»¶çš„ç‹¬ç«‹åŠŸèƒ½
- **é›†æˆæµ‹è¯•**: éªŒè¯ç»„ä»¶é—´çš„åä½œ
- **æ€§èƒ½æµ‹è¯•**: éªŒè¯æ€§èƒ½æŒ‡æ ‡æ˜¯å¦è¾¾æ ‡
- **å‹åŠ›æµ‹è¯•**: éªŒè¯åœ¨æç«¯æ¡ä»¶ä¸‹çš„ç¨³å®šæ€§
- **å›å½’æµ‹è¯•**: é˜²æ­¢å¼•å…¥æ–°çš„bug

#### 6.5.2 æµ‹è¯•è¦†ç›–ç‡
- åŠŸèƒ½è¦†ç›–ç‡: ç¡®ä¿æ‰€æœ‰åŠŸèƒ½éƒ½ç»è¿‡æµ‹è¯•
- ä»£ç è¦†ç›–ç‡: ç›®æ ‡è¾¾åˆ°85%ä»¥ä¸Š
- æ•°æ®è¦†ç›–ç‡: æ¶µç›–å„ç§è¾“å…¥ç±»å‹å’Œè¾¹ç•Œæ¡ä»¶

#### 6.5.3 è‡ªåŠ¨åŒ–æµ‹è¯•
``bash
# å®Œæ•´æµ‹è¯•å¥—ä»¶æ‰§è¡Œ
./bin/tokenizer_tests --gtest_filter=* --verbose

# æ€§èƒ½æµ‹è¯•
./bin/tokenizer_benchmark --model=qwen --text=performance_test.txt --iterations=1000

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
gcovr --html --html-details -o coverage.html
```

```cpp
// æµ‹è¯•åˆå§‹åŒ–å’Œæ¸…ç†
class TokenizerTestEnvironment : public ::testing::Environment {
public:
    void SetUp() override {
        // å‡†å¤‡æµ‹è¯•ç¯å¢ƒ
        prepareTestModels();
        initializeGlobalResources();
    }
    
    void TearDown() override {
        // æ¸…ç†æµ‹è¯•ç¯å¢ƒ
        cleanupTestModels();
        releaseGlobalResources();
    }
    
private:
    void prepareTestModels() {
        // ä¸‹è½½æˆ–å¤åˆ¶æµ‹è¯•æ¨¡å‹æ–‡ä»¶
    }
    
    void initializeGlobalResources() {
        // åˆå§‹åŒ–å…¨å±€èµ„æº
    }
    
    void cleanupTestModels() {
        // æ¸…ç†æµ‹è¯•æ¨¡å‹æ–‡ä»¶
    }
    
    void releaseGlobalResources() {
        // é‡Šæ”¾å…¨å±€èµ„æº
    }
};

// æ³¨å†Œæµ‹è¯•ç¯å¢ƒ
::testing::AddGlobalTestEnvironment(new TokenizerTestEnvironment());
```

## 7. æ¼”è¿›è§„åˆ’

### 7.1 çŸ­æœŸç›®æ ‡ï¼ˆ1-2ä¸ªæœˆï¼‰
- å®ç°åŸºç¡€llama.cppåˆ†è¯å™¨æ”¯æŒ
- æ·»åŠ Qwenå’ŒDeepSeekæ¨¡å‹æ”¯æŒ
- å®Œæˆæ€§èƒ½åŸºå‡†æµ‹è¯•

### 7.2 ä¸­æœŸç›®æ ‡ï¼ˆ3-6ä¸ªæœˆï¼‰
- æ”¯æŒæ›´å¤šæ¨¡å‹æ ¼å¼ï¼ˆLlama3ã€Mixtralç­‰ï¼‰
- ä¼˜åŒ–æ‰¹å¤„ç†æ€§èƒ½
- æ·»åŠ é‡åŒ–æ”¯æŒ

### 7.3 é•¿æœŸç›®æ ‡ï¼ˆ6-12ä¸ªæœˆï¼‰
- åŠ¨æ€åˆ†è¯å™¨åŠ è½½
- è®­ç»ƒæ”¯æŒ
- ç¡¬ä»¶åŠ é€Ÿï¼ˆGPU/TPUï¼‰
- è‡ªé€‚åº”åˆ†è¯ç®—æ³•

## 8. æ€»ç»“

æœ¬æ–‡æ¡£æå‡ºäº†ä¸€ä¸ªç°ä»£åŒ–ã€å¯æ‰©å±•çš„åˆ†è¯å™¨è®¾è®¡æ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆåŸºäºllama.cppçš„å¼ºå¤§åˆ†è¯èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒäº†ä¸cLLMé¡¹ç›®çš„å…¼å®¹æ€§ã€‚é€šè¿‡ç»Ÿä¸€çš„æ¥å£è®¾è®¡å’Œæ¨¡å‹è‡ªåŠ¨æ£€æµ‹æœºåˆ¶ï¼Œè¯¥æ–¹æ¡ˆèƒ½å¤Ÿæœ‰æ•ˆæ”¯æŒQwenã€DeepSeekç­‰å¤šç§æ¨¡å‹ï¼Œä¸ºcLLMé¡¹ç›®æä¾›å¼ºå¤§çš„æ–‡æœ¬å¤„ç†èƒ½åŠ›ã€‚

è¯¥è®¾è®¡å……åˆ†è€ƒè™‘äº†æ€§èƒ½ã€å¯ç»´æŠ¤æ€§å’Œæ‰©å±•æ€§ï¼Œä¸ºcLLMé¡¹ç›®çš„æœªæ¥å‘å±•å¥ å®šäº†åšå®çš„åŸºç¡€ã€‚ç‰¹åˆ«åœ°ï¼Œè¯¦ç»†çš„æµ‹è¯•éªŒè¯æ–¹æ¡ˆç¡®ä¿äº†åˆ†è¯å™¨æ¨¡å—çš„å¯é æ€§ã€æ€§èƒ½å’Œç¨³å®šæ€§ï¼Œé€šè¿‡å¤šå±‚æ¬¡ã€å…¨æ–¹ä½çš„æµ‹è¯•è¦†ç›–ï¼Œæˆ‘ä»¬èƒ½å¤Ÿä¿è¯åˆ†è¯å™¨åœ¨å„ç§ä½¿ç”¨åœºæ™¯ä¸‹çš„æ­£ç¡®æ€§ï¼Œå¹¶æ»¡è¶³æ€§èƒ½è¦æ±‚.

## 9. å®ç°æ³¨æ„äº‹é¡¹

### 9.1 é€šç”¨åˆ†è¯å™¨é›†æˆè¦ç‚¹
- éœ€è¦æ­£ç¡®åˆå§‹åŒ–SentencePieceå¤„ç†å™¨
- ä¸åŒæ¨¡å‹ç±»å‹å¯¹åº”ä¸åŒçš„é¢„å¤„ç†é€»è¾‘
- æ³¨æ„å†…å­˜ç®¡ç†ï¼Œé¿å…å†…å­˜æ³„æ¼
- æ”¯æŒå¤šç§åˆ†è¯ç®—æ³•ï¼šSentencePieceã€BPEã€WordPieceç­‰

### 9.2 æ€§èƒ½ä¼˜åŒ–ç­–ç•¥
- ä½¿ç”¨ç¼“å­˜æœºåˆ¶é¿å…é‡å¤è®¡ç®—
- æ‰¹å¤„ç†æ“ä½œæå‡ååé‡
- å†…å­˜æ± ç®¡ç†å‡å°‘åˆ†é…å¼€é”€
- å¹¶è¡Œå¤„ç†æå‡æ•ˆç‡

### 9.3 çº¿ç¨‹å®‰å…¨è€ƒè™‘
- Tokenizerå®ä¾‹åº”æ”¯æŒå¤šçº¿ç¨‹è®¿é—®
- ä½¿ç”¨é€‚å½“çš„é”æœºåˆ¶ä¿æŠ¤å…±äº«èµ„æº
- è€ƒè™‘æ— é”æ•°æ®ç»“æ„æå‡æ€§èƒ½

### 9.4 é”™è¯¯å¤„ç†
- æ¨¡å‹åŠ è½½å¤±è´¥çš„å¤„ç†
- æ— æ•ˆè¾“å…¥çš„å¤„ç†
- å†…å­˜ä¸è¶³çš„å¤„ç†
- å¼‚å¸¸æƒ…å†µçš„æ¢å¤æœºåˆ¶

## 10. æ€»ç»“

æœ¬æ–‡æ¡£æå‡ºäº†ä¸€ä¸ªç°ä»£åŒ–ã€å¯æ‰©å±•çš„åˆ†è¯å™¨è®¾è®¡æ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆåŸºäºé€šç”¨åˆ†è¯åº“çš„å¼ºå¤§åˆ†è¯èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒäº†ä¸cLLMé¡¹ç›®çš„å…¼å®¹æ€§ã€‚é€šè¿‡ç»Ÿä¸€çš„æ¥å£è®¾è®¡å’Œæ¨¡å‹è‡ªåŠ¨æ£€æµ‹æœºåˆ¶ï¼Œè¯¥æ–¹æ¡ˆèƒ½å¤Ÿæœ‰æ•ˆæ”¯æŒQwenã€DeepSeekç­‰å¤šç§æ¨¡å‹ï¼Œä¸ºcLLMé¡¹ç›®æä¾›å¼ºå¤§çš„æ–‡æœ¬å¤„ç†èƒ½åŠ›ã€‚

è¯¥è®¾è®¡å……åˆ†è€ƒè™‘äº†æ€§èƒ½ã€å¯ç»´æŠ¤æ€§å’Œæ‰©å±•æ€§ï¼Œä¸ºcLLMé¡¹ç›®çš„æœªæ¥å‘å±•å¥ å®šäº†åšå®çš„åŸºç¡€ã€‚ç‰¹åˆ«åœ°ï¼Œè¯¦ç»†çš„æµ‹è¯•éªŒè¯æ–¹æ¡ˆç¡®ä¿äº†åˆ†è¯å™¨æ¨¡å—çš„å¯é æ€§ã€æ€§èƒ½å’Œç¨³å®šæ€§ï¼Œé€šè¿‡å¤šå±‚æ¬¡ã€å…¨æ–¹ä½çš„æµ‹è¯•è¦†ç›–ï¼Œæˆ‘ä»¬èƒ½å¤Ÿä¿è¯åˆ†è¯å™¨åœ¨å„ç§ä½¿ç”¨åœºæ™¯ä¸‹çš„æ­£ç¡®æ€§ï¼Œå¹¶æ»¡è¶³æ€§èƒ½è¦æ±‚.
