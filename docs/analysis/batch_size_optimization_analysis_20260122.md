# 批处理大小优化效果分析报告

**日期**: 2026-01-22  
**测试环境**: Apple M3 (10 GPU核心), macOS 15.0

---

## 1. 测试配置

### 1.1 基准配置（优化前）
```yaml
backend:
  llama_cpp:
    n_batch: 512          # 批处理大小
    n_threads: 8          # CPU线程数
    n_gpu_layers: 99       # GPU层数
    n_seq_max: 64         # 最大序列数
```

### 1.2 优化配置（优化后）
```yaml
backend:
  llama_cpp:
    n_batch: 1024         # 批处理大小（增加100%）
    n_threads: 8          # CPU线程数
    n_gpu_layers: 99       # GPU层数
    n_seq_max: 64         # 最大序列数
```

---

## 2. 性能对比

### 2.1 测试结果

| 指标 | 优化前 (n_batch=512) | 优化后 (n_batch=1024) | 变化 |
|--------|----------------------|-----------------------|------|
| **吞吐量** | 132.74 tokens/sec | 118.30 tokens/sec | **-10.9%** ⬇️ |
| **平均响应时间** | 8.59s | 9.67s | **+12.6%** ⬆️ |
| **最小响应时间** | 3.47s | 2.63s | -24.2% ⬇️ |
| **最大响应时间** | 14.02s | 17.37s | +23.9% ⬆️ |
| **平均tokens/sec** | 17.26 tokens/sec | 15.46 tokens/sec | -10.4% ⬇️ |
| **总测试时间** | 27.12s | 30.43s | +12.2% ⬆️ |

### 2.2 性能分析

#### 吞吐量下降原因分析

1. **批处理过大导致GPU利用率降低**
   - n_batch=1024可能超过了GPU的最优批处理大小
   - 较大的批处理可能导致GPU内存带宽压力增大
   - 单次处理时间增加，导致整体吞吐量下降

2. **响应时间增加**
   - 平均响应时间从8.59s增加到9.67s（+12.6%）
   - 最大响应时间从14.02s增加到17.37s（+23.9%）
   - 说明批处理大小增加后，单个请求的等待时间增加

3. **最小响应时间改善**
   - 最小响应时间从3.47s降低到2.63s（-24.2%）
   - 说明在某些情况下，较大的批处理确实可以提高单个请求的处理速度

---

## 3. 理论分析

### 3.1 批处理大小的影响

批处理大小对性能的影响是非线性的：

```
性能 = f(n_batch)
       ↑
       |        /\
       |       /  \
       |      /    \
       |     /      \
       |    /        \
       |   /          \
       |  /            \
       | /              \
       |/                \
       +-------------------> n_batch
        最优值
```

- **过小**: GPU利用率不足，kernel启动开销大
- **过大**: GPU内存带宽压力增大，单次处理时间增加
- **最优**: 在GPU利用率和处理时间之间取得平衡

### 3.2 Apple M3 GPU特性

Apple M3 GPU有以下特性：
- **10个GPU核心**: 适合中等大小的批处理
- **统一内存架构**: CPU和GPU共享内存，批处理过大可能导致内存带宽瓶颈
- **Metal优化**: Metal后端对批处理大小有特定的优化范围

---

## 4. 建议的优化策略

### 4.1 短期优化（立即实施）

#### 方案1: 恢复n_batch=512
**理由**: 
- n_batch=512已经是一个较好的平衡点
- 进一步增加批处理大小导致性能下降
- 保持当前配置可以获得稳定的性能

**预期效果**: 恢复到132.74 tokens/sec的吞吐量

#### 方案2: 测试n_batch=768
**理由**:
- 在512和1024之间寻找更优值
- 可能获得比512更好的性能

**预期效果**: 可能获得5-10%的性能提升

### 4.2 中期优化（1-2天）

#### 方案3: 动态批处理大小
**实现**:
```cpp
// 根据队列大小动态调整批处理大小
size_t dynamicBatchSize(size_t queueSize, size_t runningCount) {
    if (queueSize > 32) {
        return 1024;  // 高负载时使用更大的批处理
    } else if (queueSize > 16) {
        return 768;   // 中等负载
    } else {
        return 512;   // 低负载
    }
}
```

**预期效果**: 在不同负载下都能获得最优性能

### 4.3 长期优化（1周）

#### 方案4: 自动调优系统
**实现**:
- 自动测试不同的批处理大小
- 记录每个配置的性能指标
- 自动选择最优配置

**预期效果**: 无需手动调优，系统自动找到最优配置

---

## 5. 其他优化方向

由于批处理大小优化效果不佳，建议关注以下优化方向：

### 5.1 Metal后端优化
- **n_cb参数**: 虽然llama.cpp没有暴露这个参数，但可以通过环境变量控制
  ```bash
  export GGML_METAL_CONCURRENCY_DISABLE=0  # 启用并发
  export GGML_METAL_FUSION_DISABLE=0       # 启用操作融合
  ```

### 5.2 调度器优化
- **批处理累积策略**: 已经实现，效果良好
- **动态批处理大小**: 可以根据负载调整
- **优先级调度**: 优化请求调度顺序

### 5.3 系统级优化
- **NUMA优化**: 虽然Apple M3没有NUMA，但可以优化内存访问模式
- **CPU亲和性**: 将CPU线程绑定到特定核心
- **内存预分配**: 减少动态内存分配

---

## 6. 结论

### 6.1 主要发现

1. **n_batch=1024不适合当前配置**
   - 吞吐量下降10.9%
   - 响应时间增加12.6%
   - 不建议使用

2. **n_batch=512是较好的平衡点**
   - 吞吐量: 132.74 tokens/sec
   - 响应时间: 8.59s
   - 建议保持此配置

3. **批处理大小需要根据硬件特性调整**
   - Apple M3 GPU的最优批处理大小可能在512-768之间
   - 需要通过测试找到最优值

### 6.2 下一步行动

1. ✅ **恢复n_batch=512配置**
2. ⏳ **测试n_batch=768**（可选）
3. ⏳ **实现动态批处理大小**（中期）
4. ⏳ **关注其他优化方向**（Metal后端、调度器等）

### 6.3 最终建议

**立即行动**: 恢复n_batch=512配置，保持当前性能水平。

**中期规划**: 实现动态批处理大小，根据负载自动调整。

**长期规划**: 建立自动调优系统，无需手动干预即可找到最优配置。

---

## 7. 附录

### 7.1 测试脚本
已创建测试脚本 `scripts/test_batch_sizes.sh`，可以测试多个批处理大小：

```bash
./scripts/test_batch_sizes.sh
```

### 7.2 相关文档
- [GPU使用情况分析与多核GPU优化报告](gpu_multi_core_optimization_report_20260122.md)
- [性能测试报告](cllm_performance_test_report_20260122.md)
