# cLLM 并发性能分析报告

## 问题概述

根据 `docs/testing/cllm_vs_ollama_comparison_report_v3.md` 的测试结果，cLLM 在并发测试中表现明显不如 Ollama：

- **成功率**: 95.0% vs 100% (Ollama 领先)
- **平均响应时间**: 6.57s vs 1.80s (Ollama 快 72.6%)
- **吞吐量**: 35.73 t/s vs 102.53 t/s (Ollama 高 186.9%)
- **失败请求**: 8 个请求生成 0 tokens

## 根本原因分析

### 1. **序列ID池限制 (n_seq_max=8)**

**问题**：
- 配置中 `n_seq_max: 8`，限制了 llama.cpp 最多只能同时处理 8 个序列
- 在并发测试时（5并发，160个请求），当同时处理的请求超过 8 个时，序列ID池会耗尽
- 新请求无法分配序列ID，导致失败或长时间等待

**证据**：
```yaml
# config/config.yaml
backend:
  llama_cpp:
    n_seq_max: 8  # 这是关键瓶颈！
```

**日志证据**：
```
[2026-01-19 18:18:33.591] [info] [LlamaCppBackend] Context params: n_ctx=2048, n_batch=512, n_threads=8, n_seq_max=8
[2026-01-19 18:18:33.839] [info] [LlamaCppBackend] Sequence ID pool initialized: 8 available IDs
```

**影响**：
- 当有超过 8 个请求同时处理时，新请求无法立即分配序列ID
- 请求必须在队列中等待，直到有序列ID被释放
- 这导致响应时间大幅增加（从 1.26s 增加到 6.57s）

### 2. **批处理大小受限**

**问题**：
- 虽然配置了 `max_batch_size: 8`，但由于 `n_seq_max=8` 的限制，实际批处理大小被限制在 2-3 个请求
- 从日志可以看到，并发测试时批处理大小只有 2-3 个请求，远低于配置的 8

**日志证据**：
```
[2026-01-19 18:35:35.288] [info] Starting batch processing for 2 requests (filtered from 2 total)
[2026-01-19 18:35:37.548] [info] Starting batch processing for 3 requests (filtered from 3 total)
```

**影响**：
- 批处理效率低下，无法充分利用 GPU/CPU 资源
- 吞吐量大幅下降（从顺序测试的 39.76 t/s 下降到并发测试的 35.73 t/s）

### 3. **顺序处理而非并行处理**

**问题**：
- 从日志可以看到，批处理是顺序执行的，每个批处理完成后才开始下一个
- 没有真正的并行处理，导致高并发时请求需要等待更长时间

**日志证据**：
- 每个批处理都是独立的，按顺序执行
- 没有看到多个批处理同时处理的情况

**影响**：
- 在高并发场景下，请求排队等待时间大幅增加
- 总测试时间从顺序测试的 201.20s 增加到并发测试的 212.72s

### 4. **序列ID分配失败导致请求失败**

**问题**：
- 当序列ID池耗尽时，新请求无法分配序列ID
- 这导致 8 个请求生成 0 tokens（失败）

**代码证据**：
```cpp
// src/inference/llama_cpp_backend.cpp:444
seqId = allocateSequenceId(requestId);
if (seqId == -1) {
    throw std::runtime_error(
        "LlamaCppBackend::forwardBatch: failed to allocate seq_id for request " + 
        std::to_string(requestId) + " (pool exhausted)"
    );
}
```

**影响**：
- 5% 的请求失败（8/160）
- 失败请求的响应时间与成功请求相当（7.23s - 7.37s），说明请求已经处理但无法完成

## 对比 Ollama 的优势

### Ollama 的并发处理策略

1. **更大的序列数限制**：Ollama 可能使用了更大的 `n_seq_max` 值，或者有更好的序列ID管理策略
2. **更好的批处理调度**：Ollama 可能实现了更高效的批处理调度，能够更好地利用资源
3. **更快的序列ID回收**：Ollama 可能更快地回收和重用序列ID

## 解决方案建议

### 1. **增加 n_seq_max 配置**

**短期方案**：
```yaml
backend:
  llama_cpp:
    n_seq_max: 32  # 从 8 增加到 32，支持更多并发请求
```

**注意事项**：
- 增加 `n_seq_max` 会增加内存使用
- 需要根据硬件资源（GPU 内存、系统内存）调整
- 建议逐步增加，观察内存使用情况

### 2. **优化序列ID管理**

**改进方向**：
- 实现序列ID的快速回收机制
- 在请求完成时立即释放序列ID
- 避免序列ID泄漏

**代码位置**：
- `src/inference/llama_cpp_backend.cpp` 中的 `releaseSequenceId()` 函数
- 确保在请求完成/失败时立即调用

### 3. **优化批处理调度**

**改进方向**：
- 实现更智能的批处理形成策略
- 考虑序列ID可用性，避免形成无法处理的批处理
- 实现批处理的并行处理（如果硬件支持）

### 4. **增加请求队列管理**

**改进方向**：
- 在序列ID池耗尽时，将请求放入等待队列
- 当序列ID可用时，立即处理等待队列中的请求
- 避免请求因序列ID不足而失败

### 5. **监控和告警**

**改进方向**：
- 添加序列ID池使用率监控
- 当序列ID池使用率超过阈值时，记录警告日志
- 帮助识别并发瓶颈

## 性能优化优先级

### 高优先级（立即实施）

1. **增加 n_seq_max**：从 8 增加到 32 或更高
   - 预期效果：支持更多并发请求，减少失败率
   - 风险：内存使用增加

2. **优化序列ID回收**：确保请求完成时立即释放序列ID
   - 预期效果：提高序列ID利用率
   - 风险：低

### 中优先级（短期实施）

3. **改进批处理调度**：考虑序列ID可用性
   - 预期效果：提高批处理效率
   - 风险：中等

4. **添加请求队列管理**：序列ID耗尽时的等待机制
   - 预期效果：减少请求失败率
   - 风险：低

### 低优先级（长期优化）

5. **实现并行批处理**：如果硬件支持
   - 预期效果：进一步提高吞吐量
   - 风险：高（需要大量重构）

## 预期改进效果

实施高优先级优化后，预期：

- **成功率**: 从 95.0% 提升到 99%+
- **平均响应时间**: 从 6.57s 降低到 2-3s
- **吞吐量**: 从 35.73 t/s 提升到 60-80 t/s
- **失败请求**: 从 8 个减少到 0-1 个

## 测试验证

建议在实施优化后，重新运行并发测试：

```bash
python3 tools/cllm_optimized_benchmark.py \
  --server-url http://localhost:18085 \
  --test-type concurrent \
  --requests 160 \
  --concurrency 5 \
  --max-tokens 50
```

对比优化前后的性能指标，验证改进效果。

## 结论

cLLM 在并发测试中表现不佳的主要原因是 **`n_seq_max=8` 的限制**，这导致：

1. 序列ID池快速耗尽
2. 新请求无法立即处理，必须等待
3. 批处理大小受限，无法充分利用资源
4. 部分请求因序列ID分配失败而失败

通过增加 `n_seq_max` 和优化序列ID管理，可以显著改善并发性能，接近或超越 Ollama 的表现。
