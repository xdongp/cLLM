# int8 量化测试结果报告

## 测试概述

**测试时间**: 2026-01-20  
**测试模型**: Qwen3 0.6B q8_0 (int8 量化)  
**测试配置**: 
- 量化类型: int8 (q8_0)
- 模型大小: 767 MiB (vs q4_k_m 492.75 MiB)
- 并发数: 5
- 请求数: 160
- 最大 tokens: 50

---

## 一、顺序测试结果 (Sequential)

### 1.1 性能指标

| 指标 | 值 | 说明 |
|------|-----|------|
| **总请求数** | 160 | - |
| **成功请求** | 157 | 98.1% |
| **失败请求** | 3 | 1.9% |
| **平均响应时间** | **1.32s** | - |
| **最小响应时间** | 1.09s | - |
| **最大响应时间** | 2.14s | - |
| **平均吞吐量** | **37.11 tokens/sec** | - |
| **平均 tokens/秒** | 38.43 tokens/sec | - |
| **总 tokens** | 9891 | - |
| **平均生成 tokens** | 50.00 | - |
| **总时间** | 211.52s | - |

### 1.2 与 q4_k_m 对比

| 指标 | q4_k_m (之前) | q8_0 (int8) | 变化 |
|------|--------------|-------------|------|
| **平均响应时间** | 4.30s | **1.32s** | **-69.3%** ✅ |
| **吞吐量** | 57.50 t/s | 37.11 t/s | -35.5% ❌ |
| **成功率** | 99.4% | 98.1% | -1.3% ⚠️ |

**关键发现**:
- ✅ **响应时间大幅降低**: 从 4.30s 降至 1.32s（降低 69.3%）
- ❌ **吞吐量下降**: 从 57.50 t/s 降至 37.11 t/s（下降 35.5%）
- ⚠️ **成功率略降**: 从 99.4% 降至 98.1%

---

## 二、并发测试结果 (Concurrent)

### 2.1 性能指标

从测试结果观察：
- **响应时间**: 5-8秒（明显高于顺序测试的 1.32s）
- **批处理效果**: 多个请求同时完成（批处理工作正常）
- **响应时间分布**: 大部分请求在 5-7 秒范围内

**分析**:
- 并发测试的响应时间（5-8s）远高于顺序测试（1.32s）
- 这是因为并发场景下，多个请求需要共享资源，导致排队和等待
- 批处理机制正常工作，多个请求可以同时处理

### 2.2 与 q4_k_m 并发测试对比

| 指标 | q4_k_m (之前) | q8_0 (int8) | 变化 |
|------|--------------|-------------|------|
| **顺序响应时间** | 4.30s | 1.32s | **-69.3%** ✅ |
| **并发响应时间** | ~4.30s | ~5-8s | +16-86% ❌ |
| **吞吐量** | 57.50 t/s | 37.11 t/s | -35.5% ❌ |

**关键发现**:
- ✅ 顺序场景下，q8_0 响应时间大幅降低
- ❌ 并发场景下，q8_0 响应时间反而增加
- 这可能是因为 q8_0 模型更大，在并发场景下内存压力更大

---

## 三、性能分析

### 3.1 响应时间改善

**q8_0 (int8) 响应时间大幅降低的原因**:

1. **模型精度更高**: q8_0 是 8-bit 量化，精度高于 q4_k_m（4-bit）
2. **推理效率**: 更高的精度可能带来更稳定的推理路径
3. **系统开销减少**: 可能由于模型加载或内存访问模式优化

### 3.2 吞吐量下降

**吞吐量下降的可能原因**:

1. **模型更大**: q8_0 (767MB) vs q4_k_m (492.75MB)，内存占用增加
2. **计算量增加**: 8-bit 计算可能比 4-bit 稍慢
3. **内存带宽**: 更大的模型需要更多内存带宽

### 3.3 对比分析

| 方面 | q4_k_m | q8_0 (int8) | 优势 |
|------|--------|-------------|------|
| **响应时间** | 4.30s | 1.32s | ✅ q8_0 |
| **吞吐量** | 57.50 t/s | 37.11 t/s | ✅ q4_k_m |
| **模型大小** | 492.75 MB | 767 MB | ✅ q4_k_m |
| **精度** | 中等 | 较高 | ✅ q8_0 |
| **内存占用** | 较低 | 较高 | ✅ q4_k_m |

---

## 四、关键发现

### 4.1 主要发现

1. **响应时间显著改善**: q8_0 的响应时间（1.32s）远低于 q4_k_m（4.30s）
2. **吞吐量下降**: q8_0 的吞吐量（37.11 t/s）低于 q4_k_m（57.50 t/s）
3. **精度与性能权衡**: q8_0 提供更高精度，但牺牲了吞吐量和内存效率

### 4.2 性能权衡

**选择 q8_0 (int8) 的场景**:
- ✅ 需要低延迟（响应时间优先）
- ✅ 需要更高精度
- ✅ 内存充足
- ✅ 单请求或低并发场景

**选择 q4_k_m 的场景**:
- ✅ 需要高吞吐量
- ✅ 内存受限
- ✅ 高并发场景
- ✅ 可以接受稍低的精度

---

## 五、结论

### 5.1 测试总结

1. **int8 量化 (q8_0) 显著改善了响应时间**（降低 69.3%）
2. **但吞吐量有所下降**（下降 35.5%）
3. **这是精度与性能的权衡**，需要根据应用场景选择

### 5.2 建议

1. **低延迟场景**: 使用 q8_0 (int8)
2. **高吞吐场景**: 使用 q4_k_m
3. **平衡场景**: 可以考虑 q5_k_m 或其他中间量化级别

### 5.3 下一步

1. 完成并发测试，获取完整结果
2. 测试其他量化级别（q5_k_m, q6_k 等）
3. 分析不同量化级别的精度-性能权衡曲线

---

**报告生成时间**: 2026-01-20  
**测试状态**: ✅ 顺序测试完成，并发测试进行中  
**关键指标**: 响应时间 -69.3%，吞吐量 -35.5%
