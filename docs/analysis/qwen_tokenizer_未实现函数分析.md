# QwenTokenizer æœªå®ç°å‡½æ•°åˆ†ææŠ¥å‘Š

## ğŸ“‹ æ¦‚è¿°

æœ¬æŠ¥å‘Šè¯¦ç»†åˆ†æ `qwen_tokenizer.cpp` ä¸­å°šæœªå®Œå…¨å®ç°çš„å‡½æ•°ï¼ŒåŒ…æ‹¬å®ƒä»¬çš„é¢„æœŸåŠŸèƒ½ã€å‚æ•°åˆ—è¡¨ã€åœ¨æ¶æ„ä¸­çš„ä½œç”¨ä»¥åŠå®ç°å»ºè®®ã€‚

---

## ğŸ” æœªå®ç°å‡½æ•°æ¸…å•

### 1. **applyQwenPreprocessing()**

#### ğŸ“ å‡½æ•°ç­¾å
```cpp
std::string QwenTokenizer::applyQwenPreprocessing(const std::string& text)
```

#### ğŸ¯ é¢„æœŸåŠŸèƒ½
å¯¹è¾“å…¥æ–‡æœ¬åº”ç”¨ Qwen2 æ¨¡å‹ç‰¹å®šçš„é¢„å¤„ç†é€»è¾‘ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œæ–‡æœ¬åˆ†æ®µå’Œè§„èŒƒåŒ–ã€‚

#### ğŸ“Œ å‚æ•°åˆ—è¡¨
- **text**: `const std::string&` - éœ€è¦é¢„å¤„ç†çš„åŸå§‹æ–‡æœ¬

#### ğŸ”„ è¿”å›å€¼
- `std::string` - ç»è¿‡é¢„å¤„ç†åçš„æ–‡æœ¬

#### ğŸ—ï¸ åœ¨æ¶æ„ä¸­çš„ä½œç”¨
- **ä½ç½®**: åœ¨ `encode()` è°ƒç”¨é“¾ä¸­ï¼Œä½œä¸ºæ–‡æœ¬é¢„å¤„ç†çš„ç¬¬ä¸€æ­¥
- **è°ƒç”¨é¡ºåº**: `encode()` â†’ `applyQwenPreprocessing()` â†’ SentencePiece ç¼–ç 
- **ä½œç”¨**: ç¡®ä¿æ–‡æœ¬æ ¼å¼ç¬¦åˆ Qwen2 æ¨¡å‹çš„è®­ç»ƒæ•°æ®æ ¼å¼

#### ğŸ“ è®¾è®¡æ–‡æ¡£è¦æ±‚

æ ¹æ® `docs/åˆ†è¯å™¨è®¾è®¡.md` å’Œ `docs/modules/CTokenizeråˆ†è¯è®¾è®¡.md`ï¼ŒQwen2 çš„é¢„å¤„ç†åº”å®ç°ä»¥ä¸‹æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ï¼š

```cpp
"(?:'[sS]|'[tT]|'[rR][eE]|'[vV][eE]|'[mM]|'[lL][lL]|'[dD])|"
"[^\\r\\n\\p{L}\\p{N}]?\\p{L}+|"
"\\p{N}|"
" ?[^\\s\\p{L}\\p{N}]+[\\r\\n]*|"
"\\s*[\\r\\n]+|"
"\\s+(?!\\S)|"
"\\s+"
```

**æ­£åˆ™è¡¨è¾¾å¼å«ä¹‰è§£æ**ï¼š
1. `(?:'[sS]|'[tT]|'[rR][eE]|'[vV][eE]|'[mM]|'[lL][lL]|'[dD])` - åŒ¹é…è‹±è¯­ç¼©å†™ï¼ˆå¦‚ 's, 't, 're, 've, 'm, 'll, 'dï¼‰
2. `[^\r\n\p{L}\p{N}]?\p{L}+` - åŒ¹é…å­—æ¯åºåˆ—ï¼ˆå¯é€‰çš„éå­—æ¯éæ•°å­—å‰ç¼€ï¼‰
3. `\p{N}` - åŒ¹é…å•ä¸ªæ•°å­—
4. ` ?[^\s\p{L}\p{N}]+[\r\n]*` - åŒ¹é…æ ‡ç‚¹ç¬¦å·å’Œç‰¹æ®Šå­—ç¬¦ï¼ˆå¯é€‰çš„å‰å¯¼ç©ºæ ¼å’Œåç¼€æ¢è¡Œï¼‰
5. `\s*[\r\n]+` - åŒ¹é…æ¢è¡Œç¬¦ï¼ˆå¯é€‰çš„å‰å¯¼ç©ºæ ¼ï¼‰
6. `\s+(?!\S)` - åŒ¹é…å°¾éšç©ºç™½
7. `\s+` - åŒ¹é…å…¶ä»–ç©ºç™½å­—ç¬¦

#### âš ï¸ å½“å‰å®ç°çŠ¶æ€
```cpp
std::string QwenTokenizer::applyQwenPreprocessing(const std::string& text) {
    // å½“å‰ä»…è¿”å›åŸå§‹æ–‡æœ¬ï¼Œæ²¡æœ‰ä»»ä½•é¢„å¤„ç†
    return text;
}
```

#### ğŸ’¥ å½±å“è¯„ä¼°
- **ä¸¥é‡ç¨‹åº¦**: ğŸ”´ **é«˜** - æ ¸å¿ƒåŠŸèƒ½ç¼ºå¤±
- **å½±å“èŒƒå›´**:
  - âŒ æ— æ³•æ­£ç¡®å¤„ç†è‹±è¯­ç¼©å†™ï¼ˆå¦‚ "don't" â†’ "do" + "n't"ï¼‰
  - âŒ æ•°å­—å’Œæ ‡ç‚¹çš„åˆ†è¯ä¸ç¬¦åˆ Qwen2 è®­ç»ƒæ ¼å¼
  - âŒ ç©ºç™½å­—ç¬¦å¤„ç†ä¸å½“ï¼Œå½±å“tokenè¾¹ç•Œ
  - âŒ ç¼–ç ç»“æœä¸ Qwen2 å®˜æ–¹ä¸ä¸€è‡´ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸‹é™

#### âœ… å»ºè®®å®ç°æ–¹æ¡ˆ

**æ–¹æ¡ˆ 1: åŸºäº std::regex å®ç°ï¼ˆæ¨èï¼‰**
```cpp
std::string QwenTokenizer::applyQwenPreprocessing(const std::string& text) {
    if (text.empty()) {
        return text;
    }
    
    std::string result;
    result.reserve(text.size());
    
    // Qwen2 æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
    std::regex pattern(
        R"((?:'[sS]|'[tT]|'[rR][eE]|'[vV][eE]|'[mM]|'[lL][lL]|'[dD])|)"
        R"([^\r\n\p{L}\p{N}]?\p{L}+|)"
        R"(\p{N}|)"
        R"( ?[^\s\p{L}\p{N}]+[\r\n]*|)"
        R"(\s*[\r\n]+|)"
        R"(\s+(?!\S)|)"
        R"(\s+)"
    );
    
    std::sregex_iterator iter(text.begin(), text.end(), pattern);
    std::sregex_iterator end;
    
    for (; iter != end; ++iter) {
        result += iter->str();
    }
    
    return result.empty() ? text : result;
}
```

**ä¼˜ç‚¹**: ä»£ç ç®€æ´ï¼Œç¬¦åˆC++æ ‡å‡†ï¼Œæ˜“äºç»´æŠ¤
**ç¼ºç‚¹**: C++ std::regex å¯¹ Unicode å±æ€§ç±»ï¼ˆ`\p{L}`, `\p{N}`ï¼‰æ”¯æŒæœ‰é™

**æ–¹æ¡ˆ 2: ä½¿ç”¨ RE2 æˆ– PCRE2 åº“**
```cpp
// éœ€è¦æ·»åŠ ä¾èµ–: RE2 æˆ– PCRE2
#include <re2/re2.h>

std::string QwenTokenizer::applyQwenPreprocessing(const std::string& text) {
    if (text.empty()) {
        return text;
    }
    
    static const RE2 pattern(
        "(?:'[sS]|'[tT]|'[rR][eE]|'[vV][eE]|'[mM]|'[lL][lL]|'[dD])|"
        "[^\\r\\n\\p{L}\\p{N}]?\\p{L}+|"
        "\\p{N}|"
        " ?[^\\s\\p{L}\\p{N}]+[\\r\\n]*|"
        "\\s*[\\r\\n]+|"
        "\\s+(?!\\S)|"
        "\\s+"
    );
    
    std::string result;
    re2::StringPiece input(text);
    re2::StringPiece match;
    
    while (RE2::FindAndConsume(&input, pattern, &match)) {
        result += match.as_string();
    }
    
    return result.empty() ? text : result;
}
```

**ä¼˜ç‚¹**: å®Œæ•´çš„ Unicode æ”¯æŒï¼Œæ€§èƒ½ä¼˜ç§€
**ç¼ºç‚¹**: å¼•å…¥å¤–éƒ¨ä¾èµ–

**æ–¹æ¡ˆ 3: æ‰‹åŠ¨å®ç°ï¼ˆæœ€ä¿é™©ï¼‰**
```cpp
std::string QwenTokenizer::applyQwenPreprocessing(const std::string& text) {
    if (text.empty()) {
        return text;
    }
    
    std::string result;
    result.reserve(text.size());
    size_t pos = 0;
    
    while (pos < text.size()) {
        // 1. æ£€æŸ¥è‹±è¯­ç¼©å†™
        if (text[pos] == '\'' && pos + 1 < text.size()) {
            char next = text[pos + 1];
            if (next == 's' || next == 'S' || next == 't' || next == 'T' ||
                next == 'm' || next == 'M' || next == 'd' || next == 'D') {
                result += text[pos];
                result += text[pos + 1];
                pos += 2;
                continue;
            }
            // æ£€æŸ¥ 're, 've, 'll
            if (pos + 2 < text.size()) {
                std::string two_char = text.substr(pos + 1, 2);
                if (two_char == "re" || two_char == "RE" ||
                    two_char == "ve" || two_char == "VE" ||
                    two_char == "ll" || two_char == "LL") {
                    result += text.substr(pos, 3);
                    pos += 3;
                    continue;
                }
            }
        }
        
        // 2. å­—æ¯åºåˆ—
        if (std::isalpha(static_cast<unsigned char>(text[pos]))) {
            size_t start = pos;
            while (pos < text.size() && std::isalpha(static_cast<unsigned char>(text[pos]))) {
                pos++;
            }
            result += text.substr(start, pos - start);
            continue;
        }
        
        // 3. æ•°å­—
        if (std::isdigit(static_cast<unsigned char>(text[pos]))) {
            result += text[pos];
            pos++;
            continue;
        }
        
        // 4. æ¢è¡Œç¬¦
        if (text[pos] == '\r' || text[pos] == '\n') {
            size_t start = pos;
            while (pos < text.size() && (text[pos] == '\r' || text[pos] == '\n' || text[pos] == ' ')) {
                pos++;
            }
            result += text.substr(start, pos - start);
            continue;
        }
        
        // 5. ç©ºç™½å­—ç¬¦
        if (std::isspace(static_cast<unsigned char>(text[pos]))) {
            size_t start = pos;
            while (pos < text.size() && std::isspace(static_cast<unsigned char>(text[pos]))) {
                pos++;
            }
            result += text.substr(start, pos - start);
            continue;
        }
        
        // 6. å…¶ä»–å­—ç¬¦ï¼ˆæ ‡ç‚¹ç­‰ï¼‰
        result += text[pos];
        pos++;
    }
    
    return result;
}
```

**ä¼˜ç‚¹**: æ— å¤–éƒ¨ä¾èµ–ï¼Œè¡Œä¸ºå¯æ§ï¼Œè°ƒè¯•æ–¹ä¾¿
**ç¼ºç‚¹**: ä»£ç è¾ƒé•¿ï¼Œéœ€è¦ä»”ç»†å¤„ç†Unicodeå­—ç¬¦

---

### 2. **encodeWithFim()** âœ… å·²éƒ¨åˆ†å®ç°

#### ğŸ“ å‡½æ•°ç­¾å
```cpp
std::vector<llama_token> QwenTokenizer::encodeWithFim(const std::string& text, bool addSpecialTokens)
```

#### ğŸ¯ é¢„æœŸåŠŸèƒ½
å®ç° Qwen æ¨¡å‹çš„ **FIMï¼ˆFill-in-the-Middleï¼‰** åŠŸèƒ½ï¼Œç”¨äºä»£ç è¡¥å…¨åœºæ™¯ã€‚å°†æ–‡æœ¬æŒ‰ç…§ FIM æ ¼å¼è¿›è¡Œç¼–ç ï¼Œæ”¯æŒå‰ç¼€ã€ä¸­ç¼€ã€åç¼€çš„åˆ†ç¦»å¤„ç†ã€‚

#### ğŸ“Œ å‚æ•°åˆ—è¡¨
- **text**: `const std::string&` - åŒ…å« FIM æ ‡è®°çš„æ–‡æœ¬
- **addSpecialTokens**: `bool` - æ˜¯å¦æ·»åŠ ç‰¹æ®Štokenï¼ˆBOS/EOSï¼‰

#### ğŸ”„ è¿”å›å€¼
- `std::vector<llama_token>` - FIM æ ¼å¼çš„ token åºåˆ—

#### ğŸ—ï¸ åœ¨æ¶æ„ä¸­çš„ä½œç”¨
- **ä½ç½®**: `encode()` çš„åˆ†æ”¯è·¯å¾„ï¼Œä¸“é—¨å¤„ç†ä»£ç è¡¥å…¨åœºæ™¯
- **è°ƒç”¨é“¾**: `encode()` â†’ `needsFimProcessing()` â†’ `encodeWithFim()`
- **åº”ç”¨åœºæ™¯**: IDE ä»£ç è¡¥å…¨ã€ä»£ç ç”Ÿæˆä»»åŠ¡

#### ğŸ“ FIM æ ¼å¼è¯´æ˜

æ ¹æ®è®¾è®¡æ–‡æ¡£ï¼ŒQwen çš„ FIM ç‰¹æ®Š tokensï¼š
- `<|fim_begin|>` - FIM åºåˆ—å¼€å§‹
- `<|fim_pre|>` - å‰ç¼€æ ‡è®°ï¼ˆå…‰æ ‡å‰çš„ä»£ç ï¼‰
- `<|fim_suf|>` - åç¼€æ ‡è®°ï¼ˆå…‰æ ‡åçš„ä»£ç ï¼‰
- `<|fim_end|>` - FIM åºåˆ—ç»“æŸ
- `<|fim_pad|>` - å¡«å……æ ‡è®°
- ` `` ` - ç®€åŒ–çš„ FIM æ ‡è®°ï¼ˆåŒåå¼•å·ï¼‰

**FIM æ ¼å¼ç¤ºä¾‹**ï¼š
```python
# è¾“å…¥æ–‡æœ¬
"<|fim_pre|>def add(a, b):\n    return <|fim_suf|>\n\nprint(add(1, 2))<|fim_end|>"

# æœŸæœ›çš„ token åºåˆ—
[fim_pre_token, tokens_of("def add(a, b):\n    return "), 
 fim_suf_token, tokens_of("\n\nprint(add(1, 2))"), 
 fim_end_token]
```

#### âš ï¸ å½“å‰å®ç°çŠ¶æ€
```cpp
std::vector<llama_token> QwenTokenizer::encodeWithFim(const std::string& text, bool addSpecialTokens) {
    // å·²å®ç°åŸºç¡€é€»è¾‘ï¼Œä½†å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
    // 1. FIM token çš„è·å–æ–¹å¼ tokenToId() å¯èƒ½è¿”å› unknown token
    // 2. æ²¡æœ‰éªŒè¯ FIM token æ˜¯å¦å­˜åœ¨äºè¯æ±‡è¡¨ä¸­
    // 3. é”™è¯¯å¤„ç†ä¸å®Œå–„
    // 4. ä¸æ”¯æŒç®€åŒ–çš„ `` æ ‡è®°æ ¼å¼
}
```

#### ğŸ’¥ å½±å“è¯„ä¼°
- **ä¸¥é‡ç¨‹åº¦**: ğŸŸ¡ **ä¸­ç­‰** - éƒ¨åˆ†åŠŸèƒ½å¯ç”¨ï¼Œä½†ä¸å®Œå–„
- **å½±å“èŒƒå›´**:
  - âœ… åŸºæœ¬çš„ FIM å¤„ç†å¯ä»¥å·¥ä½œ
  - âš ï¸ å¦‚æœæ¨¡å‹è¯æ±‡è¡¨ä¸­ç¼ºå°‘ FIM tokensï¼Œä¼šäº§ç”Ÿé”™è¯¯ç»“æœ
  - âš ï¸ ä¸æ”¯æŒ ` `` ` ç®€åŒ–æ ¼å¼ï¼Œä¸æŸäº› Qwen ç‰ˆæœ¬ä¸å…¼å®¹
  - âŒ é”™è¯¯æƒ…å†µä¸‹çš„é™çº§å¤„ç†ä¸å½“

#### âœ… æ”¹è¿›å»ºè®®

```cpp
std::vector<llama_token> QwenTokenizer::encodeWithFim(const std::string& text, bool addSpecialTokens) {
    // æŸ¥æ‰¾ FIM æ ‡è®°
    std::string fim_pre = "<|fim_pre|>";
    std::string fim_suf = "<|fim_suf|>";
    std::string fim_end = "<|fim_end|>";
    
    // æ£€æŸ¥æ–‡æœ¬ä¸­æ˜¯å¦åŒ…å«å®Œæ•´çš„ FIM æ ‡è®°
    size_t pre_pos = text.find(fim_pre);
    size_t suf_pos = text.find(fim_suf);
    size_t end_pos = text.find(fim_end);
    
    // éªŒè¯ FIM æ ¼å¼å®Œæ•´æ€§
    if (pre_pos == std::string::npos || suf_pos == std::string::npos || end_pos == std::string::npos) {
        // æ ¼å¼ä¸å®Œæ•´ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯ç®€åŒ–çš„ `` æ ¼å¼
        if (text.find("``") != std::string::npos) {
            return encodeSimpleFim(text, addSpecialTokens);
        }
        // é™çº§åˆ°æ™®é€šç¼–ç 
        return SentencePieceTokenizer::encode(text, addSpecialTokens);
    }
    
    // éªŒè¯ FIM token é¡ºåºæ­£ç¡®
    if (!(pre_pos < suf_pos && suf_pos < end_pos)) {
        // FIM æ ‡è®°é¡ºåºé”™è¯¯ï¼Œé™çº§åˆ°æ™®é€šç¼–ç 
        return SentencePieceTokenizer::encode(text, addSpecialTokens);
    }
    
    // æå–å„éƒ¨åˆ†
    std::string prefix_text = text.substr(0, pre_pos);
    std::string middle_text = text.substr(pre_pos + fim_pre.length(), 
                                          suf_pos - (pre_pos + fim_pre.length()));
    std::string suffix_text = text.substr(suf_pos + fim_suf.length(), 
                                          end_pos - (suf_pos + fim_suf.length()));
    
    // è·å– FIM ç‰¹æ®Š tokensï¼ˆå¸¦éªŒè¯ï¼‰
    llama_token fim_pre_token = tokenToId(fim_pre);
    llama_token fim_suf_token = tokenToId(fim_suf);
    llama_token fim_end_token = tokenToId(fim_end);
    
    // éªŒè¯ FIM tokens æ˜¯å¦æœ‰æ•ˆ
    llama_token unk_token = tokenToId("<unk>");
    if (fim_pre_token == unk_token || fim_suf_token == unk_token || fim_end_token == unk_token) {
        // FIM tokens ä¸å­˜åœ¨ï¼Œé™çº§åˆ°æ™®é€šç¼–ç 
        return SentencePieceTokenizer::encode(text, addSpecialTokens);
    }
    
    // åˆ†åˆ«ç¼–ç å„éƒ¨åˆ†
    std::vector<llama_token> result;
    
    // å‰ç¼€éƒ¨åˆ†
    if (!prefix_text.empty()) {
        auto prefix_tokens = SentencePieceTokenizer::encode(prefix_text, addSpecialTokens);
        result.insert(result.end(), prefix_tokens.begin(), prefix_tokens.end());
    }
    
    // FIM æ ¼å¼: [fim_pre] middle [fim_suf] suffix [fim_end]
    result.push_back(fim_pre_token);
    
    // ä¸­é—´éƒ¨åˆ†ï¼ˆè¦å¡«å……çš„å†…å®¹ï¼‰
    if (!middle_text.empty()) {
        auto middle_tokens = SentencePieceTokenizer::encode(middle_text, false);
        result.insert(result.end(), middle_tokens.begin(), middle_tokens.end());
    }
    
    result.push_back(fim_suf_token);
    
    // åç¼€éƒ¨åˆ†
    if (!suffix_text.empty()) {
        auto suffix_tokens = SentencePieceTokenizer::encode(suffix_text, false);
        result.insert(result.end(), suffix_tokens.begin(), suffix_tokens.end());
    }
    
    result.push_back(fim_end_token);
    
    return result;
}

// æ–°å¢ï¼šå¤„ç†ç®€åŒ–çš„ `` æ ¼å¼
std::vector<llama_token> QwenTokenizer::encodeSimpleFim(const std::string& text, bool addSpecialTokens) {
    // ç®€åŒ–çš„ FIM æ ¼å¼: "prefix `` suffix"
    size_t marker_pos = text.find("``");
    if (marker_pos == std::string::npos) {
        return SentencePieceTokenizer::encode(text, addSpecialTokens);
    }
    
    std::string prefix = text.substr(0, marker_pos);
    std::string suffix = text.substr(marker_pos + 2);
    
    std::vector<llama_token> result;
    
    // ç¼–ç å‰ç¼€
    auto prefix_tokens = SentencePieceTokenizer::encode(prefix, addSpecialTokens);
    result.insert(result.end(), prefix_tokens.begin(), prefix_tokens.end());
    
    // æ·»åŠ  FIM æ ‡è®°ï¼ˆä½¿ç”¨ <|fim_pre|> ä½œä¸ºå ä½ç¬¦ï¼‰
    llama_token fim_marker = tokenToId("<|fim_pre|>");
    if (fim_marker != tokenToId("<unk>")) {
        result.push_back(fim_marker);
    }
    
    // ç¼–ç åç¼€
    auto suffix_tokens = SentencePieceTokenizer::encode(suffix, false);
    result.insert(result.end(), suffix_tokens.begin(), suffix_tokens.end());
    
    return result;
}
```

**æ”¹è¿›è¦ç‚¹**ï¼š
1. âœ… å®Œæ•´çš„æ ¼å¼éªŒè¯ï¼ˆFIM æ ‡è®°å­˜åœ¨æ€§å’Œé¡ºåºï¼‰
2. âœ… FIM token æœ‰æ•ˆæ€§æ£€æŸ¥
3. âœ… ä¼˜é›…çš„é™çº§å¤„ç†ï¼ˆæ ¼å¼é”™è¯¯æ—¶å›é€€åˆ°æ™®é€šç¼–ç ï¼‰
4. âœ… æ”¯æŒç®€åŒ–çš„ ` `` ` æ ¼å¼
5. âœ… è¯¦ç»†çš„æ³¨é‡Šè¯´æ˜

---

### 3. **needsFimProcessing()** âœ… å·²æ­£ç¡®å®ç°

#### ğŸ“ å‡½æ•°ç­¾å
```cpp
bool QwenTokenizer::needsFimProcessing(const std::string& text)
```

#### ğŸ¯ é¢„æœŸåŠŸèƒ½
æ£€æµ‹æ–‡æœ¬ä¸­æ˜¯å¦åŒ…å« FIMï¼ˆFill-in-the-Middleï¼‰æ ‡è®°ï¼Œå†³å®šæ˜¯å¦éœ€è¦ä½¿ç”¨ FIM ç¼–ç è·¯å¾„ã€‚

#### âš ï¸ å½“å‰å®ç°çŠ¶æ€
```cpp
bool QwenTokenizer::needsFimProcessing(const std::string& text) {
    return text.find("<|fim_begin|>") != std::string::npos || 
           text.find("<|fim_end|>") != std::string::npos ||
           text.find("``") != std::string::npos ||
           text.find("<|fim_suf|>") != std::string::npos ||
           text.find("<|fim_pre|>") != std::string::npos;
}
```

#### ğŸ’¥ å½±å“è¯„ä¼°
- **ä¸¥é‡ç¨‹åº¦**: ğŸŸ¢ **ä½** - å·²æ­£ç¡®å®ç°
- **æ½œåœ¨æ”¹è¿›**:
  - å¯ä»¥æ·»åŠ æ€§èƒ½ä¼˜åŒ–ï¼ˆé¿å…å¤šæ¬¡å­—ç¬¦ä¸²æŸ¥æ‰¾ï¼‰
  - å¯ä»¥æ”¯æŒæ›´å¤š FIM å˜ä½“

#### âœ… ä¼˜åŒ–å»ºè®®ï¼ˆå¯é€‰ï¼‰

```cpp
bool QwenTokenizer::needsFimProcessing(const std::string& text) {
    // æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨å•æ¬¡éå†
    static const std::vector<std::string> fim_markers = {
        "<|fim_begin|>", "<|fim_end|>", "<|fim_pre|>", 
        "<|fim_suf|>", "<|fim_pad|>", "``"
    };
    
    for (const auto& marker : fim_markers) {
        if (text.find(marker) != std::string::npos) {
            return true;
        }
    }
    
    return false;
}
```

---

## ğŸ“Š æ€»ç»“

### ğŸ”´ é«˜ä¼˜å…ˆçº§ï¼ˆå¿…é¡»å®ç°ï¼‰

| å‡½æ•° | çŠ¶æ€ | å½±å“ | é¢„è®¡å·¥ä½œé‡ |
|------|------|------|-----------|
| **applyQwenPreprocessing()** | âŒ æœªå®ç° | æ ¸å¿ƒåŠŸèƒ½ç¼ºå¤± | 4-6 å°æ—¶ |

### ğŸŸ¡ ä¸­ä¼˜å…ˆçº§ï¼ˆå»ºè®®æ”¹è¿›ï¼‰

| å‡½æ•° | çŠ¶æ€ | å½±å“ | é¢„è®¡å·¥ä½œé‡ |
|------|------|------|-----------|
| **encodeWithFim()** | âš ï¸ éƒ¨åˆ†å®ç° | FIM åŠŸèƒ½ä¸ç¨³å®š | 2-3 å°æ—¶ |

### ğŸŸ¢ ä½ä¼˜å…ˆçº§ï¼ˆå¯é€‰ä¼˜åŒ–ï¼‰

| å‡½æ•° | çŠ¶æ€ | å½±å“ | é¢„è®¡å·¥ä½œé‡ |
|------|------|------|-----------|
| **needsFimProcessing()** | âœ… å·²å®ç° | æ€§èƒ½å¯å¾®ä¼˜åŒ– | 0.5 å°æ—¶ |

---

## ğŸ¯ å®æ–½å»ºè®®

### ç¬¬ä¸€é˜¶æ®µï¼šæ ¸å¿ƒåŠŸèƒ½è¡¥å…¨ï¼ˆå¿…åšï¼‰

1. **å®ç° applyQwenPreprocessing()**
   - é€‰æ‹©å®ç°æ–¹æ¡ˆï¼ˆæ¨èæ–¹æ¡ˆ1æˆ–æ–¹æ¡ˆ3ï¼‰
   - ç¼–å†™å•å…ƒæµ‹è¯•ï¼ˆå‚è€ƒ `test_deepseek_preprocessing_unit.cpp`ï¼‰
   - éªŒè¯ä¸å®˜æ–¹ Qwen tokenizer çš„ä¸€è‡´æ€§

### ç¬¬äºŒé˜¶æ®µï¼šFIM åŠŸèƒ½å®Œå–„ï¼ˆå»ºè®®ï¼‰

2. **æ”¹è¿› encodeWithFim()**
   - æ·»åŠ æ ¼å¼éªŒè¯
   - æ·»åŠ é”™è¯¯å¤„ç†å’Œé™çº§é€»è¾‘
   - æ”¯æŒç®€åŒ–çš„ ` `` ` æ ¼å¼
   - ç¼–å†™ FIM ä¸“é¡¹æµ‹è¯•

### ç¬¬ä¸‰é˜¶æ®µï¼šæ€§èƒ½ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰

3. **ä¼˜åŒ– needsFimProcessing()**
   - å‡å°‘å­—ç¬¦ä¸²æŸ¥æ‰¾æ¬¡æ•°
   - è€ƒè™‘ç¼“å­˜æœºåˆ¶

---

## ğŸ“š å‚è€ƒæ–‡æ¡£

1. **è®¾è®¡æ–‡æ¡£**:
   - `docs/modules/CTokenizeråˆ†è¯è®¾è®¡.md` - ç¬¬ 3.2.3 èŠ‚ï¼ˆQwen åˆ†è¯å™¨å®ç°ï¼‰
   - `docs/åˆ†è¯å™¨è®¾è®¡.md` - ç¬¬ 5.4 èŠ‚ï¼ˆQwen æ­£åˆ™è¡¨è¾¾å¼ï¼‰

2. **ä»£ç è§„èŒƒ**:
   - `docs/C++ç¼–ç¨‹è§„èŒƒ.md`
   - `docs/ç”Ÿæˆä»£ç è§„èŒƒ.md`

3. **æµ‹è¯•å‚è€ƒ**:
   - `tests/test_ctokenizer.cpp` - QwenFimDetection æµ‹è¯•
   - `tests/test_deepseek_preprocessing_unit.cpp` - é¢„å¤„ç†æµ‹è¯•æ¨¡æ¿

4. **Review é—®é¢˜**:
   - `docs/review/tokenizeræ¨¡å—review.md` - ç¬¬6èŠ‚ï¼ˆæ¨¡å‹ç‰¹å®šåˆ†è¯å™¨å®ç°ä¸å®Œæ•´ï¼‰

---

## âš ï¸ é£é™©æç¤º

### å½“å‰é£é™©

1. **ç¼–ç ä¸ä¸€è‡´æ€§**: 
   - æœªå®ç° `applyQwenPreprocessing()` å¯¼è‡´ç¼–ç ç»“æœä¸å®˜æ–¹ Qwen ä¸ä¸€è‡´
   - å¯èƒ½å¯¼è‡´æ¨¡å‹æ¨ç†æ•ˆæœæ˜¾è‘—ä¸‹é™

2. **FIM åŠŸèƒ½ä¸ç¨³å®š**:
   - `encodeWithFim()` ç¼ºå°‘é”™è¯¯å¤„ç†
   - åœ¨ FIM token ç¼ºå¤±æ—¶å¯èƒ½å´©æºƒæˆ–äº§ç”Ÿé”™è¯¯ç»“æœ

3. **æµ‹è¯•è¦†ç›–ä¸è¶³**:
   - ç¼ºå°‘é’ˆå¯¹ Qwen é¢„å¤„ç†çš„å•å…ƒæµ‹è¯•
   - FIM åŠŸèƒ½æµ‹è¯•ä¸å……åˆ†

### ç¼“è§£æªæ–½

1. âœ… **ç«‹å³å®ç° applyQwenPreprocessing()**ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
2. âœ… **ç¼–å†™å®Œæ•´çš„å•å…ƒæµ‹è¯•**
3. âœ… **ä¸å®˜æ–¹ Qwen tokenizer å¯¹æ¯”éªŒè¯**
4. âœ… **æ·»åŠ é”™è¯¯æ—¥å¿—å’Œé™çº§å¤„ç†**

---

## ğŸ“ å®æ–½æ£€æŸ¥æ¸…å•

- [ ] é€‰æ‹© `applyQwenPreprocessing()` å®ç°æ–¹æ¡ˆ
- [ ] å®ç°å‡½æ•°ä»£ç 
- [ ] ç¼–å†™å•å…ƒæµ‹è¯•ï¼ˆè‡³å°‘10ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼‰
- [ ] ä¸å®˜æ–¹ Qwen tokenizer ç»“æœå¯¹æ¯”
- [ ] æ”¹è¿› `encodeWithFim()` é”™è¯¯å¤„ç†
- [ ] æ·»åŠ  FIM æ ¼å¼éªŒè¯
- [ ] æ”¯æŒç®€åŒ–çš„ ` `` ` æ ¼å¼
- [ ] è¿è¡Œæ‰€æœ‰æµ‹è¯•ç¡®ä¿æ— å›å½’
- [ ] æ›´æ–°æ–‡æ¡£å’Œæ³¨é‡Š
- [ ] ä»£ç å®¡æŸ¥

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: 2026-01-10  
**åˆ†æäºº**: AI æ™ºèƒ½ç¼–ç¨‹åŠ©æ‰‹  
**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
