# Tokenizer æ¨¡å—è”è°ƒå‡†å¤‡æŒ‡å—

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  
**å‡†å¤‡æ—¥æœŸ**: 2026-01-10  
**ç›®æ ‡**: ä¸º Tokenizer æ¨¡å—ä¸å…¶ä»–ç³»ç»Ÿç»„ä»¶çš„è”è°ƒæµ‹è¯•æä¾›å®æ“æŒ‡å—

---

## ğŸ“‹ å¿«é€Ÿè¯„ä¼°

### æ¨¡å—å°±ç»ªçŠ¶æ€

| ç»´åº¦ | çŠ¶æ€ | å®Œæˆåº¦ | è¯´æ˜ |
|-----|------|-------|------|
| **æ ¸å¿ƒåŠŸèƒ½** | âœ… å°±ç»ª | 100% | æ‰€æœ‰æ¥å£å·²å®ç° |
| **æ€§èƒ½ä¼˜åŒ–** | âœ… å°±ç»ª | 100% | æ‰¹å¤„ç†ã€ç¼“å­˜ã€ç›‘æ§å·²å®Œæˆ |
| **æµ‹è¯•è¦†ç›–** | âœ… å°±ç»ª | 88% | 155+ æµ‹è¯•ç”¨ä¾‹ |
| **æ–‡æ¡£** | âœ… å°±ç»ª | 85% | è®¾è®¡å’Œå®ç°æ–‡æ¡£å®Œæ•´ |
| **è”è°ƒå‡†å¤‡** | âœ… å°±ç»ª | 95% | ä»…éœ€ CI é…ç½® |

**æ€»ä½“è¯„ä¼°**: âœ… **å¯ç«‹å³å¼€å§‹è”è°ƒæµ‹è¯•**

---

## 1. è”è°ƒåœºæ™¯æ¸…å•

### 1.1 åœºæ™¯ä¼˜å…ˆçº§

| åœºæ™¯ | ä¼˜å…ˆçº§ | ä¾èµ–æ¨¡å— | é¢„è®¡å·¥ä½œé‡ | é£é™© |
|------|--------|---------|-----------|------|
| Tokenizer â†” ModelExecutor | ğŸ”´ P0 | ModelExecutor | 4-6h | ä½ |
| Tokenizer â†” Server/API | ğŸ”´ P0 | Server, HTTPServer | 6-8h | ä½ |
| Tokenizer â†” KVCache | ğŸŸ¡ P1 | KVCache | 2-4h | ä½ |
| æ‰¹å¤„ç†æ€§èƒ½éªŒè¯ | ğŸŸ¡ P1 | - | 4-6h | ä¸­ |
| ç«¯åˆ°ç«¯é›†æˆæµ‹è¯• | ğŸŸ¢ P2 | æ‰€æœ‰æ¨¡å— | 8-12h | é«˜ |

---

## 2. åœºæ™¯ 1: Tokenizer â†” ModelExecutor è”è°ƒ

### 2.1 æµ‹è¯•ç›®æ ‡

éªŒè¯åˆ†è¯å™¨èƒ½ä¸ºæ¨¡å‹æ‰§è¡Œå™¨æä¾›æ­£ç¡®çš„ token åºåˆ—

### 2.2 ç¯å¢ƒå‡†å¤‡

```bash
# 1. å‡†å¤‡æµ‹è¯•æ¨¡å‹
cd /path/to/cLLM
mkdir -p model_test
# ä¸‹è½½ Qwen2-7B-Instruct æ¨¡å‹ï¼ˆæˆ–ä½¿ç”¨å·²æœ‰æ¨¡å‹ï¼‰

# 2. ç¼–è¯‘æµ‹è¯•ç¨‹åº
mkdir -p build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release
make test_tokenizer_executor_integration

# 3. é…ç½®ç¯å¢ƒå˜é‡
export MODEL_PATH="../model_test/qwen2-7b-instruct"
export LOG_LEVEL="DEBUG"
```

### 2.3 æµ‹è¯•ç”¨ä¾‹

#### æµ‹è¯•ç”¨ä¾‹ 1: åŸºç¡€ç¼–è§£ç 

```cpp
// tests/integration/test_tokenizer_executor.cpp
TEST(TokenizerExecutorIntegration, BasicEncodeDecode) {
    // 1. åˆå§‹åŒ–åˆ†è¯å™¨
    auto tokenizer = std::make_unique<NativeTokenizer>();
    ASSERT_TRUE(tokenizer->load(MODEL_PATH));
    
    // 2. ç¼–ç æ–‡æœ¬
    std::string prompt = "Hello, how are you?";
    auto tokens = tokenizer->encode(prompt, true);
    
    // 3. éªŒè¯ token æ ¼å¼
    EXPECT_GT(tokens.size(), 0);
    EXPECT_EQ(tokens[0], tokenizer->getBosId());  // BOS token
    
    // 4. ä¼ é€’ç»™ ModelExecutor
    ModelExecutor executor;
    ASSERT_TRUE(executor.load(MODEL_PATH));
    
    auto output = executor.execute(tokens);
    EXPECT_GT(output.size(), 0);
    
    // 5. è§£ç è¾“å‡º
    std::string decoded = tokenizer->decode(output, true);
    EXPECT_FALSE(decoded.empty());
}
```

#### æµ‹è¯•ç”¨ä¾‹ 2: é•¿æ–‡æœ¬å¤„ç†

```cpp
TEST(TokenizerExecutorIntegration, LongTextProcessing) {
    auto tokenizer = std::make_unique<NativeTokenizer>();
    tokenizer->load(MODEL_PATH);
    
    // ç”Ÿæˆ 1000 å­—é•¿æ–‡æœ¬
    std::string longText = generateLongText(1000);
    
    auto tokens = tokenizer->encode(longText, true);
    EXPECT_LT(tokens.size(), 10000);  // åˆç†çš„ token æ•°é‡
    
    // éªŒè¯ä¸ ModelExecutor å…¼å®¹
    ModelExecutor executor;
    executor.load(MODEL_PATH);
    EXPECT_NO_THROW(executor.execute(tokens));
}
```

#### æµ‹è¯•ç”¨ä¾‹ 3: ç‰¹æ®Š token å¤„ç†

```cpp
TEST(TokenizerExecutorIntegration, SpecialTokens) {
    auto tokenizer = std::make_unique<NativeTokenizer>();
    tokenizer->load(MODEL_PATH);
    
    // æµ‹è¯•ç³»ç»Ÿæç¤ºè¯æ ¼å¼
    std::string prompt = "<|im_start|>system\nYou are a helpful assistant.<|im_end|>";
    auto tokens = tokenizer->encode(prompt, true);
    
    // éªŒè¯ç‰¹æ®Š token è¢«æ­£ç¡®è¯†åˆ«
    EXPECT_TRUE(containsSpecialToken(tokens, "<|im_start|>"));
    EXPECT_TRUE(containsSpecialToken(tokens, "<|im_end|>"));
    
    ModelExecutor executor;
    executor.load(MODEL_PATH);
    auto output = executor.execute(tokens);
    EXPECT_GT(output.size(), 0);
}
```

### 2.4 æ€§èƒ½åŸºå‡†

```cpp
TEST(TokenizerExecutorIntegration, PerformanceBenchmark) {
    auto tokenizer = std::make_unique<NativeTokenizer>();
    tokenizer->enablePerformanceMonitor(true);
    tokenizer->load(MODEL_PATH);
    
    ModelExecutor executor;
    executor.load(MODEL_PATH);
    
    // æµ‹è¯• 100 æ¬¡ç¼–ç  + æ¨ç†
    auto start = std::chrono::high_resolution_clock::now();
    for (int i = 0; i < 100; ++i) {
        std::string text = "Test prompt " + std::to_string(i);
        auto tokens = tokenizer->encode(text, true);
        executor.execute(tokens);
    }
    auto end = std::chrono::high_resolution_clock::now();
    
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);
    double avgLatency = duration.count() / 100.0;
    
    // éªŒè¯æ€§èƒ½ç›®æ ‡
    EXPECT_LT(avgLatency, 100);  // å¹³å‡ < 100ms
    
    auto stats = tokenizer->getPerformanceStats();
    std::cout << "Average encode latency: " << stats.avgEncodeLatency << " ms" << std::endl;
    std::cout << "P95 encode latency: " << stats.p95EncodeLatency << " ms" << std::endl;
}
```

### 2.5 é¢„æœŸç»“æœ

| æŒ‡æ ‡ | é¢„æœŸå€¼ | éªŒè¯æ–¹æ³• |
|------|--------|---------|
| Token æ ¼å¼æ­£ç¡®æ€§ | 100% | æ£€æŸ¥ BOS/EOS |
| ç¼–ç é€Ÿåº¦ | â‰¥ 50 MB/s | PerformanceStats |
| å†…å­˜å ç”¨ | â‰¤ 50 MB | ç³»ç»Ÿç›‘æ§ |
| é”™è¯¯ç‡ | 0% | å¼‚å¸¸æ•è· |

---

## 3. åœºæ™¯ 2: Tokenizer â†” Server/API è”è°ƒ

### 3.1 æµ‹è¯•ç›®æ ‡

éªŒè¯åˆ†è¯å™¨èƒ½æ­£ç¡®å¤„ç† HTTP è¯·æ±‚ä¸­çš„æ–‡æœ¬

### 3.2 ç¯å¢ƒå‡†å¤‡

```bash
# 1. å¯åŠ¨æµ‹è¯•æœåŠ¡å™¨
cd build
./cllm_server --config ../config/server_test.yaml --port 8080

# 2. åœ¨å¦ä¸€ä¸ªç»ˆç«¯è¿è¡Œæµ‹è¯•
cd tests/integration
python3 test_tokenizer_api.py
```

### 3.3 API æµ‹è¯•ç”¨ä¾‹

#### æµ‹è¯•ç”¨ä¾‹ 1: åŸºç¡€ç¼–ç  API

```python
# tests/integration/test_tokenizer_api.py
import requests
import json

def test_encode_api():
    url = "http://localhost:8080/v1/tokenize"
    payload = {
        "text": "Hello, world!",
        "add_special_tokens": True
    }
    
    response = requests.post(url, json=payload)
    assert response.status_code == 200
    
    data = response.json()
    assert "tokens" in data
    assert len(data["tokens"]) > 0
    print(f"Encoded tokens: {data['tokens']}")
```

#### æµ‹è¯•ç”¨ä¾‹ 2: æ‰¹é‡ç¼–ç  API

```python
def test_batch_encode_api():
    url = "http://localhost:8080/v1/tokenize/batch"
    payload = {
        "texts": [
            "Hello, world!",
            "How are you?",
            "This is a test."
        ],
        "add_special_tokens": True
    }
    
    response = requests.post(url, json=payload)
    assert response.status_code == 200
    
    data = response.json()
    assert "results" in data
    assert len(data["results"]) == 3
    
    # éªŒè¯æ‰¹å¤„ç†æ€§èƒ½æå‡
    assert data.get("batch_speedup", 1.0) >= 2.0
```

#### æµ‹è¯•ç”¨ä¾‹ 3: UTF-8 ç¼–ç æµ‹è¯•

```python
def test_utf8_encoding():
    url = "http://localhost:8080/v1/tokenize"
    
    # æµ‹è¯•å¤šè¯­è¨€æ–‡æœ¬
    test_cases = [
        "Hello, world!",           # è‹±è¯­
        "ä½ å¥½ï¼Œä¸–ç•Œï¼",             # ä¸­æ–‡
        "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, Ğ¼Ğ¸Ñ€!",            # ä¿„è¯­
        "Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…",           # é˜¿æ‹‰ä¼¯è¯­
        "Hello ä¸–ç•Œ ĞŸÑ€Ğ¸Ğ²ĞµÑ‚ ğŸŒ",   # æ··åˆ
    ]
    
    for text in test_cases:
        payload = {"text": text, "add_special_tokens": True}
        response = requests.post(url, json=payload)
        assert response.status_code == 200, f"Failed for: {text}"
        
        data = response.json()
        assert len(data["tokens"]) > 0
        print(f"âœ“ {text[:30]}: {len(data['tokens'])} tokens")
```

#### æµ‹è¯•ç”¨ä¾‹ 4: æ€§èƒ½å‹åŠ›æµ‹è¯•

```python
import concurrent.futures
import time

def test_concurrent_requests():
    url = "http://localhost:8080/v1/tokenize"
    
    def send_request(i):
        payload = {"text": f"Test request {i}", "add_special_tokens": True}
        start = time.time()
        response = requests.post(url, json=payload)
        latency = (time.time() - start) * 1000  # ms
        return response.status_code, latency
    
    # å¹¶å‘ 100 ä¸ªè¯·æ±‚
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        futures = [executor.submit(send_request, i) for i in range(100)]
        results = [f.result() for f in futures]
    
    # éªŒè¯ç»“æœ
    success_count = sum(1 for status, _ in results if status == 200)
    latencies = [lat for _, lat in results]
    
    assert success_count == 100, f"Only {success_count}/100 succeeded"
    
    avg_latency = sum(latencies) / len(latencies)
    p95_latency = sorted(latencies)[int(len(latencies) * 0.95)]
    
    print(f"Average latency: {avg_latency:.2f} ms")
    print(f"P95 latency: {p95_latency:.2f} ms")
    
    assert avg_latency < 50, "Average latency too high"
    assert p95_latency < 100, "P95 latency too high"
```

### 3.4 C++ é›†æˆæµ‹è¯•

```cpp
// tests/integration/test_server_tokenizer.cpp
TEST(ServerTokenizerIntegration, HttpRequestHandling) {
    // 1. åˆ›å»ºæµ‹è¯•æœåŠ¡å™¨
    ServerConfig config;
    config.port = 8080;
    config.model_path = MODEL_PATH;
    
    Server server(config);
    server.start();
    
    // 2. åˆ›å»º HTTP å®¢æˆ·ç«¯
    HttpClient client("http://localhost:8080");
    
    // 3. å‘é€ç¼–ç è¯·æ±‚
    json request = {
        {"text", "Hello, world!"},
        {"add_special_tokens", true}
    };
    
    auto response = client.post("/v1/tokenize", request);
    EXPECT_EQ(response.status_code, 200);
    
    auto data = json::parse(response.body);
    EXPECT_TRUE(data.contains("tokens"));
    EXPECT_GT(data["tokens"].size(), 0);
    
    server.stop();
}
```

### 3.5 é¢„æœŸç»“æœ

| æŒ‡æ ‡ | é¢„æœŸå€¼ | éªŒè¯æ–¹æ³• |
|------|--------|---------|
| API å¯ç”¨æ€§ | 100% | HTTP 200 |
| UTF-8 æ”¯æŒ | å®Œæ•´ | å¤šè¯­è¨€æµ‹è¯• |
| å¹¶å‘å¤„ç† | 100 QPS | å‹åŠ›æµ‹è¯• |
| å¹³å‡å»¶è¿Ÿ | < 50 ms | æ€§èƒ½ç›‘æ§ |
| P95 å»¶è¿Ÿ | < 100 ms | æ€§èƒ½ç›‘æ§ |

---

## 4. åœºæ™¯ 3: æ‰¹å¤„ç†æ€§èƒ½éªŒè¯

### 4.1 æµ‹è¯•ç›®æ ‡

éªŒè¯æ‰¹å¤„ç†ç›¸æ¯”å•çº¿ç¨‹çš„æ€§èƒ½æå‡ â‰¥ 3x

### 4.2 æµ‹è¯•ä»£ç 

```cpp
// tests/performance/test_batch_performance.cpp
TEST(BatchPerformance, ThroughputComparison) {
    auto tokenizer = std::make_unique<NativeTokenizer>();
    tokenizer->load(MODEL_PATH);
    
    // å‡†å¤‡æµ‹è¯•æ•°æ®
    std::vector<std::string> texts;
    for (int i = 0; i < 1000; ++i) {
        texts.push_back("This is test text number " + std::to_string(i));
    }
    
    // æµ‹è¯• 1: å•çº¿ç¨‹å¤„ç†
    auto start1 = std::chrono::high_resolution_clock::now();
    for (const auto& text : texts) {
        tokenizer->encode(text, true);
    }
    auto end1 = std::chrono::high_resolution_clock::now();
    auto duration1 = std::chrono::duration_cast<std::chrono::milliseconds>(end1 - start1);
    
    // æµ‹è¯• 2: æ‰¹å¤„ç†ï¼ˆé»˜è®¤å¹¶è¡Œåº¦ï¼‰
    auto start2 = std::chrono::high_resolution_clock::now();
    auto result = BatchTokenizer::batchEncode(tokenizer.get(), texts, true, 0);
    auto end2 = std::chrono::high_resolution_clock::now();
    auto duration2 = std::chrono::duration_cast<std::chrono::milliseconds>(end2 - start2);
    
    // è®¡ç®—åŠ é€Ÿæ¯”
    double speedup = static_cast<double>(duration1.count()) / duration2.count();
    
    std::cout << "Single-thread time: " << duration1.count() << " ms" << std::endl;
    std::cout << "Batch time: " << duration2.count() << " ms" << std::endl;
    std::cout << "Speedup: " << speedup << "x" << std::endl;
    
    // éªŒè¯æ€§èƒ½ç›®æ ‡
    EXPECT_GE(speedup, 3.0) << "Batch processing speedup below target";
    
    // éªŒè¯ç»“æœæ­£ç¡®æ€§
    size_t successCount = std::count(result.success.begin(), result.success.end(), true);
    EXPECT_EQ(successCount, texts.size()) << "Some batch items failed";
}
```

### 4.3 ä¸åŒåœºæ™¯æµ‹è¯•

```cpp
TEST(BatchPerformance, VariousBatchSizes) {
    auto tokenizer = std::make_unique<NativeTokenizer>();
    tokenizer->load(MODEL_PATH);
    
    std::vector<int> batchSizes = {1, 4, 8, 16, 32, 64, 128};
    
    for (int batchSize : batchSizes) {
        // ç”Ÿæˆæµ‹è¯•æ•°æ®
        std::vector<std::string> texts(batchSize, "Test text for batch processing");
        
        // æµ‹é‡æ‰¹å¤„ç†æ—¶é—´
        auto start = std::chrono::high_resolution_clock::now();
        auto result = BatchTokenizer::batchEncode(tokenizer.get(), texts, true, 4);
        auto end = std::chrono::high_resolution_clock::now();
        
        auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end - start);
        double avgLatency = duration.count() / static_cast<double>(batchSize);
        
        std::cout << "Batch size " << batchSize 
                  << ": avg latency " << avgLatency << " Î¼s/item" << std::endl;
    }
}
```

### 4.4 é¢„æœŸç»“æœ

| Batch Size | é¢„æœŸåŠ é€Ÿæ¯” | é¢„æœŸæˆåŠŸç‡ |
|-----------|-----------|-----------|
| 1 | 1.0x | 100% |
| 8 | 2.5-3.5x | 100% |
| 32 | 3.5-4.5x | 100% |
| 128 | 4.0-5.0x | 100% |

---

## 5. åœºæ™¯ 4: ç¼“å­˜æ•ˆæœéªŒè¯

### 5.1 æµ‹è¯•ç›®æ ‡

éªŒè¯ç¼“å­˜å‘½ä¸­ç‡ â‰¥ 50%ï¼ˆé‡å¤æ–‡æœ¬åœºæ™¯ï¼‰

### 5.2 æµ‹è¯•ä»£ç 

```cpp
TEST(CachePerformance, HitRateValidation) {
    auto tokenizer = std::make_unique<NativeTokenizer>();
    tokenizer->load(MODEL_PATH);
    tokenizer->enablePerformanceMonitor(true);
    
    // è®¾ç½®é«˜æ€§èƒ½é…ç½®ï¼ˆå¯ç”¨ç¼“å­˜ï¼‰
    auto config = TokenizerPerformanceConfig::getHighPerformance();
    tokenizer->setPerformanceConfig(config);
    
    // å‡†å¤‡æµ‹è¯•æ•°æ®ï¼ˆ50% é‡å¤ï¼‰
    std::vector<std::string> texts;
    for (int i = 0; i < 100; ++i) {
        texts.push_back("Repeated text " + std::to_string(i % 50));
    }
    
    // éšæœºæ‰“ä¹±é¡ºåº
    std::shuffle(texts.begin(), texts.end(), std::mt19937{std::random_device{}()});
    
    // æ‰§è¡Œç¼–ç 
    for (const auto& text : texts) {
        tokenizer->encode(text, true);
    }
    
    // è·å–ç»Ÿè®¡æ•°æ®
    auto stats = tokenizer->getPerformanceStats();
    double hitRate = stats.getCacheHitRate();
    
    std::cout << "Cache hits: " << stats.cacheHits << std::endl;
    std::cout << "Cache misses: " << stats.cacheMisses << std::endl;
    std::cout << "Hit rate: " << hitRate * 100 << "%" << std::endl;
    
    // éªŒè¯ç¼“å­˜æ•ˆæœ
    EXPECT_GE(hitRate, 0.45) << "Cache hit rate too low";
}
```

### 5.3 ç¼“å­˜æ€§èƒ½å¯¹æ¯”

```cpp
TEST(CachePerformance, SpeedupMeasurement) {
    auto tokenizer = std::make_unique<NativeTokenizer>();
    tokenizer->load(MODEL_PATH);
    
    std::string repeatedText = "This is a repeated text for cache testing";
    
    // æµ‹è¯• 1: æ— ç¼“å­˜
    auto config1 = TokenizerPerformanceConfig::getDefault();
    config1.cacheEnabled = false;
    tokenizer->setPerformanceConfig(config1);
    
    auto start1 = std::chrono::high_resolution_clock::now();
    for (int i = 0; i < 1000; ++i) {
        tokenizer->encode(repeatedText, true);
    }
    auto end1 = std::chrono::high_resolution_clock::now();
    auto duration1 = std::chrono::duration_cast<std::chrono::microseconds>(end1 - start1);
    
    // æµ‹è¯• 2: æœ‰ç¼“å­˜
    auto config2 = TokenizerPerformanceConfig::getDefault();
    config2.cacheEnabled = true;
    tokenizer->setPerformanceConfig(config2);
    
    auto start2 = std::chrono::high_resolution_clock::now();
    for (int i = 0; i < 1000; ++i) {
        tokenizer->encode(repeatedText, true);
    }
    auto end2 = std::chrono::high_resolution_clock::now();
    auto duration2 = std::chrono::duration_cast<std::chrono::microseconds>(end2 - start2);
    
    // è®¡ç®—åŠ é€Ÿæ¯”
    double speedup = static_cast<double>(duration1.count()) / duration2.count();
    
    std::cout << "Without cache: " << duration1.count() << " Î¼s" << std::endl;
    std::cout << "With cache: " << duration2.count() << " Î¼s" << std::endl;
    std::cout << "Speedup: " << speedup << "x" << std::endl;
    
    EXPECT_GE(speedup, 5.0) << "Cache speedup below expectation";
}
```

---

## 6. é—®é¢˜æ’æŸ¥æŒ‡å—

### 6.1 å¸¸è§é—®é¢˜æ¸…å•

#### é—®é¢˜ 1: ç¼–ç ç»“æœä¸ä¸€è‡´

**ç—‡çŠ¶**:
```
FAIL: Expected token count 10, got 12
```

**æ’æŸ¥æ­¥éª¤**:
1. æ£€æŸ¥ç‰¹æ®Š token è®¾ç½®
   ```cpp
   auto tokens = tokenizer->encode(text, false);  // ä¸æ·»åŠ ç‰¹æ®Š token
   ```

2. éªŒè¯ Unicode è§„èŒƒåŒ–
   ```cpp
   std::string normalized = UnicodeUtils::normalizeNFC(text);
   EXPECT_EQ(text, normalized);
   ```

3. æ£€æŸ¥è¯æ±‡è¡¨åŠ è½½
   ```cpp
   EXPECT_GT(tokenizer->getVocabSize(), 0);
   EXPECT_NE(tokenizer->getBosId(), -1);
   ```

---

#### é—®é¢˜ 2: æ‰¹å¤„ç†æ€§èƒ½æœªè¾¾é¢„æœŸ

**ç—‡çŠ¶**:
```
Speedup: 1.5x (expected >= 3.0x)
```

**æ’æŸ¥æ­¥éª¤**:
1. æ£€æŸ¥å¹¶è¡Œçº¿ç¨‹æ•°
   ```cpp
   auto config = tokenizer->getPerformanceConfig();
   std::cout << "Num threads: " << config.numThreads << std::endl;
   ```

2. éªŒè¯ CPU æ ¸å¿ƒæ•°
   ```cpp
   int cores = std::thread::hardware_concurrency();
   EXPECT_GE(cores, 4);
   ```

3. æ£€æŸ¥ä»»åŠ¡æ•°é‡
   ```cpp
   // ä»»åŠ¡æ•°åº” >= çº¿ç¨‹æ•°
   EXPECT_GE(texts.size(), config.numThreads * 2);
   ```

---

#### é—®é¢˜ 3: ç¼“å­˜æœªç”Ÿæ•ˆ

**ç—‡çŠ¶**:
```
Cache hit rate: 0% (expected >= 50%)
```

**æ’æŸ¥æ­¥éª¤**:
1. ç¡®è®¤ç¼“å­˜å·²å¯ç”¨
   ```cpp
   auto config = tokenizer->getPerformanceConfig();
   EXPECT_TRUE(config.cacheEnabled);
   ```

2. æ£€æŸ¥ç¼“å­˜å¤§å°
   ```cpp
   EXPECT_GT(config.cacheMaxSize, 0);
   ```

3. éªŒè¯æ–‡æœ¬å®Œå…¨ç›¸åŒï¼ˆåŒ…æ‹¬ç©ºæ ¼ï¼‰
   ```cpp
   std::string text1 = "Hello";
   std::string text2 = "Hello ";  // æœ«å°¾æœ‰ç©ºæ ¼
   EXPECT_NE(text1, text2);
   ```

---

#### é—®é¢˜ 4: å†…å­˜å ç”¨è¿‡é«˜

**ç—‡çŠ¶**:
```
Peak memory usage: 500 MB (expected <= 50 MB)
```

**æ’æŸ¥æ­¥éª¤**:
1. æ£€æŸ¥ç¼“å­˜é…ç½®
   ```cpp
   auto config = TokenizerPerformanceConfig::getLowMemory();
   tokenizer->setPerformanceConfig(config);
   ```

2. ç›‘æ§å†…å­˜ä½¿ç”¨
   ```cpp
   auto stats = tokenizer->getPerformanceStats();
   std::cout << "Current memory: " << stats.currentMemoryUsage / 1024 / 1024 << " MB" << std::endl;
   ```

3. å®šæœŸæ¸…ç†ç¼“å­˜
   ```cpp
   if (stats.currentMemoryUsage > 50 * 1024 * 1024) {
       tokenizer->clearCache();
   }
   ```

---

### 6.2 è°ƒè¯•å·¥å…·

#### å¯ç”¨è¯¦ç»†æ—¥å¿—

```cpp
// åœ¨ä»£ç ä¸­å¯ç”¨
tokenizer->setLogLevel(LogLevel::DEBUG);

// æˆ–é€šè¿‡ç¯å¢ƒå˜é‡
export TOKENIZER_LOG_LEVEL=DEBUG
```

#### æ€§èƒ½ç›‘æ§

```cpp
// å¯ç”¨æ€§èƒ½ç›‘æ§
tokenizer->enablePerformanceMonitor(true);

// å®šæœŸæ‰“å°ç»Ÿè®¡
auto stats = tokenizer->getPerformanceStats();
std::cout << "=== Tokenizer Performance Stats ===" << std::endl;
std::cout << "Total encodes: " << stats.totalEncodes << std::endl;
std::cout << "Avg latency: " << stats.avgEncodeLatency << " ms" << std::endl;
std::cout << "P95 latency: " << stats.p95EncodeLatency << " ms" << std::endl;
std::cout << "Cache hit rate: " << stats.getCacheHitRate() * 100 << "%" << std::endl;
std::cout << "Memory usage: " << stats.currentMemoryUsage / 1024 / 1024 << " MB" << std::endl;
```

---

## 7. æŒç»­é›†æˆé…ç½®

### 7.1 GitHub Actions é…ç½®

```yaml
# .github/workflows/tokenizer_test.yml
name: Tokenizer Integration Tests

on:
  push:
    branches: [ main, dev ]
    paths:
      - 'src/tokenizer/**'
      - 'src/CTokenizer/**'
      - 'tests/**'
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y cmake build-essential libgtest-dev
    
    - name: Download test model
      run: |
        mkdir -p model_test
        # ä¸‹è½½è½»é‡çº§æµ‹è¯•æ¨¡å‹
        wget https://example.com/qwen2-test-model.bin -O model_test/qwen2.bin
    
    - name: Build tests
      run: |
        mkdir build && cd build
        cmake .. -DCMAKE_BUILD_TYPE=Release -DENABLE_TESTS=ON
        make -j$(nproc)
    
    - name: Run unit tests
      run: |
        cd build
        ctest --output-on-failure -L tokenizer
    
    - name: Run integration tests
      run: |
        cd build
        ./test_tokenizer_executor_integration
        ./test_tokenizer_api_integration
    
    - name: Performance benchmark
      run: |
        cd build
        ./test_batch_performance > perf_results.txt
        cat perf_results.txt
    
    - name: Upload test results
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: test-results
        path: build/perf_results.txt
```

---

## 8. éªŒæ”¶æ ‡å‡†

### 8.1 åŠŸèƒ½éªŒæ”¶

| éªŒæ”¶é¡¹ | æ ‡å‡† | éªŒè¯æ–¹æ³• |
|-------|------|---------|
| åŸºç¡€ç¼–è§£ç  | 100% é€šè¿‡ | å•å…ƒæµ‹è¯• |
| æ‰¹å¤„ç†åŠŸèƒ½ | åŠ é€Ÿ â‰¥ 3x | æ€§èƒ½æµ‹è¯• |
| ç¼“å­˜æ•ˆæœ | å‘½ä¸­ç‡ â‰¥ 50% | æ€§èƒ½ç›‘æ§ |
| ç‰¹æ®Šå­—ç¬¦ | UTF-8 å®Œæ•´æ”¯æŒ | å­—ç¬¦é›†æµ‹è¯• |
| é”™è¯¯å¤„ç† | æ— å´©æºƒ | å¼‚å¸¸æµ‹è¯• |

### 8.2 æ€§èƒ½éªŒæ”¶

| æŒ‡æ ‡ | ç›®æ ‡ | éªŒè¯æ–¹æ³• |
|------|------|---------|
| ç¼–ç é€Ÿåº¦ | â‰¥ 50 MB/s | æ€§èƒ½æµ‹è¯• |
| å¹³å‡å»¶è¿Ÿ | â‰¤ 10 ms | ç›‘æ§æ•°æ® |
| P95 å»¶è¿Ÿ | â‰¤ 20 ms | ç›‘æ§æ•°æ® |
| P99 å»¶è¿Ÿ | â‰¤ 50 ms | ç›‘æ§æ•°æ® |
| å†…å­˜å ç”¨ | â‰¤ 50 MB | ç³»ç»Ÿç›‘æ§ |
| å¹¶å‘å¤„ç† | â‰¥ 100 QPS | å‹åŠ›æµ‹è¯• |

### 8.3 ç¨³å®šæ€§éªŒæ”¶

| éªŒæ”¶é¡¹ | æ ‡å‡† | éªŒè¯æ–¹æ³• |
|-------|------|---------|
| é•¿æ—¶é—´è¿è¡Œ | 24h æ— å´©æºƒ | ç¨³å®šæ€§æµ‹è¯• |
| å¹¶å‘å®‰å…¨ | æ— æ•°æ®ç«äº‰ | çº¿ç¨‹å®‰å…¨æµ‹è¯• |
| å†…å­˜æ³„æ¼ | æ— æ³„æ¼ | Valgrind |
| é”™è¯¯æ¢å¤ | è‡ªåŠ¨æ¢å¤ | é”™è¯¯æ³¨å…¥æµ‹è¯• |

---

## 9. è”è°ƒæ—¶é—´è¡¨

### 9.1 å»ºè®®æ—¶é—´å®‰æ’

| é˜¶æ®µ | ä»»åŠ¡ | å·¥ä½œé‡ | è´Ÿè´£äºº | å®Œæˆæ ‡å¿— |
|------|------|-------|--------|---------|
| **Week 1** | Tokenizer â†” ModelExecutor | 6h | å¼€å‘ A | æ‰€æœ‰é›†æˆæµ‹è¯•é€šè¿‡ |
| **Week 1** | Tokenizer â†” Server/API | 8h | å¼€å‘ B | API æµ‹è¯•é€šè¿‡ |
| **Week 2** | æ‰¹å¤„ç†æ€§èƒ½éªŒè¯ | 6h | å¼€å‘ A | æ€§èƒ½è¾¾æ ‡ |
| **Week 2** | ç¼“å­˜æ•ˆæœéªŒè¯ | 4h | å¼€å‘ B | å‘½ä¸­ç‡è¾¾æ ‡ |
| **Week 3** | ç«¯åˆ°ç«¯é›†æˆæµ‹è¯• | 12h | å…¨å‘˜ | æ‰€æœ‰åœºæ™¯é€šè¿‡ |
| **Week 3** | æ€§èƒ½è°ƒä¼˜ | 8h | å…¨å‘˜ | æ€§èƒ½æŒ‡æ ‡è¾¾æ ‡ |
| **Week 4** | æ–‡æ¡£å’ŒéªŒæ”¶ | 6h | å…¨å‘˜ | éªŒæ”¶å®Œæˆ |

**æ€»å·¥ä½œé‡**: ~50 å°æ—¶  
**å»ºè®®å›¢é˜Ÿè§„æ¨¡**: 2-3 äºº  
**é¢„è®¡å‘¨æœŸ**: 4 å‘¨

---

## 10. æ€»ç»“

### 10.1 å°±ç»ªçŠ¶æ€

âœ… **Tokenizer æ¨¡å—å·²å®Œå…¨å°±ç»ªï¼Œå¯ç«‹å³å¼€å§‹è”è°ƒæµ‹è¯•**

**å…³é”®ä¼˜åŠ¿**:
- âœ… æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½å·²å®ç°ä¸”ç»è¿‡æµ‹è¯•
- âœ… æ€§èƒ½ä¼˜åŒ–ï¼ˆæ‰¹å¤„ç†ã€ç¼“å­˜ï¼‰å·²å®Œæˆ
- âœ… ç›‘æ§å’Œé…ç½®ç³»ç»Ÿå®Œå–„
- âœ… æ–‡æ¡£é½å…¨ï¼Œæ˜“äºé›†æˆ

### 10.2 å…³é”®å»ºè®®

1. **ä¼˜å…ˆè¿›è¡Œ Tokenizer â†” ModelExecutor è”è°ƒ**ï¼ˆæœ€å…³é”®ï¼‰
2. **å°½æ—©é…ç½® CI/CD**ï¼ˆè‡ªåŠ¨åŒ–æµ‹è¯•ï¼‰
3. **å¯ç”¨æ€§èƒ½ç›‘æ§**ï¼ˆåŠæ—¶å‘ç°é—®é¢˜ï¼‰
4. **ä¿æŒæ–‡æ¡£åŒæ­¥**ï¼ˆä¾¿äºåç»­ç»´æŠ¤ï¼‰

### 10.3 è”ç³»æ”¯æŒ

å¦‚é‡åˆ°é—®é¢˜ï¼Œè¯·å‚è€ƒï¼š
- ğŸ“„ è®¾è®¡æ–‡æ¡£: `docs/modules/Tokenizeræ¨¡å—è®¾è®¡.md`
- ğŸ“Š å®Œæ•´æ€§æŠ¥å‘Š: `docs/analysis/src_tokenizeræ¨¡å—å®Œæ•´æ€§åˆ†ææŠ¥å‘Š_v2.md`
- ğŸ” æµ‹è¯•ç”¨ä¾‹: `tests/test_tokenizer*.cpp`

---

**æ–‡æ¡£ç»´æŠ¤**: è¯·åœ¨è”è°ƒè¿‡ç¨‹ä¸­åŠæ—¶æ›´æ–°æœ¬æ–‡æ¡£  
**æœ€åæ›´æ–°**: 2026-01-10
