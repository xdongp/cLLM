# v13性能瓶颈分析报告

## 测试结果

**日期**: 2026-01-20
**版本**: v13稳定版本（回退原子操作后）
**测试配置**: 40请求, 5并发, 50 tokens/请求

### 性能数据
- **吞吐量**: 52.38 tokens/sec
- **基线**: 51.77 tokens/sec
- **提升**: +1.18%
- **目标**: 80.00 tokens/sec
- **差距**: 27.62 t/s (34.5%)
- **成功请求**: 40/40 ✅

### 关键发现

#### 1. 批处理大小受限
从日志分析：
- 批处理大小主要限制在 **1-4个请求**
- 即使配置了 `max_batch_size=32` 和 `n_seq_max=64`，实际批处理仍然很小
- 这表明有其他因素限制了批处理大小的形成

#### 2. 可能的原因

**A. 上下文长度限制**
- `maxContextLength_ = 2048`
- `runningLength > maxContextLength_ * 0.9` 时停止形成新批处理
- 即使单个请求prompt较短，当运行中请求累积时，可能导致新批处理无法形成

**B. 序列ID可用性**
- `availableSeqIds < 4` 时会限制 `dynamicBatchSize`
- 虽然有 `availableSeqIds * 1.5` 的放宽，但仍可能成为瓶颈

**C. 批处理效率递减**
- 当批处理中请求完成时间不一致时，批处理效率从100%递减到25%或更低
- 导致GPU利用率不足

**D. 调度循环频率**
- 当前使用固定的调度间隔（10μs/50μs）
- 可能无法及时形成新的批处理

#### 3. 优化方向

**高优先级**（解决34.5%差距的关键）:

1. **批处理大小限制分析**
   - 问题: 实际批处理大小只有1-4个请求
   - 需要: 详细日志分析，找出限制因素
   - 预期收益: 15-25%

2. **批处理效率优化**
   - 问题: 批处理效率递减（100% → 25%）
   - 方案: 动态批处理重组机制
   - 预期收益: 15-20%

3. **调度循环优化**
   - 问题: 可能无法及时响应请求完成
   - 方案: 使用原子操作减少锁竞争，提升响应速度
   - 预期收益: 5-10%

**中优先级**:

4. **增量输入准备**
   - 问题: 每次迭代都重新构建整个批处理输入
   - 方案: 真正实现增量追加（只添加新tokens）
   - 预期收益: 5-10%

5. **序列ID分配优化**
   - 问题: 可能成为瓶颈
   - 方案: 批量分配、无锁数据结构
   - 预期收益: 5-10%

## 下一步行动

1. ✅ 回退到v13稳定版本（已完成）
2. 🔄 分析批处理大小限制的根本原因（进行中）
3. ⏸️ 逐步应用原子操作优化
4. ⏸️ 实施批处理效率优化
