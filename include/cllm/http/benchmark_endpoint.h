/**
 * @file benchmark_endpoint.h
 * @brief Benchmarkç«¯ç‚¹ï¼Œç”¨äºæœåŠ¡å™¨ç«¯æ€§èƒ½æµ‹è¯•
 * @author cLLM Team
 * @date 2026-01-20
 */

#ifndef CLLM_BENCHMARK_ENDPOINT_H
#define CLLM_BENCHMARK_ENDPOINT_H

#include <memory>
#include "cllm/http/api_endpoint.h"
#include "cllm/http/request.h"
#include "cllm/http/response.h"

namespace cllm {

class GenerateEndpoint;
class Scheduler;
class ITokenizer;
class ModelExecutor;

/**
 * @brief Benchmarkç«¯ç‚¹ç±»
 * 
 * å¤„ç†/benchmark APIè¯·æ±‚ï¼Œåœ¨æœåŠ¡å™¨ç«¯å†…éƒ¨å¹¶å‘å¤„ç†å¤šä¸ªè¯·æ±‚ï¼Œ
 * æ¶ˆé™¤ç½‘ç»œä¼ è¾“å’ŒPythonç«¯å¼€é”€ï¼Œç›´æ¥æµ‹è¯•C++å†…éƒ¨æ€§èƒ½ã€‚
 * 
 * ğŸ”¥ ä¼˜åŒ–ç‰ˆæœ¬ï¼šç›´æ¥è°ƒç”¨Schedulerå’ŒTokenizerï¼Œç»•è¿‡GenerateEndpointå’ŒHTTPå±‚å¼€é”€ã€‚
 * 
 * è¯·æ±‚æ ¼å¼:
 * {
 *   "requests": 40,           // æ€»è¯·æ±‚æ•°
 *   "concurrency": 8,         // å¹¶å‘æ•°
 *   "max_tokens": 50,         // æ¯ä¸ªè¯·æ±‚çš„æœ€å¤§tokenæ•°
 *   "prompt": "Hello, world", // æç¤ºè¯ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ï¼‰
 *   "temperature": 0.7       // æ¸©åº¦å‚æ•°ï¼ˆå¯é€‰ï¼‰
 * }
 * 
 * å“åº”æ ¼å¼:
 * {
 *   "success": true,
 *   "data": {
 *     "total_requests": 40,
 *     "successful_requests": 38,
 *     "failed_requests": 2,
 *     "avg_response_time": 7.50,
 *     "min_response_time": 1.09,
 *     "max_response_time": 8.60,
 *     "avg_throughput": 49.13,
 *     "avg_tokens_per_second": 7.65,
 *     "total_tokens_processed": 2408,
 *     "avg_generated_tokens": 50.00,
 *     "total_time": 38.68
 *   }
 * }
 */
class BenchmarkEndpoint : public ApiEndpoint {
public:
    /**
     * @brief æ„é€ å‡½æ•°ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼šç›´æ¥ä½¿ç”¨Schedulerå’ŒTokenizerï¼‰
     * @param scheduler ScheduleræŒ‡é’ˆï¼Œç”¨äºç›´æ¥è°ƒåº¦è¯·æ±‚
     * @param tokenizer TokenizeræŒ‡é’ˆï¼Œç”¨äºç¼–ç /è§£ç 
     */
    BenchmarkEndpoint(Scheduler* scheduler, ITokenizer* tokenizer);
    
    /**
     * @brief æ„é€ å‡½æ•°ï¼ˆæœ€ä¼˜ç‰ˆæœ¬ï¼šä½¿ç”¨ç‹¬ç«‹çš„Schedulerå®ä¾‹ï¼Œå‚è€ƒStage 15ï¼‰
     * @param modelExecutor ModelExecutoræŒ‡é’ˆï¼Œç”¨äºåˆ›å»ºç‹¬ç«‹çš„Scheduler
     * @param tokenizer TokenizeræŒ‡é’ˆï¼Œç”¨äºç¼–ç /è§£ç 
     * @param maxBatchSize æœ€å¤§æ‰¹å¤„ç†å¤§å°ï¼ˆé»˜è®¤8ï¼Œä¸Stage 15ä¸€è‡´ï¼‰
     * @param maxContextLength æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆé»˜è®¤2048ï¼Œä¸Stage 15ä¸€è‡´ï¼‰
     */
    BenchmarkEndpoint(ModelExecutor* modelExecutor, ITokenizer* tokenizer, 
                      size_t maxBatchSize = 8, size_t maxContextLength = 2048);
    
    /**
     * @brief æ„é€ å‡½æ•°ï¼ˆå…¼å®¹ç‰ˆæœ¬ï¼šä½¿ç”¨GenerateEndpointï¼‰
     * @param generateEndpoint GenerateEndpointæŒ‡é’ˆï¼Œç”¨äºå¤„ç†å®é™…è¯·æ±‚
     */
    explicit BenchmarkEndpoint(GenerateEndpoint* generateEndpoint);
    
    /**
     * @brief ææ„å‡½æ•°
     */
    ~BenchmarkEndpoint();
    
    /**
     * @brief å¤„ç†HTTPè¯·æ±‚
     * @param request HTTPè¯·æ±‚å¯¹è±¡
     * @return HTTPå“åº”å¯¹è±¡
     */
    HttpResponse handle(const HttpRequest& request) override;
    
    /**
     * @brief è®¾ç½®GenerateEndpointï¼ˆå…¼å®¹æ¨¡å¼ï¼‰
     * @param generateEndpoint GenerateEndpointæŒ‡é’ˆ
     */
    void setGenerateEndpoint(GenerateEndpoint* generateEndpoint);
    
    /**
     * @brief è®¾ç½®Schedulerå’ŒTokenizerï¼ˆä¼˜åŒ–æ¨¡å¼ï¼‰
     * @param scheduler ScheduleræŒ‡é’ˆ
     * @param tokenizer TokenizeræŒ‡é’ˆ
     */
    void setSchedulerAndTokenizer(Scheduler* scheduler, ITokenizer* tokenizer);

private:
    /**
     * @brief Benchmarkè¯·æ±‚å‚æ•°ç»“æ„
     */
    struct BenchmarkRequest {
        int requests = 40;          ///< æ€»è¯·æ±‚æ•°
        int concurrency = 8;       ///< å¹¶å‘æ•°
        int maxTokens = 50;        ///< æ¯ä¸ªè¯·æ±‚çš„æœ€å¤§tokenæ•°
        std::string prompt = "Hello, world! How are you today?";  ///< æç¤ºè¯
        float temperature = 0.7f;  ///< æ¸©åº¦å‚æ•°
    };
    
    /**
     * @brief å•ä¸ªè¯·æ±‚çš„ç»“æœ
     */
    struct RequestResult {
        bool success = false;              ///< æ˜¯å¦æˆåŠŸ
        double responseTime = 0.0;         ///< å“åº”æ—¶é—´ï¼ˆç§’ï¼‰
        size_t generatedTokens = 0;         ///< ç”Ÿæˆçš„tokenæ•°
        size_t totalTokens = 0;            ///< æ€»tokenæ•°ï¼ˆprompt + generatedï¼‰
        double tokensPerSecond = 0.0;      ///< tokens per second
        std::string errorMessage;          ///< é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
    };
    
    /**
     * @brief ç»Ÿè®¡ç»“æœ
     */
    struct Statistics {
        int totalRequests = 0;
        int successfulRequests = 0;
        int failedRequests = 0;
        double avgResponseTime = 0.0;
        double minResponseTime = 0.0;
        double maxResponseTime = 0.0;
        double avgThroughput = 0.0;         ///< å¹³å‡ååé‡ï¼ˆtokens/secï¼‰
        double avgTokensPerSecond = 0.0;   ///< å¹³å‡tokens per second
        size_t totalTokensProcessed = 0;
        double avgGeneratedTokens = 0.0;
        double totalTime = 0.0;            ///< æ€»æµ‹è¯•æ—¶é—´
    };
    
    BenchmarkRequest parseRequest(const HttpRequest& request);  ///< è§£æbenchmarkè¯·æ±‚
    RequestResult executeSingleRequest(const BenchmarkRequest& params, int requestIndex);  ///< æ‰§è¡Œå•ä¸ªè¯·æ±‚ï¼ˆå…¼å®¹æ¨¡å¼ï¼šé€šè¿‡GenerateEndpointï¼‰
    RequestResult executeSingleRequestDirect(const BenchmarkRequest& params, int requestIndex);  ///< æ‰§è¡Œå•ä¸ªè¯·æ±‚ï¼ˆä¼˜åŒ–æ¨¡å¼ï¼šç›´æ¥è°ƒç”¨Schedulerï¼‰
    Statistics calculateStatistics(const std::vector<RequestResult>& results, double totalTime);  ///< è®¡ç®—ç»Ÿè®¡æ•°æ®
    HttpResponse buildResponse(const Statistics& stats);  ///< æ„å»ºå“åº”
    
    bool useDirectMode_;  ///< æ˜¯å¦ä½¿ç”¨ç›´æ¥æ¨¡å¼ï¼ˆç›´æ¥è°ƒç”¨Schedulerï¼‰
    bool useIndependentScheduler_;  ///< æ˜¯å¦ä½¿ç”¨ç‹¬ç«‹çš„Schedulerå®ä¾‹ï¼ˆæœ€ä¼˜æ¨¡å¼ï¼‰
    GenerateEndpoint* generateEndpoint_;  ///< GenerateEndpointæŒ‡é’ˆï¼ˆå…¼å®¹æ¨¡å¼ï¼‰
    Scheduler* scheduler_;  ///< ScheduleræŒ‡é’ˆï¼ˆä¼˜åŒ–æ¨¡å¼ï¼Œå…±äº«Schedulerï¼‰
    std::unique_ptr<Scheduler> independentScheduler_;  ///< ç‹¬ç«‹çš„Schedulerå®ä¾‹ï¼ˆæœ€ä¼˜æ¨¡å¼ï¼‰
    ITokenizer* tokenizer_;  ///< TokenizeræŒ‡é’ˆï¼ˆä¼˜åŒ–æ¨¡å¼ï¼‰
    size_t maxBatchSize_;  ///< æœ€å¤§æ‰¹å¤„ç†å¤§å°ï¼ˆç”¨äºåˆ›å»ºç‹¬ç«‹Schedulerï¼‰
    size_t maxContextLength_;  ///< æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆç”¨äºåˆ›å»ºç‹¬ç«‹Schedulerï¼‰
};

} // namespace cllm

#endif // CLLM_BENCHMARK_ENDPOINT_H
