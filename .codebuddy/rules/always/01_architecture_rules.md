# ğŸ—ï¸ cLLM æ¶æ„è®¾è®¡çº¦æŸ

> **ä¼˜å…ˆçº§**: HIGH | ä¿è¯ç³»ç»Ÿæ¶æ„å®Œæ•´æ€§å’Œæ¨¡å—è§£è€¦

---

## ğŸ¯ æ¶æ„åŸåˆ™

### 1. æ¨¡å—åŒ–è®¾è®¡

```
cLLM é‡‡ç”¨åˆ†å±‚æ¶æ„:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         HTTP Server Layer               â”‚  â† å¯¹å¤–API
â”‚  (è‡ªå®šä¹‰HTTP Server - åŸºäºAsio)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Request Processing Layer           â”‚
â”‚  (Validator, Handler, Response)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     TokenizerManager Layer              â”‚  â† æ ¸å¿ƒä¸šåŠ¡
â”‚  (Tokenizer, Generator)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Model Executor Layer                â”‚
â”‚  (Inference Engine, Sampler)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Backend Layer (LibTorch/Kylin)       â”‚  â† æ¨ç†åç«¯
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Infrastructure Layer                  â”‚
â”‚ (Logger, ThreadPool, KVCache, Memory)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. ä¾èµ–è§„åˆ™

**å…è®¸çš„ä¾èµ–æ–¹å‘** (ä¸Šå±‚ä¾èµ–ä¸‹å±‚):

```
HTTP â†’ TokenizerManager â†’ ModelExecutor â†’ Backend â†’ Infrastructure
  â†“                           â†“
Request                    KVCache
                              â†“
                        Infrastructure
```

**ç¦æ­¢çš„ä¾èµ–**:

- âŒ Infrastructure ä¾èµ–ä¸Šå±‚æ¨¡å—
- âŒ Backend ä¾èµ– TokenizerManager
- âŒ ä»»ä½•å¾ªç¯ä¾èµ–

---

## ğŸ“¦ æ ¸å¿ƒæ¨¡å—è¯´æ˜

### 1. Tokenizer æ¨¡å—

**ä½ç½®**: `include/cllm/tokenizer/`, `src/tokenizer/`, `src/CTokenizer/`

**èŒè´£**:
- æ–‡æœ¬ç¼–ç /è§£ç 
- æ”¯æŒå¤šç§åˆ†è¯å™¨æ ¼å¼ (HF, SentencePiece, Native)
- Tokenç”Ÿæˆæµå¼è¾“å‡º

**æ¥å£å®šä¹‰**:

```cpp
namespace cllm {

// åŸºç¡€æ¥å£ (æ‰€æœ‰Tokenizerå¿…é¡»å®ç°)
class ITokenizer {
public:
    virtual ~ITokenizer() = default;
    
    virtual bool load(const std::string& modelPath) = 0;
    virtual std::vector<int> encode(const std::string& text, bool addSpecialTokens) = 0;
    virtual std::string decode(const std::vector<int>& ids, bool skipSpecialTokens) = 0;
    
    virtual int getVocabSize() const = 0;
    virtual int getBosId() const = 0;
    virtual int getEosId() const = 0;
    virtual int getPadId() const = 0;
    virtual int getUnkId() const = 0;
};

// å®ç°ç±»
class HFTokenizer : public ITokenizer { /* ... */ };
class NativeTokenizer : public ITokenizer { /* ... */ };
class UnifiedTokenizer : public ITokenizer { /* ... */ };

} // namespace cllm
```

**ä¾èµ–è§„åˆ™**:
- âœ… å¯ä¾èµ–: `common/logger`, `common/utils`
- âŒ ç¦æ­¢ä¾èµ–: `model/executor`, `http/`
- âš ï¸  æ¡ä»¶ä¾èµ–: `tokenizers-cpp` (æ¡ä»¶ç¼–è¯‘)

---

### 2. ModelExecutor æ¨¡å—

**ä½ç½®**: `include/cllm/model/`, `src/model/`

**èŒè´£**:
- æ¨¡å‹æ¨ç†
- Batchå¤„ç†
- é‡‡æ ·ç­–ç•¥
- KVCacheç®¡ç†

**æ¥å£å®šä¹‰**:

```cpp
namespace cllm {

class ModelExecutor {
public:
    // å•æ¬¡æ¨ç†
    torch::Tensor forward(
        const torch::Tensor& inputIds,
        const torch::Tensor& attentionMask,
        std::optional<torch::Tensor> pastKeyValues = std::nullopt
    );
    
    // ç”Ÿæˆ (å®Œæ•´)
    std::vector<int> generate(
        const std::vector<int>& inputIds,
        int maxTokens,
        float temperature = 1.0f
    );
    
    // æµå¼ç”Ÿæˆ
    int generateNext(
        const torch::Tensor& inputIds,
        const torch::Tensor& attentionMask,
        float temperature = 1.0f
    );
};

} // namespace cllm
```

**ä¾èµ–è§„åˆ™**:
- âœ… å¯ä¾èµ–: `kv_cache/cache`, `sampler/sampler`, `common/*`
- âŒ ç¦æ­¢ä¾èµ–: `tokenizer/manager`, `http/`
- âœ… å¯è¢«ä¾èµ–: `tokenizer/manager`

---

### 3. KVCache æ¨¡å—

**ä½ç½®**: `include/cllm/kv_cache/`, `src/kv_cache/`

**èŒè´£**:
- ç¼“å­˜ Key-Value states
- å†…å­˜ç®¡ç†
- ç¼“å­˜æ·˜æ±°ç­–ç•¥

**æ¥å£å®šä¹‰**:

```cpp
namespace cllm {

class KVCache {
public:
    void insert(const std::string& key, const torch::Tensor& kv);
    std::optional<torch::Tensor> get(const std::string& key);
    void evict(const std::string& key);
    void clear();
    
    size_t size() const;
    size_t memoryUsage() const;
};

} // namespace cllm
```

**ä¾èµ–è§„åˆ™**:
- âœ… å¯ä¾èµ–: `common/logger`, `common/memory_utils`
- âŒ ç¦æ­¢ä¾èµ–: ä»»ä½•ä¸šåŠ¡æ¨¡å—
- âœ… å¯è¢«ä¾èµ–: `model/executor`

---

### 4. HTTP Server æ¨¡å—

**ä½ç½®**: `include/cllm/http/`, `src/http/`

**èŒè´£**:
- HTTPè¯·æ±‚å¤„ç†
- OpenAI APIå…¼å®¹
- è¯·æ±‚éªŒè¯
- å“åº”æ„å»º

**æ¥å£å®šä¹‰**:

```cpp
namespace cllm {

class HttpServer {
public:
    void start(const std::string& host, int port);
    void stop();
    
    void registerEndpoint(const std::string& path, EndpointHandler handler);
};

// Endpoint handlers
void handleGenerate(const HttpRequest& req, HttpResponse& resp);
void handleEncode(const HttpRequest& req, HttpResponse& resp);
void handleHealth(const HttpRequest& req, HttpResponse& resp);

} // namespace cllm
```

**ä¾èµ–è§„åˆ™**:
- âœ… å¯ä¾èµ–: `tokenizer/manager`, `model/executor`, `common/*`
- âŒ ç¦æ­¢ä¾èµ–: åº•å±‚Backend

---

### 5. Scheduler æ¨¡å—

**ä½ç½®**: `include/cllm/scheduler/`, `src/scheduler/`

**èŒè´£**:
- è¯·æ±‚è°ƒåº¦
- æ‰¹å¤„ç†ä¼˜åŒ–
- ä¼˜å…ˆçº§ç®¡ç†

**æ¥å£å®šä¹‰**:

```cpp
namespace cllm {

class Scheduler {
public:
    void submit(std::shared_ptr<Request> request);
    std::vector<std::shared_ptr<Request>> schedule();
    
    void setPriority(const std::string& requestId, int priority);
    void cancel(const std::string& requestId);
};

} // namespace cllm
```

---

## ğŸ”§ æ¨¡å—é›†æˆè§„èŒƒ

### 1. TokenizerManager é›†æˆ

```cpp
// âœ… æ­£ç¡®çš„åˆå§‹åŒ–é¡ºåº
auto modelExecutor = std::make_unique<ModelExecutor>(config);
auto kvCache = std::make_shared<KVCache>(cacheConfig);

modelExecutor->setKVCache(kvCache.get());

auto tokenizerManager = std::make_unique<TokenizerManager>(
    modelPath,
    modelExecutor.get(),
    TokenizerImpl::AUTO  // è‡ªåŠ¨æ£€æµ‹
);
```

### 2. HTTP Server é›†æˆ

```cpp
// âœ… æ­£ç¡®çš„æœåŠ¡å¯åŠ¨æµç¨‹
HttpServer server;

// è®¾ç½®ä¾èµ–
server.setTokenizerManager(tokenizerManager.get());
server.setModelExecutor(modelExecutor.get());

// æ³¨å†Œç«¯ç‚¹
server.registerEndpoint("/v1/chat/completions", handleGenerate);
server.registerEndpoint("/v1/embeddings", handleEncode);
server.registerEndpoint("/health", handleHealth);

// å¯åŠ¨æœåŠ¡
server.start("0.0.0.0", 8080);
```

---

## ğŸ“ æ¨¡å—ä¿®æ”¹è§„èŒƒ

### ä¿®æ”¹å‰æ£€æŸ¥æ¸…å•

åœ¨ä¿®æ”¹ä»»ä½•æ¨¡å—å‰,å¿…é¡»æ£€æŸ¥:

1. **ä¾èµ–å½±å“åˆ†æ**
   ```bash
   # æœç´¢æ‰€æœ‰ä¾èµ–è¯¥æ¨¡å—çš„ä»£ç 
   search_content("include.*<cllm/æ¨¡å—å/", "include,src")
   ```

2. **æ¥å£å…¼å®¹æ€§**
   - æ˜¯å¦æ”¹å˜äº†å…¬å…±æ¥å£?
   - æ˜¯å¦éœ€è¦æ›´æ–°ä¾èµ–æ¨¡å—?
   - æ˜¯å¦éœ€è¦æ›´æ–°å•å…ƒæµ‹è¯•?

3. **å¤´æ–‡ä»¶ä¿®æ”¹åŒæ­¥**
   ```
   ä¿®æ”¹ include/cllm/tokenizer/hf_tokenizer.h
   â†“ å¿…é¡»åŒæ­¥æ£€æŸ¥
   src/tokenizer/hf_tokenizer.cpp
   ```

4. **CMakeLists.txt æ›´æ–°**
   - æ–°å¢æºæ–‡ä»¶éœ€æ·»åŠ åˆ° `target_sources`
   - æ–°å¢ä¾èµ–éœ€æ·»åŠ åˆ° `target_link_libraries`

---

## ğŸ­ è®¾è®¡æ¨¡å¼åº”ç”¨

### 1. Factory æ¨¡å¼ (Tokenizeråˆ›å»º)

```cpp
// âœ… ä½¿ç”¨Factoryç»Ÿä¸€åˆ›å»º
class TokenizerFactory {
public:
    static std::unique_ptr<ITokenizer> create(
        const std::string& modelPath,
        TokenizerImpl impl = TokenizerImpl::AUTO
    );
};

// ä½¿ç”¨
auto tokenizer = TokenizerFactory::create(modelPath);
```

### 2. Strategy æ¨¡å¼ (é‡‡æ ·ç­–ç•¥)

```cpp
class SamplerStrategy {
public:
    virtual int sample(const torch::Tensor& logits) = 0;
};

class GreedySampler : public SamplerStrategy { /* ... */ };
class TopKSampler : public SamplerStrategy { /* ... */ };
class TopPSampler : public SamplerStrategy { /* ... */ };
```

### 3. Observer æ¨¡å¼ (æµå¼ç”Ÿæˆ)

```cpp
class GenerationObserver {
public:
    virtual void onTokenGenerated(int tokenId, const std::string& text) = 0;
    virtual void onComplete() = 0;
};

// StreamGenerator é€šçŸ¥è§‚å¯Ÿè€…
for (auto observer : observers_) {
    observer->onTokenGenerated(tokenId, text);
}
```

### 4. Singleton æ¨¡å¼ (Logger)

```cpp
// âœ… ä½¿ç”¨å±€éƒ¨é™æ€å˜é‡å®ç°çº¿ç¨‹å®‰å…¨å•ä¾‹
class Logger {
public:
    static Logger& instance() {
        static Logger instance;
        return instance;
    }
    
private:
    Logger() = default;
    Logger(const Logger&) = delete;
    Logger& operator=(const Logger&) = delete;
};
```

---

## ğŸ”’ çº¿ç¨‹å®‰å…¨è§„èŒƒ

### 1. å…±äº«èµ„æºä¿æŠ¤

```cpp
class KVCache {
private:
    mutable std::mutex mutex_;
    std::unordered_map<std::string, torch::Tensor> cache_;
    
public:
    void insert(const std::string& key, const torch::Tensor& kv) {
        std::lock_guard<std::mutex> lock(mutex_);
        cache_[key] = kv;
    }
    
    std::optional<torch::Tensor> get(const std::string& key) {
        std::lock_guard<std::mutex> lock(mutex_);
        auto it = cache_.find(key);
        if (it != cache_.end()) {
            return it->second;
        }
        return std::nullopt;
    }
};
```

### 2. çº¿ç¨‹æ± ä½¿ç”¨

```cpp
#include <BS_thread_pool.hpp>

// âœ… æ¨è: ä½¿ç”¨BS::thread_pool
BS::thread_pool pool(std::thread::hardware_concurrency());

// æäº¤ä»»åŠ¡
auto future = pool.submit_task([](int x) {
    return x * x;
}, 42);

int result = future.get();
```

---

## ğŸ“Š æ€§èƒ½ç›‘æ§åŸ‹ç‚¹

### 1. å…³é”®è·¯å¾„è®¡æ—¶

```cpp
#include "cllm/common/timer.h"

void processRequest() {
    Timer timer("processRequest");
    
    // ä¸šåŠ¡é€»è¾‘
    
    CLLM_INFO("Request processed in %.2f ms", timer.elapsed());
}
```

### 2. ç»Ÿè®¡ä¿¡æ¯æ”¶é›†

```cpp
class TokenizerStats {
public:
    void incrementEncodeCount() { ++encodeCount_; }
    void addEncodeTime(float time) { totalEncodeTime_ += time; }
    
    float getAvgEncodeTime() const {
        return totalEncodeTime_ / encodeCount_;
    }
    
private:
    std::atomic<size_t> encodeCount_{0};
    std::atomic<float> totalEncodeTime_{0.0f};
};
```

---

## ğŸš¨ æ¶æ„å˜æ›´å®¡æ‰¹

ä»¥ä¸‹å˜æ›´éœ€ç‰¹åˆ«è°¨æ…:

1. **ä¿®æ”¹æ ¸å¿ƒæ¥å£** (ITokenizer, ModelExecutor)
   - å½±å“èŒƒå›´: æ‰€æœ‰å®ç°ç±»
   - éœ€è¦: å®Œæ•´çš„è¿ç§»è®¡åˆ’

2. **æ·»åŠ æ–°çš„æ¨¡å—ä¾èµ–**
   - å½±å“èŒƒå›´: ç¼–è¯‘ç³»ç»Ÿ
   - éœ€è¦: æ›´æ–°CMakeLists.txt, æ–‡æ¡£

3. **ä¿®æ”¹çº¿ç¨‹æ¨¡å‹**
   - å½±å“èŒƒå›´: æ•´ä½“æ€§èƒ½
   - éœ€è¦: æ€§èƒ½æµ‹è¯•éªŒè¯

4. **ä¿®æ”¹æ•°æ®æµå‘**
   - å½±å“èŒƒå›´: æ¶æ„å®Œæ•´æ€§
   - éœ€è¦: æ¶æ„å›¾æ›´æ–°

---

## ğŸ“š ç›¸å…³è®¾è®¡æ–‡æ¡£

- **æ•´ä½“æ¶æ„**: `docs/cLLMè¯¦ç»†è®¾è®¡.md`
- **Tokenizerè®¾è®¡**: `docs/modules/åˆ†è¯å™¨è®¾è®¡.md`
- **è°ƒåº¦å™¨è®¾è®¡**: `docs/modules/è°ƒåº¦å™¨æ¨¡å—è®¾è®¡.md`
- **ç»„ä»¶äº¤äº’**: `docs/ç»„ä»¶äº¤äº’è®¾è®¡.md`

---

**æœ€åæ›´æ–°**: 2026-01-11  
**ç»´æŠ¤è€…**: cLLM Architecture Team
