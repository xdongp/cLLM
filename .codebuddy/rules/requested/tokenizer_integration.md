# ğŸ”Œ Tokenizeré›†æˆä¸“é¡¹è§„åˆ™

> **ä½¿ç”¨åœºæ™¯**: é›†æˆæ–°çš„Tokenizerå®ç°æˆ–ä¿®æ”¹ç°æœ‰Tokenizer

---

## ğŸ“‹ é›†æˆæ£€æŸ¥æ¸…å•

### 1. å®ç°ITokenizeræ¥å£

```cpp
class NewTokenizer : public ITokenizer {
public:
    // âœ… å¿…é¡»å®ç°çš„æ¥å£
    bool load(const std::string& modelPath) override;
    std::vector<int> encode(const std::string& text, bool addSpecialTokens) override;
    std::string decode(const std::vector<int>& ids, bool skipSpecialTokens) override;
    
    int getVocabSize() const override;
    std::string idToToken(int id) const override;
    int tokenToId(const std::string& token) const override;
    
    int getBosId() const override;
    int getEosId() const override;
    int getPadId() const override;
    int getUnkId() const override;
    
    ModelType getModelType() const override;
};
```

### 2. æ¡ä»¶ç¼–è¯‘ä¿æŠ¤

```cpp
// include/cllm/tokenizer/new_tokenizer.h
#pragma once

#include "i_tokenizer.h"

#ifdef USE_NEW_TOKENIZER_LIB
#include <new_tokenizer_lib.h>
#endif

namespace cllm {

class NewTokenizer : public ITokenizer {
public:
    NewTokenizer(ModelType modelType = ModelType::AUTO);
    ~NewTokenizer() override;
    
    bool load(const std::string& modelPath) override;
    // ...

private:
#ifdef USE_NEW_TOKENIZER_LIB
    std::unique_ptr<new_tokenizer::Tokenizer> impl_;
#else
    // å›é€€å®ç°æˆ–æŠ›å‡ºå¼‚å¸¸
#endif
};

} // namespace cllm
```

### 3. æ›´æ–°CMakeLists.txt

```cmake
# æ·»åŠ ç¼–è¯‘é€‰é¡¹
option(USE_NEW_TOKENIZER_LIB "Use new tokenizer library" OFF)

if(USE_NEW_TOKENIZER_LIB)
    message(STATUS "âœ… Enabling new tokenizer support")
    
    # æŸ¥æ‰¾åº“
    find_path(NEW_TOKENIZER_INCLUDE_DIR 
        NAMES new_tokenizer.h
        PATHS /usr/local/include /opt/homebrew/include
    )
    
    find_library(NEW_TOKENIZER_LIBRARY 
        NAMES new_tokenizer
        PATHS /usr/local/lib /opt/homebrew/lib
    )
    
    if(NEW_TOKENIZER_INCLUDE_DIR AND NEW_TOKENIZER_LIBRARY)
        message(STATUS "   Include: ${NEW_TOKENIZER_INCLUDE_DIR}")
        message(STATUS "   Library: ${NEW_TOKENIZER_LIBRARY}")
        
        add_compile_definitions(USE_NEW_TOKENIZER_LIB)
        include_directories(${NEW_TOKENIZER_INCLUDE_DIR})
        
        set(NEW_TOKENIZER_LIBRARIES ${NEW_TOKENIZER_LIBRARY})
    else()
        message(WARNING "âš ï¸  new tokenizer not found")
        set(USE_NEW_TOKENIZER_LIB OFF)
    endif()
endif()

# æ·»åŠ åˆ°é“¾æ¥åº“
target_link_libraries(cllm_core
    # ... å…¶ä»–åº“ ...
    ${NEW_TOKENIZER_LIBRARIES}
)
```

### 4. æ›´æ–°TokenizerManageræ£€æµ‹é€»è¾‘

```cpp
// src/tokenizer/manager.cpp

namespace {
    bool hasNewTokenizerFormat(const std::string& modelPath) {
        namespace fs = std::filesystem;
        // æ£€æµ‹ç‰¹å®šæ–‡ä»¶
        return fs::exists(fs::path(modelPath) / "new_tokenizer.json");
    }
}

TokenizerManager::TokenizerManager(...) {
    switch(impl) {
        case TokenizerImpl::AUTO:
            // âœ… æ·»åŠ åˆ°è‡ªåŠ¨æ£€æµ‹é€»è¾‘
            if (hasNewTokenizerFormat(modelPath)) {
                CLLM_INFO("âœ… Detected new tokenizer format");
                tokenizer_ = new NewTokenizer(modelType);
                
            } else if (hasTokenizerJson(modelPath)) {
                CLLM_INFO("âœ… Detected HuggingFace format");
                tokenizer_ = new HFTokenizer(modelType);
                
            } else if (hasTokenizerModel(modelPath)) {
                CLLM_INFO("âœ… Detected SentencePiece format");
                tokenizer_ = new NativeTokenizer(modelType);
                
            } else {
                CLLM_WARN("âš ï¸  Unknown format, fallback to Native");
                tokenizer_ = new NativeTokenizer(modelType);
            }
            break;
    }
}
```

### 5. ç¼–å†™å•å…ƒæµ‹è¯•

```cpp
// tests/test_new_tokenizer.cpp
#include <gtest/gtest.h>
#include "cllm/tokenizer/new_tokenizer.h"

class NewTokenizerTest : public ::testing::Test {
protected:
    void SetUp() override {
        tokenizer_ = std::make_unique<cllm::NewTokenizer>();
        ASSERT_TRUE(tokenizer_->load("path/to/test/model"));
    }
    
    std::unique_ptr<cllm::NewTokenizer> tokenizer_;
};

TEST_F(NewTokenizerTest, EncodeDecodeRoundtrip) {
    std::string text = "Hello, world!";
    auto ids = tokenizer_->encode(text, true);
    auto decoded = tokenizer_->decode(ids, true);
    EXPECT_EQ(text, decoded);
}

TEST_F(NewTokenizerTest, SpecialTokens) {
    EXPECT_GE(tokenizer_->getBosId(), 0);
    EXPECT_GE(tokenizer_->getEosId(), 0);
    EXPECT_GE(tokenizer_->getVocabSize(), 1000);
}

TEST_F(NewTokenizerTest, EmptyText) {
    auto ids = tokenizer_->encode("", false);
    EXPECT_TRUE(ids.empty());
}

TEST_F(NewTokenizerTest, LongText) {
    std::string longText(10000, 'a');
    auto ids = tokenizer_->encode(longText, false);
    EXPECT_GT(ids.size(), 0);
}
```

---

## ğŸ”§ å®ç°æœ€ä½³å®è·µ

### 1. é”™è¯¯å¤„ç†

```cpp
bool NewTokenizer::load(const std::string& modelPath) {
#ifdef USE_NEW_TOKENIZER_LIB
    try {
        impl_ = new_tokenizer::Tokenizer::FromFile(modelPath);
        if (!impl_) {
            CLLM_ERROR("Failed to load tokenizer: %s", modelPath.c_str());
            return false;
        }
        
        CLLM_INFO("âœ… NewTokenizer loaded: %s", modelPath.c_str());
        return true;
        
    } catch (const std::exception& e) {
        CLLM_ERROR("Exception loading tokenizer: %s", e.what());
        return false;
    }
#else
    CLLM_ERROR("NewTokenizer requires USE_NEW_TOKENIZER_LIB=ON");
    return false;
#endif
}
```

### 2. ç‰¹æ®ŠTokenå¤„ç†

```cpp
void NewTokenizer::loadConfig(const std::string& modelPath) {
    namespace fs = std::filesystem;
    
    std::string configPath = (fs::path(modelPath) / "config.json").string();
    if (!fs::exists(configPath)) return;
    
    std::ifstream f(configPath);
    if (!f.is_open()) return;
    
    try {
        auto config = nlohmann::json::parse(f);
        
        // è¯»å–ç‰¹æ®ŠToken IDs
        if (config.contains("bos_token_id")) {
            bosId_ = config["bos_token_id"].get<int>();
        }
        if (config.contains("eos_token_id")) {
            eosId_ = config["eos_token_id"].get<int>();
        }
        if (config.contains("pad_token_id") && !config["pad_token_id"].is_null()) {
            padId_ = config["pad_token_id"].get<int>();
        }
        if (config.contains("unk_token_id")) {
            unkId_ = config["unk_token_id"].get<int>();
        }
        
        CLLM_INFO("Loaded special tokens: BOS=%d, EOS=%d, PAD=%d, UNK=%d",
                  bosId_, eosId_, padId_, unkId_);
        
    } catch (const std::exception& e) {
        CLLM_WARN("Failed to parse config: %s", e.what());
    }
}
```

### 3. æ€§èƒ½ä¼˜åŒ–

```cpp
// ç¼“å­˜ç¼–ç ç»“æœ
class CachedNewTokenizer : public NewTokenizer {
    std::unordered_map<std::string, std::vector<int>> cache_;
    size_t maxCacheSize_ = 10000;
    
public:
    std::vector<int> encode(const std::string& text, bool addSpecialTokens) override {
        // æŸ¥ç¼“å­˜
        auto it = cache_.find(text);
        if (it != cache_.end()) {
            return it->second;
        }
        
        // ç¼–ç 
        auto result = NewTokenizer::encode(text, addSpecialTokens);
        
        // ç¼“å­˜
        if (cache_.size() < maxCacheSize_) {
            cache_[text] = result;
        }
        
        return result;
    }
};
```

---

## ğŸ“Š é›†æˆéªŒè¯æ­¥éª¤

### 1. ç¼–è¯‘éªŒè¯

```bash
cd build && rm -rf *
cmake .. -DUSE_NEW_TOKENIZER_LIB=ON
make -j8

# æ£€æŸ¥æ˜¯å¦æˆåŠŸé“¾æ¥
ldd bin/cllm_server | grep new_tokenizer
```

### 2. å•å…ƒæµ‹è¯•

```bash
./bin/test_new_tokenizer
```

### 3. é›†æˆæµ‹è¯•

```bash
# ä½¿ç”¨æµ‹è¯•æ¨¡å‹
./bin/test_tokenizer_manager --model=/path/to/test/model

# æ£€æŸ¥æ—¥å¿—
cat logs/cllm.log | grep "NewTokenizer"
```

### 4. æ€§èƒ½æµ‹è¯•

```bash
# å¯¹æ¯”ä¸åŒTokenizeræ€§èƒ½
./bin/benchmark_tokenizer --impl=new
./bin/benchmark_tokenizer --impl=hf
./bin/benchmark_tokenizer --impl=native
```

---

## ğŸš¨ å¸¸è§é—®é¢˜

### é—®é¢˜1: é“¾æ¥å¤±è´¥

```markdown
é”™è¯¯: undefined reference to 'new_tokenizer::Tokenizer::FromFile'

è§£å†³:
1. æ£€æŸ¥åº“æ˜¯å¦å®‰è£…: ls /usr/local/lib | grep new_tokenizer
2. æ£€æŸ¥CMakeæ˜¯å¦æ‰¾åˆ°åº“: cmake .. -DUSE_NEW_TOKENIZER_LIB=ON æŸ¥çœ‹è¾“å‡º
3. æ£€æŸ¥é“¾æ¥é¡ºåº: target_link_libraries ä¸­æ·»åŠ åº“
```

### é—®é¢˜2: å¤´æ–‡ä»¶æ‰¾ä¸åˆ°

```markdown
é”™è¯¯: fatal error: new_tokenizer.h: No such file or directory

è§£å†³:
1. æ£€æŸ¥å¤´æ–‡ä»¶è·¯å¾„: find /usr/local/include -name "new_tokenizer.h"
2. æ·»åŠ includeè·¯å¾„: include_directories(...)
3. æ£€æŸ¥æ¡ä»¶ç¼–è¯‘: #ifdef USE_NEW_TOKENIZER_LIB
```

### é—®é¢˜3: è¿è¡Œæ—¶æ‰¾ä¸åˆ°åº“

```markdown
é”™è¯¯: error while loading shared libraries: libnew_tokenizer.so

è§£å†³:
# Linux
export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH

# macOS
export DYLD_LIBRARY_PATH=/usr/local/lib:$DYLD_LIBRARY_PATH

# æˆ–å®‰è£…åˆ°ç³»ç»Ÿè·¯å¾„
sudo make install
sudo ldconfig  # Linux
```

---

## ğŸ“š å‚è€ƒå®ç°

æŸ¥çœ‹ç°æœ‰Tokenizerå®ç°:

- **HFTokenizer**: `src/tokenizer/hf_tokenizer.cpp`
- **NativeTokenizer**: `src/tokenizer/native_tokenizer.cpp`
- **UnifiedTokenizer**: `src/tokenizer/unified_tokenizer.cpp`

---

**æœ€åæ›´æ–°**: 2026-01-11
