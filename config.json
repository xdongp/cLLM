{
  "model": {
    "type": "hf",
    "path": "model/Qwen/qwen3_0.6b_cllm_fp16.bin",
    "config_path": "model/Qwen/Qwen3-0.6B/config.json",
    "tokenizer_path": "model/Qwen/Qwen3-0.6B",
    "max_seq_len": 2048,
    "num_threads": 4
  },
  "server": {
    "host": "0.0.0.0",
    "port": 8080,
    "max_batch_size": 1,
    "max_concurrent_requests": 10
  },
  "generation": {
    "max_tokens": 256,
    "temperature": 0.7,
    "top_p": 0.9,
    "top_k": 40,
    "repetition_penalty": 1.0
  }
}
