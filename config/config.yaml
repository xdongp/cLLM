# cLLM é…ç½®æ–‡ä»¶ï¼ˆæ¨¡æ¿ï¼‰
# å¤åˆ¶ä¸º config.yaml åæŒ‰éœ€ä¿®æ”¹

# æœåŠ¡å™¨é…ç½®
server:
  host: "0.0.0.0"          # æœåŠ¡å™¨ç›‘å¬åœ°å€
  port: 8080               # æœåŠ¡å™¨ç›‘å¬ç«¯å£
  num_threads: 8          # Drogon å·¥ä½œçº¿ç¨‹æ•°ï¼ˆ0 è¡¨ç¤ºä½¿ç”¨ç¡¬ä»¶å¹¶å‘æ•°ï¼‰- åŸºçº¿é…ç½®
  min_threads: 4           # æœ€å°çº¿ç¨‹æ•°ï¼ˆé¿å… /generate é˜»å¡å¯¼è‡´ /health å¡ä½ï¼‰- åŸºçº¿é…ç½®
  use_libtorch: false      # æ˜¯å¦ä½¿ç”¨ LibTorch åç«¯ï¼ˆå¦åˆ™ä½¿ç”¨ Kylinï¼‰

# æ¨¡å‹é…ç½®
model:
  path: "/Users/dannypan/PycharmProjects/xllm/cpp/cLLM/model/Qwen/qwen3-0.6b-q4_k_m.gguf"   # æ¨¡å‹ç›®å½•æˆ–æ¨¡å‹æ–‡ä»¶è·¯å¾„ (q4_k_m é‡åŒ–)
  vocab_size: 151936       # è¯è¡¨å¤§å°ï¼ˆå¯è¢«åç«¯è‡ªåŠ¨æ¢æµ‹è¦†ç›–ï¼‰
  max_context_length: 2048 # æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
  default_max_tokens: 100  # é»˜è®¤æœ€å¤§ç”Ÿæˆ token æ•° - ä¿®å¤ï¼šä¸APIé»˜è®¤å€¼ä¸€è‡´ï¼Œé¿å…è¦†ç›–ç”¨æˆ·è¯·æ±‚çš„max_tokens
  quantization: "q4_k_m"   # é‡åŒ–ç±»å‹: fp16, int8, int4, q4_k_m

# HTTP é…ç½®
http:
  max_input_tokens: 120    # æœ€å¤§è¾“å…¥ tokenï¼ˆè¿‡é•¿ prompt ä¼šè¢«è£å‰ªï¼‰
  timeout_ms: 30000        # HTTP è¯·æ±‚è¶…æ—¶æ—¶é—´(æ¯«ç§’)

# API ç«¯ç‚¹é…ç½®
api:
  endpoints:
    health:
      name: "health"
      path: "/health"
      method: "GET"
    generate:
      name: "generate"
      path: "/generate"
      method: "POST"
    generate_stream:
      name: "generate_stream"
      path: "/generate_stream"
      method: "POST"
    encode:
      name: "encode"
      path: "/encode"
      method: "POST"

  response:
    content_type:
      json: "application/json"
      stream: "text/event-stream"
    headers:
      cache_control: "no-cache"
      connection: "keep-alive"

  defaults:
    prompt: ""
    max_tokens: 100
    temperature: 0.7
    top_p: 0.9

  timeouts:
    min: 60.0
    max: 600.0
    token_factor: 10.0

# è°ƒåº¦å™¨é…ç½®
scheduler:
  max_iterations: 2000      # ä¼˜åŒ–ï¼šå¢åŠ æœ€å¤§è¿­ä»£æ¬¡æ•°ä»¥å¤„ç†æ›´å¤šè¯·æ±‚
  batch_timeout_ms: 100     # ä¼˜åŒ–ï¼šå‡å°‘æ‰¹å¤„ç†è¶…æ—¶ä»¥æ›´å¿«å“åº”
  max_batch_size: 128      # ğŸ”¥ ä¼˜åŒ–ï¼šå¤§å¹…å¢åŠ æœ€å¤§æ‰¹å¤„ç†å¤§å°ä»¥æœ€å¤§åŒ–ååé‡
  context_usage_threshold: 0.75
  default_temperature: 0.7
  default_top_p: 0.9
  default_top_k: 50
  default_max_tokens: 100
  request_timeout: 120.0    # ä¼˜åŒ–ï¼šå¢åŠ è¯·æ±‚è¶…æ—¶æ—¶é—´ä»¥é€‚åº”å¹¶å‘åœºæ™¯
  loop_interval: 1          # ä¼˜åŒ–ï¼šæçŸ­å¾ªç¯é—´éš”ä»¥æœ€å¤§åŒ–ååé‡
  idle_loop_interval: 10     # ä¼˜åŒ–ï¼šæçŸ­ç©ºé—²å¾ªç¯é—´éš”
  wait_poll_interval_ms: 1   # ä¼˜åŒ–ï¼šæçŸ­ç­‰å¾…è½®è¯¢é—´éš”ï¼ˆå·²ä½¿ç”¨æ¡ä»¶å˜é‡ï¼Œæ­¤å‚æ•°ä¸å†ä½¿ç”¨ï¼‰

# èµ„æºé…ç½®
resources:
  max_batch_size: 128      # ğŸ”¥ ä¼˜åŒ–ï¼šå¤§å¹…å¢åŠ æœ€å¤§æ‰¹å¤„ç†å¤§å°ä»¥æœ€å¤§åŒ–GPUå¹¶è¡Œèƒ½åŠ›
  max_context_length: 2048
  # ğŸ”§ KV Cache é…ç½®ï¼ˆç”¨äº inference::KVCacheManager ç»Ÿè®¡ç®¡ç†ï¼‰
  # æ³¨æ„ï¼šå¯¹äº llama.cpp åç«¯ï¼Œå®é™… KV cache æ•°æ®ç”± llama.cpp å†…éƒ¨ç®¡ç†
  # è¿™é‡Œçš„é…ç½®ç”¨äºç»Ÿè®¡ä¿¡æ¯è·Ÿè¸ªå’Œæ·˜æ±°å†³ç­–
  kv_cache_max_size: 64     # ğŸ”§ ä¼˜åŒ–ï¼šä¸ n_seq_max ä¿æŒä¸€è‡´ï¼ˆ64ä¸ªåºåˆ—ï¼‰
  kv_cache_max_memory_mb: 2048  # ğŸ”§ ä¼˜åŒ–ï¼š2GBï¼Œè¶³å¤Ÿæ”¯æŒé«˜å¹¶å‘åœºæ™¯
  memory_limit_mb: 8192

# ç¼“å­˜é…ç½®ï¼ˆç”¨äºé llama.cpp åç«¯çš„ KVCacheï¼‰
# å¯¹äº llama.cpp åç«¯ï¼Œæ­¤é…ç½®ä¸ä½¿ç”¨ï¼ˆScheduler ä¸åˆ›å»º KVCacheï¼‰
cache:
  default_max_size: 64      # ğŸ”§ ä¼˜åŒ–ï¼šä¸ n_seq_max ä¿æŒä¸€è‡´
  default_max_memory_mb: 2048  # ğŸ”§ ä¼˜åŒ–ï¼šä¸ kv_cache_max_memory_mb ä¸€è‡´
  enable_lru: true
  enable_memory_limit: true
  enable_stats: true
  eviction_threshold: 0.8    # ğŸ”§ ä¼˜åŒ–ï¼š80% è§¦å‘æ·˜æ±°ï¼Œé¿å…å†…å­˜æº¢å‡º
  cleanup_interval: 500    # ä¼˜åŒ–ï¼šå‡å°‘æ¸…ç†é—´éš”ä»¥æ›´å¿«é‡Šæ”¾å†…å­˜

# LibTorch åç«¯é…ç½®
backend:
  libtorch:
    seq_len_candidates: [8, 16, 32, 64, 128, 256]
    fallback_seq_len: 8
  
  # llama.cpp åç«¯é…ç½®
  llama_cpp:
    n_batch: 512          # æ‰¹å¤„ç†å¤§å°ï¼ˆ512æ˜¯å½“å‰æœ€ä¼˜é…ç½®ï¼‰
    n_threads: 8          # åŸºçº¿é…ç½®ï¼šä¸CPUæ ¸å¿ƒæ•°ä¸€è‡´ï¼ˆ8æ ¸ï¼‰
    n_gpu_layers: 99       # GPUå±‚æ•°ï¼ˆ99è¡¨ç¤ºä½¿ç”¨å…¨éƒ¨GPUå±‚ï¼Œå¯ç”¨MetalåŠ é€Ÿï¼‰
    n_seq_max: 64         # åŸºçº¿é…ç½®ï¼šæ”¯æŒåˆç†å¹¶å‘
    use_mmap: true        # ä½¿ç”¨å†…å­˜æ˜ å°„
    use_mlock: false      # ä½¿ç”¨å†…å­˜é”å®š

# åŠ¨æ€æ‰¹å¤„ç†è°ƒè°å™¨é…ç½®
dynamic_batch_tuner:
  enabled: true                     # æ˜¯å¦å¯ç”¨åŠ¨æ€ batch size è°ƒè°å™¨
  
  # ç­–ç•¥é€‰æ‹©
  strategy: "hybrid"               # ç­–ç•¥: static, adaptive, hybrid
  
  # æœç´¢ç®—æ³•é€‰æ‹©ï¼ˆadaptive å’Œ hybrid ç­–ç•¥ä½¿ç”¨ï¼‰
  search_algorithm: "adaptive_step"  # ç®—æ³•: adaptive_step, exponential_binary
  
  # static ç­–ç•¥ä¸“ç”¨å‚æ•°
  fixed_batch_size: 24             # é™æ€ç®—æ³•ä½¿ç”¨çš„å›ºå®š batch size
  
  # adaptive/hybrid ç­–ç•¥å‚æ•°
  min_batch_size: 16               # æœ€å° batch size
  max_batch_size: 48               # æœ€å¤§ batch size
  initial_batch_size: 24           # åˆå§‹ batch size
  
  # æ—¶é—´é˜ˆå€¼
  time_increase_threshold: 0.30    # å¤„ç†æ—¶é—´å¢åŠ é˜ˆå€¼ï¼ˆ30%ï¼Œä¼˜åŒ–ï¼šæ”¾å®½ä»¥å…è®¸æ›´å¤§çš„batch sizeï¼‰
  time_decrease_threshold: 0.10    # å¤„ç†æ—¶é—´å‡å°‘é˜ˆå€¼ï¼ˆ10%ï¼Œä¼˜åŒ–ï¼šå¢åŠ ä»¥æ›´ç§¯æè°ƒæ•´ï¼‰
  
  # éªŒè¯å’Œè°ƒæ•´
  validation_interval: 50          # éªŒè¯é—´éš”ï¼ˆæ¯ 50 ä¸ª batchï¼Œä¼˜åŒ–ï¼šå‡å°‘ä»¥æ›´å¿«éªŒè¯ï¼‰
  max_consecutive_time_increases: 5  # æœ€å¤§è¿ç»­æ—¶é—´å¢åŠ æ¬¡æ•°ï¼ˆä¼˜åŒ–ï¼šå¢åŠ ä»¥å…è®¸æ›´å¤šæ¢ç´¢ï¼‰
  auto_adjust_enabled: true        # æ˜¯å¦å¯ç”¨è‡ªåŠ¨è°ƒæ•´
  
  # æ¢æµ‹å‚æ•°
  probe_batch_count: 10            # æ¢æµ‹æ—¶è¿è¡Œçš„ batch æ•°é‡ï¼ˆä¼˜åŒ–ï¼šå¢åŠ ä»¥æé«˜å‡†ç¡®æ€§ï¼‰
  validation_batch_count: 10       # éªŒè¯æ—¶è¿è¡Œçš„ batch æ•°é‡ï¼ˆä¼˜åŒ–ï¼šå¢åŠ ä»¥æé«˜å‡†ç¡®æ€§ï¼‰
  
  # è°ƒæ•´å› å­
  adjustment_factor: 0.50          # è°ƒæ•´å› å­ï¼ˆ50%ï¼Œä¼˜åŒ–ï¼šå¢åŠ ä»¥æ›´å¿«è°ƒæ•´ï¼‰
  
  # æ¢ç´¢å‚æ•°
  exploration_interval: 200        # å®šæœŸæ¢ç´¢é—´éš”ï¼ˆæ¯ 200 ä¸ª batchï¼Œä¼˜åŒ–ï¼šå‡å°‘ä»¥æ›´é¢‘ç¹æ¢ç´¢ï¼‰

# æ—¥å¿—é…ç½®
logging:
  level: "debug"         # æ—¥å¿—çº§åˆ«: trace, debug, info, warn, error, critical
  file: "logs/cllm_server.log"  # æ—¥å¿—æ–‡ä»¶è·¯å¾„
  max_size_mb: 100         # æ—¥å¿—æ–‡ä»¶æœ€å¤§å¤§å°(MB)
  max_files: 5            # ä¿ç•™çš„æ—¥å¿—æ–‡ä»¶æ•°é‡
