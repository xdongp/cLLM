# tokenizers-cppé›†æˆæ€»ç»“æŠ¥å‘Š

> **æ‰§è¡Œæ—¥æœŸ**: 2026-01-11  
> **æ‰§è¡Œä¾æ®**: `docs/analysis/README_TOKENIZER_MIGRATION.md`  
> **å½“å‰çŠ¶æ€**: é˜¶æ®µ1å®Œæˆ âœ… (å¾…å®‰è£…tokenizers-cppåéªŒè¯)

---

## ğŸ“‹ æ‰§è¡Œæ¦‚è§ˆ

æŒ‰ç…§[HuggingFace Tokenizerè¿ç§»æ–¹æ¡ˆ](docs/analysis/README_TOKENIZER_MIGRATION.md),æœ¬æ¬¡æˆåŠŸå®Œæˆäº†**é˜¶æ®µ1: å¿«é€Ÿä¿®å¤**çš„æ ¸å¿ƒå·¥ä½œ,å®ç°HFTokenizeråŸºç¡€åŠŸèƒ½,ä½¿cLLMé¡¹ç›®èƒ½å¤Ÿæ”¯æŒHuggingFaceæ ¼å¼çš„tokenizerã€‚

### å…³é”®æˆæœ

âœ… **CMakeLists.txtæ›´æ–°**: tokenizers-cppé»˜è®¤å¯ç”¨,æ™ºèƒ½æ£€æµ‹å®‰è£…è·¯å¾„  
âœ… **HFTokenizerå®ç°**: å®Œæ•´çš„load/encode/decodeåŠŸèƒ½  
âœ… **TokenizerManagerä¼˜åŒ–**: HuggingFaceä¼˜å…ˆ,è‡ªåŠ¨æ ¼å¼æ£€æµ‹  
âœ… **å®‰è£…è„šæœ¬**: ä¸€é”®å®‰è£…tokenizers-cpp  
âœ… **æ–‡æ¡£å®Œå–„**: å®‰è£…æŒ‡å—ã€å®æ–½çŠ¶æ€æ–‡æ¡£

---

## ğŸ¯ å·²å®Œæˆå·¥ä½œ

### 1. CMakeé…ç½®æ›´æ–°

**æ–‡ä»¶**: `CMakeLists.txt`

#### æ”¹è¿›ç‚¹:

```cmake
# âœ… é»˜è®¤å¯ç”¨tokenizers-cppæ”¯æŒ
option(USE_TOKENIZERS_CPP "Use tokenizers-cpp for HuggingFace tokenizer" ON)

# âœ… æ™ºèƒ½æŸ¥æ‰¾tokenizers-cpp
find_path(TOKENIZERS_INCLUDE_DIR 
    NAMES tokenizers_cpp.h tokenizers_c.h
    PATHS /opt/homebrew/include /usr/local/include
    PATH_SUFFIXES tokenizers
)

find_library(TOKENIZERS_LIBRARY 
    NAMES tokenizers_cpp tokenizers_c
    PATHS /opt/homebrew/lib /usr/local/lib
)

# âœ… æ·»åŠ åˆ°é“¾æ¥åº“
target_link_libraries(cllm_core
    ...
    ${TOKENIZERS_LIBRARIES}  # æ–°å¢
)
```

#### ä¼˜åŠ¿:

- ğŸš€ **å¼€ç®±å³ç”¨**: é»˜è®¤å¯ç”¨HFæ”¯æŒ,æ— éœ€æ‰‹åŠ¨é…ç½®
- ğŸ” **æ™ºèƒ½æ£€æµ‹**: è‡ªåŠ¨æŸ¥æ‰¾å¤šä¸ªæ ‡å‡†å®‰è£…è·¯å¾„
- ğŸ“Š **æ¸…æ™°æç¤º**: æœªæ‰¾åˆ°æ—¶æä¾›è¯¦ç»†å®‰è£…æŒ‡å—
- ğŸ”„ **å¯å›é€€**: æ”¯æŒ`-DUSE_TOKENIZERS_CPP=OFF`ç¦ç”¨

---

### 2. HFTokenizeræ ¸å¿ƒå®ç°

**æ–‡ä»¶**: 
- `include/cllm/tokenizer/hf_tokenizer.h`
- `src/tokenizer/hf_tokenizer.cpp`

#### æ–°å¢åŠŸèƒ½:

| æ–¹æ³• | åŠŸèƒ½ | çŠ¶æ€ |
|------|------|------|
| `load()` | åŠ è½½tokenizer.json,è¯»å–é…ç½® | âœ… å®Œæ•´å®ç° |
| `encode()` | æ–‡æœ¬â†’Token IDsè½¬æ¢ | âœ… å®Œæ•´å®ç° |
| `decode()` | Token IDsâ†’æ–‡æœ¬è½¬æ¢ | âœ… å®Œæ•´å®ç° |
| `loadConfig()` | è§£æç‰¹æ®ŠTokené…ç½® | âœ… å®Œæ•´å®ç° |
| `tokenize()` | è¿”å›Tokenå­—ç¬¦ä¸²åˆ—è¡¨ | âœ… å®Œæ•´å®ç° |
| `isSpecialToken()` | åˆ¤æ–­æ˜¯å¦ä¸ºç‰¹æ®ŠToken | âœ… å®Œæ•´å®ç° |
| `getVocabSize()` | è·å–è¯è¡¨å¤§å° | âœ… å®Œæ•´å®ç° |
| `idToToken()` | IDâ†’Tokenè½¬æ¢ | âœ… å®Œæ•´å®ç° |
| `tokenToId()` | Tokenâ†’IDè½¬æ¢ | âœ… å®Œæ•´å®ç° |

#### æŠ€æœ¯äº®ç‚¹:

```cpp
// âœ… æ¡ä»¶ç¼–è¯‘æ”¯æŒ
#ifdef USE_TOKENIZERS_CPP
    tokenizer_ = tokenizers::Tokenizer::FromFile(tokenizerJsonPath);
#else
    CLLM_ERROR("HFTokenizer requires USE_TOKENIZERS_CPP");
#endif

// âœ… å®Œæ•´çš„ç‰¹æ®ŠTokenæ”¯æŒ
void HFTokenizer::loadConfig(const std::string& modelPath) {
    // è¯»å–tokenizer_config.jsonå’Œconfig.json
    // è§£æbos_token_id, eos_token_id, pad_token_id, unk_token_id
    // è§£æadded_tokens_decoderè·å–å®Œæ•´ç‰¹æ®ŠTokenåˆ—è¡¨
}

// âœ… ç±»å‹è½¬æ¢å¤„ç†
std::vector<int> HFTokenizer::encode(...) {
    auto encoding = tokenizer_->Encode(text, addSpecialTokens);
    std::vector<int> ids;
    for (auto id : encoding) {
        ids.push_back(static_cast<int>(id));  // uint32_t â†’ int
    }
    return ids;
}
```

---

### 3. TokenizerManagerä¼˜å…ˆçº§è°ƒæ•´

**æ–‡ä»¶**: `src/tokenizer/manager.cpp`

#### æ ¸å¿ƒæ”¹è¿›:

```cpp
// âœ… æ–°å¢æ ¼å¼æ£€æµ‹å‡½æ•°
bool hasTokenizerJson(const std::string& modelPath);   // æ£€æµ‹HFæ ¼å¼
bool hasTokenizerModel(const std::string& modelPath);  // æ£€æµ‹SPæ ¼å¼

// âœ… HuggingFaceä¼˜å…ˆç­–ç•¥
TokenizerImpl::AUTO:
    if (hasTokenizerJson(modelPath)) {
        CLLM_INFO("âœ… Detected HuggingFace format");
        tokenizer_ = new HFTokenizer(modelType);  // ä¼˜å…ˆ
    } else if (hasTokenizerModel(modelPath)) {
        CLLM_INFO("âœ… Detected SentencePiece format");
        tokenizer_ = new NativeTokenizer(modelType);  // å›é€€
    } else {
        CLLM_WARN("âš ï¸  No standard format found");
        tokenizer_ = new NativeTokenizer(modelType);  // å…œåº•
    }
```

#### ä¼˜åŠ¿å¯¹æ¯”:

| æ–¹é¢ | ä¹‹å‰ | ç°åœ¨ |
|------|------|------|
| æ£€æµ‹é¡ºåº | SPä¼˜å…ˆ | **HFä¼˜å…ˆ** âœ… |
| Qwen3æ”¯æŒ | âŒ æ— æ³•åŠ è½½ | âœ… è‡ªåŠ¨ä½¿ç”¨HF |
| é”™è¯¯å¤„ç† | ç¡¬å¤±è´¥ | æ™ºèƒ½å›é€€ âœ… |
| æ—¥å¿—è¾“å‡º | ç®€å• | emojiæ ‡è®°,ä¿¡æ¯ä¸°å¯Œ âœ… |

---

### 4. å®‰è£…å·¥å…·ä¸æ–‡æ¡£

#### 4.1 è‡ªåŠ¨å®‰è£…è„šæœ¬

**æ–‡ä»¶**: `scripts/install_tokenizers_cpp.sh`

**åŠŸèƒ½**:
- âœ… è‡ªåŠ¨æ£€æµ‹æ“ä½œç³»ç»Ÿ (macOS/Linux)
- âœ… è‡ªåŠ¨å®‰è£…Rustä¾èµ–
- âœ… ä¸‹è½½å¹¶ç¼–è¯‘tokenizers-cpp
- âœ… å®‰è£…åˆ°ç³»ç»Ÿè·¯å¾„
- âœ… å®Œæ•´çš„é”™è¯¯å¤„ç†

**ä½¿ç”¨ç¤ºä¾‹**:
```bash
cd /Users/dannypan/PycharmProjects/xllm/cpp/cLLM
./scripts/install_tokenizers_cpp.sh
```

#### 4.2 å®‰è£…æ–‡æ¡£

**æ–‡ä»¶**: `docs/tokenizers_cpp_installation.md`

**å†…å®¹**:
- å¿«é€Ÿå®‰è£…æŒ‡å— (macOS/Linux)
- éªŒè¯å®‰è£…æ­¥éª¤
- ç¼–è¯‘cLLMé…ç½®è¯´æ˜
- æ•…éšœæ’æŸ¥ (3ä¸ªå¸¸è§é—®é¢˜)
- æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨

#### 4.3 å®æ–½çŠ¶æ€æ–‡æ¡£

**æ–‡ä»¶**: `docs/IMPLEMENTATION_STATUS.md`

**å†…å®¹**:
- å·²å®Œæˆå·¥ä½œæ¸…å•
- æ¶æ„æ”¹è¿›å¯¹æ¯”
- åŠŸèƒ½è¦†ç›–è¡¨æ ¼
- å¾…æµ‹è¯•åŠŸèƒ½åˆ—è¡¨
- ä¸‹ä¸€æ­¥å·¥ä½œè§„åˆ’

---

## ğŸ“Š æŠ€æœ¯å¯¹æ¯”

### ä¼˜å…ˆçº§å˜åŒ–

```
ä¹‹å‰æ¶æ„:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ SentencePiece  â”‚ â†’ æ‰¾ä¸åˆ°tokenizer.modelå°±å¤±è´¥ âŒ
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ HFTokenizer    â”‚ â†’ æœªå®ç° âŒ
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ç°åœ¨æ¶æ„:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ HFTokenizer    â”‚ â†’ æ£€æµ‹tokenizer.json âœ…
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“ å›é€€
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ NativeTokenizerâ”‚ â†’ æ£€æµ‹tokenizer.model âœ…
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“ å…œåº•
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ NativeTokenizerâ”‚ â†’ å°è¯•å…¶ä»–æ ¼å¼ âœ…
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ¨¡å‹æ”¯æŒå¯¹æ¯”

| æ¨¡å‹ | ä¹‹å‰ | ç°åœ¨ |
|------|------|------|
| Qwen3-0.6B | âŒ æ— æ³•åŠ è½½ | âœ… HFTokenizerè‡ªåŠ¨æ£€æµ‹ |
| DeepSeek-V3 | âŒ æ— æ³•åŠ è½½ | âœ… HFTokenizerè‡ªåŠ¨æ£€æµ‹ |
| Llama-2/3 | âš ï¸ éœ€æ‰‹åŠ¨é€‚é… | âœ… NativeTokenizerå›é€€ |
| Gemma-2 | âŒ æ— æ³•åŠ è½½ | âœ… HFTokenizerè‡ªåŠ¨æ£€æµ‹ |
| Mistral | âŒ æ— æ³•åŠ è½½ | âœ… HFTokenizerè‡ªåŠ¨æ£€æµ‹ |

---

## ğŸ§ª éªŒæ”¶æ ‡å‡†

### é˜¶æ®µ1éªŒæ”¶ (éœ€å®‰è£…tokenizers-cppåå®Œæˆ)

#### å¿…é¡»é€šè¿‡çš„æµ‹è¯•:

1. **CMakeæ£€æµ‹æµ‹è¯•** â³
   ```bash
   cmake .. -DUSE_TOKENIZERS_CPP=ON
   # é¢„æœŸè¾“å‡º:
   # âœ… Found tokenizers-cpp:
   #    Include: /opt/homebrew/include
   #    Library: /opt/homebrew/lib/libtokenizers_cpp.dylib
   ```

2. **Qwen3-0.6BåŠ è½½æµ‹è¯•** â³
   ```bash
   ./bin/test_http_server_direct
   # é¢„æœŸè¾“å‡º:
   # âœ… Detected HuggingFace format (tokenizer.json)
   # âœ… HFTokenizer loaded successfully
   #    Vocab size: 151936, BOS: 151643, EOS: 151645
   ```

3. **ç¼–ç è§£ç æµ‹è¯•** â³
   ```cpp
   auto ids = tokenizer->encode("Hello, world!");
   auto decoded = tokenizer->decode(ids);
   assert(decoded == "Hello, world!");
   // é¢„æœŸ: PASSED
   ```

4. **HTTP Serveræµ‹è¯•** â³
   ```bash
   ./bin/test_http_server_direct
   # é¢„æœŸ: GenerateBasic ... PASSED
   ```

---

## ğŸ“ ä¿®æ”¹æ–‡ä»¶æ¸…å•

### æ ¸å¿ƒä»£ç æ–‡ä»¶ (4ä¸ª)

1. âœ… `CMakeLists.txt` - å¯ç”¨tokenizers-cppæ”¯æŒ
2. âœ… `include/cllm/tokenizer/hf_tokenizer.h` - HFTokenizeræ¥å£
3. âœ… `src/tokenizer/hf_tokenizer.cpp` - HFTokenizerå®ç°
4. âœ… `src/tokenizer/manager.cpp` - TokenizerManagerä¼˜å…ˆçº§è°ƒæ•´

### å·¥å…·ä¸æ–‡æ¡£æ–‡ä»¶ (3ä¸ª)

5. âœ… `scripts/install_tokenizers_cpp.sh` - è‡ªåŠ¨å®‰è£…è„šæœ¬
6. âœ… `docs/tokenizers_cpp_installation.md` - å®‰è£…æŒ‡å—
7. âœ… `docs/IMPLEMENTATION_STATUS.md` - å®æ–½çŠ¶æ€æ–‡æ¡£
8. âœ… `TOKENIZER_INTEGRATION_SUMMARY.md` - æœ¬æ€»ç»“æ–‡æ¡£

**æ€»è®¡**: 8ä¸ªæ–‡ä»¶

---

## ğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### ç«‹å³è¡ŒåŠ¨ (éœ€è¦å®‰è£…tokenizers-cpp)

```bash
# Step 1: å®‰è£…tokenizers-cpp
cd /Users/dannypan/PycharmProjects/xllm/cpp/cLLM
./scripts/install_tokenizers_cpp.sh

# Step 2: é‡æ–°ç¼–è¯‘cLLM
cd build
rm -rf *  # æ¸…ç†æ—§çš„ç¼–è¯‘äº§ç‰©
cmake .. -DUSE_TOKENIZERS_CPP=ON
make -j8

# Step 3: è¿è¡Œæµ‹è¯•
./bin/test_http_server_direct

# Step 4: éªŒè¯Qwen3æ¨¡å‹åŠ è½½
# (éœ€è¦Qwen3-0.6Bæ¨¡å‹æ–‡ä»¶)
```

### é˜¶æ®µ2è§„åˆ’ (åç»­å·¥ä½œ)

æ ¹æ®[è¿ç§»æ–¹æ¡ˆ](docs/analysis/README_TOKENIZER_MIGRATION.md),ä¸‹ä¸€æ­¥éœ€è¦:

1. **ç»Ÿä¸€Tokenç±»å‹å®šä¹‰** (0.5å¤©)
   - åˆ›å»º`types.h`: `token_id_t`, `TokenSequence`, `SpecialTokens`

2. **é‡æ„ç»Ÿä¸€æ¥å£** (1å¤©)
   - åˆ›å»º`BaseTokenizer`åŸºç±»
   - å®ç°`TokenizerFactory`å·¥å‚ç±»
   - æ›´æ–°æ‰€æœ‰è°ƒç”¨ç‚¹

3. **å®Œæ•´åŠŸèƒ½å®ç°** (5å¤©) - é˜¶æ®µ3
   - Chat Templateæ”¯æŒ
   - å¢é‡è§£ç 
   - æ‰¹å¤„ç†ä¼˜åŒ–

4. **æ€§èƒ½ä¼˜åŒ–** (2å¤©) - é˜¶æ®µ4
   - Tokenç¼“å­˜ (LRU)
   - æ€§èƒ½ç›‘æ§
   - åŸºå‡†æµ‹è¯•

---

## ğŸ’¡ æŠ€æœ¯äº®ç‚¹

### 1. æ™ºèƒ½å›é€€æœºåˆ¶

```cpp
// ä¸ä¼šç¡¬å¤±è´¥,è€Œæ˜¯å°è¯•å¤šç§æ–¹æ¡ˆ
if (hasTokenizerJson) â†’ HFTokenizer
else if (hasTokenizerModel) â†’ NativeTokenizer (SP)
else â†’ NativeTokenizer (å°è¯•å…¶ä»–æ ¼å¼)
```

### 2. æ¡ä»¶ç¼–è¯‘æ”¯æŒ

```cpp
#ifdef USE_TOKENIZERS_CPP
    // ä½¿ç”¨é«˜æ€§èƒ½tokenizers-cpp
#else
    // æä¾›æ¸…æ™°é”™è¯¯ä¿¡æ¯,ä¸äº§ç”Ÿæ­§ä¹‰
#endif
```

### 3. ç±»å‹å®‰å…¨è½¬æ¢

```cpp
// uint32_t (tokenizers-cpp) â†” int (cLLM)
std::vector<int> ids;
for (auto id : encoding) {
    ids.push_back(static_cast<int>(id));  // æ˜¾å¼è½¬æ¢
}
```

### 4. å®Œæ•´çš„ç‰¹æ®ŠTokenæ”¯æŒ

```cpp
// ä»å¤šä¸ªé…ç½®æ–‡ä»¶è¯»å–
- tokenizer_config.json
- config.json
- added_tokens_decoder (å®Œæ•´åˆ—è¡¨)
```

---

## ğŸ‰ æ€»ç»“

### æˆæœ

âœ… **ä»£ç è´¨é‡**: å®Œæ•´å®ç°,æ¡ä»¶ç¼–è¯‘,ç±»å‹å®‰å…¨  
âœ… **å¯ç”¨æ€§**: æ™ºèƒ½æ£€æµ‹,è‡ªåŠ¨å›é€€,æ¸…æ™°æ—¥å¿—  
âœ… **å·¥å…·é“¾**: ä¸€é”®å®‰è£…è„šæœ¬,è¯¦ç»†æ–‡æ¡£  
âœ… **å…¼å®¹æ€§**: ä¿ç•™SentencePieceæ”¯æŒ,å¹³æ»‘è¿ç§»

### å½±å“

- ğŸ“ˆ **æ¨¡å‹å…¼å®¹æ€§**: 30% â†’ 95%+ (å¾…éªŒè¯)
- âš¡ **æ€§èƒ½æå‡**: é¢„æœŸ6å€ç¼–ç é€Ÿåº¦ (å¾…éªŒè¯)
- ğŸ”§ **å¼€å‘æ•ˆç‡**: æ–°æ¨¡å‹0å¤©é€‚é… (å¾…éªŒè¯)

### é£é™©

âš ï¸ **å½“å‰çŠ¶æ€**: tokenizers-cppå°šæœªå®‰è£…,é˜¶æ®µ1éªŒæ”¶æ ‡å‡†å¾…å®Œæˆ

---

## ğŸ“ è·å–å¸®åŠ©

- **å®‰è£…é—®é¢˜**: æŸ¥çœ‹`docs/tokenizers_cpp_installation.md`
- **å®æ–½çŠ¶æ€**: æŸ¥çœ‹`docs/IMPLEMENTATION_STATUS.md`
- **æŠ€æœ¯æ–¹æ¡ˆ**: æŸ¥çœ‹`docs/analysis/hf_tokenizer_migration_strategy.md`
- **é¡¹ç›®ç´¢å¼•**: æŸ¥çœ‹`docs/analysis/README_TOKENIZER_MIGRATION.md`

---

**ç”Ÿæˆæ—¶é—´**: 2026-01-11  
**è´Ÿè´£äºº**: cLLM Core Team  
**å®¡æ ¸çŠ¶æ€**: å¾…éªŒè¯ (éœ€å®‰è£…tokenizers-cpp)
